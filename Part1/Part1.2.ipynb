{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston    # 506 samples, 13 feature\n",
    "\n",
    "df = load_boston()\n",
    "x = df.data\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson's correlation feature selection for numeric input and numeric output\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature selection\n",
    "fs = SelectKBest(score_func = f_regression, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 10)\n"
     ]
    }
   ],
   "source": [
    "# apply feature selection\n",
    "x_selected = fs.fit_transform(x, y)\n",
    "print(x_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.fit_transform(x_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(x, y, test_size = 0.2, random_state = 87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data X train matrix (404, 10)\n",
      "Size of data Y train array (404,)\n",
      "Size of data X test matrix (102, 10)\n",
      "Size of data Y test array (102,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of data X train matrix %s\"  % str(train_X.shape))\n",
    "print(\"Size of data Y train array %s\"  % str(train_y.shape))\n",
    "print(\"Size of data X test matrix %s\"  % str(test_X.shape))\n",
    "print(\"Size of data Y test array %s\"  % str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_column_train = np.ones((train_X.shape[0], 1))\n",
    "train_X_new = np.append(one_column_train, train_X, axis = 1) # Add bias\n",
    "\n",
    "one_column_test = np.ones((test_X.shape[0], 1))\n",
    "test_X_new = np.append(one_column_test, test_X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data X train matrix (404, 11)\n",
      "Size of data Y train array (404,)\n",
      "Size of data X test matrix (102, 11)\n",
      "Size of data Y test array (102,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of data X train matrix %s\"  % str(train_X_new.shape))\n",
    "print(\"Size of data Y train array %s\"  % str(train_y.shape))\n",
    "print(\"Size of data X test matrix %s\"  % str(test_X_new.shape))\n",
    "print(\"Size of data Y test array %s\"  % str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_cost_vectorized(w, X, y):\n",
    "    '''\n",
    "    Evaluate the cost function in a vectorized manner for \n",
    "    inputs `X` and targets `t`, at weights `w` and `b`.\n",
    "    \n",
    "    X: dataset matrix has (m, n) dimension. \n",
    "    y: targets vector has (n, ) dimension.\n",
    "    w: weights vector has (n, ) dimension\n",
    "    b: a scalar bias.\n",
    "    \n",
    "    Return a scalar cost value of `w`, `b`.\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[0] # number of samples in dataset\n",
    "    w = np.array(w) # convert to numpy array\n",
    "    y_hat = np.dot(X, w) # hypothesis\n",
    "    \n",
    "    return np.sum((y_hat - y)**2)/(2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_grad_fn_vectorized(w, X, y):\n",
    "    '''\n",
    "    Given `w` - a current \"Guess\" of what our weights should be\n",
    "          `X` - matrix of shape (m, n + 1) of input features\n",
    "          `y` - target y values\n",
    "    Return gradient of each weight evaluated at the current value\n",
    "    '''\n",
    "    \n",
    "    #TODO: Complete the below followed the above expressions\n",
    "    m, n = X.shape\n",
    "    y_hat = np.dot(X, w)\n",
    "    grad_w = np.dot(X.T, y_hat - y)/m\n",
    "    \n",
    "    return grad_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_solve_via_gradient_descent(X, y, print_every=5000,\n",
    "                                  niter=100000, alpha=0.005):\n",
    "    '''\n",
    "    Given `X` - matrix of shape (m, n+1) of input features\n",
    "          `y` - target y values\n",
    "    Solves for linear regression weights.\n",
    "    Return weights after `niter` iterations.\n",
    "    '''\n",
    "    m, n = X.shape\n",
    "    # initialize all the weights to zeros\n",
    "    w = np.zeros((n,))\n",
    "    for k in range(niter):\n",
    "        \n",
    "        dw = np_grad_fn_vectorized(w, X, y) \n",
    "        w = w - alpha*dw\n",
    "        \n",
    "        if k % print_every == 0:\n",
    "            print('Weight after %d iteration: %s' % (k, str(w)))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight after 0 iteration: [0.11068564 0.00289013 0.01646994 0.03786181 0.03482141 0.06114533\n",
      " 0.0696155  0.03603987 0.04115908 0.06437591 0.02720058]\n",
      "Weight after 5000 iteration: [ 17.68349016  -2.91609326   5.81528695  -1.36067871  -0.63287267\n",
      "  18.6971211    1.8358486   -0.85504806  -3.08287965  -2.31298171\n",
      " -10.56191088]\n",
      "Weight after 10000 iteration: [ 18.68859219  -4.01120425   3.58410881  -0.61196256  -0.57619495\n",
      "  22.1059845    1.71567547   1.53459542  -3.39120718  -5.56140081\n",
      " -15.26504738]\n",
      "Weight after 15000 iteration: [ 19.37263669  -4.83799158   2.06603354   0.06771047  -0.99680849\n",
      "  23.46085126   1.70269987   2.84668913  -3.88356093  -6.96536053\n",
      " -17.52861825]\n",
      "Weight after 20000 iteration: [ 19.89194534  -5.48741957   1.19391933   0.63001217  -1.51797153\n",
      "  23.92590907   1.71594898   3.69663492  -4.34803966  -7.69051108\n",
      " -18.65670543]\n",
      "Weight after 25000 iteration: [ 20.3052759   -6.01931847   0.72056777   1.08845795  -2.00549639\n",
      "  23.99173807   1.75114831   4.30858136  -4.75482963  -8.13689002\n",
      " -19.23828907]\n",
      "Weight after 30000 iteration: [ 20.64391168  -6.46890464   0.47130221   1.46096203  -2.42416251\n",
      "  23.88134121   1.80005382   4.7811317   -5.10721572  -8.44793276\n",
      " -19.55355438]\n",
      "Weight after 35000 iteration: [ 20.92665608  -6.85678527   0.34365772   1.76386527  -2.77197303\n",
      "  23.69927379   1.85454297   5.16302319  -5.4126369   -8.68100597\n",
      " -19.7379332 ]\n",
      "Weight after 40000 iteration: [ 21.1658052   -7.19555737   0.28114671   2.0108806   -3.05690185\n",
      "  23.49507395   1.90908818   5.48047427  -5.67776708  -8.86283518\n",
      " -19.85715367]\n",
      "Weight after 45000 iteration: [ 21.36992371  -7.49347961   0.25334974   2.21309148  -3.28898453\n",
      "  23.29197227   1.96058014   5.74884011  -5.90807929  -9.00803464\n",
      " -19.94305835]\n",
      "Weight after 50000 iteration: [ 21.54527832  -7.7564211    0.24398235   2.37929928  -3.47771004\n",
      "  23.10040766   2.00755773   5.97795654  -6.10811438  -9.12571933\n",
      " -20.01099597]\n",
      "Weight after 55000 iteration: [ 21.69663721  -7.98887967   0.24429565   2.51645132  -3.63126659\n",
      "  22.92455613   2.04954462   6.17468822  -6.28173932  -9.22211239\n",
      " -20.06832263]\n",
      "Weight after 60000 iteration: [ 21.82774253  -8.19451315   0.24954785   2.63003606  -3.75644492\n",
      "  22.76553837   2.08660307   6.34418199  -6.43231122  -9.30171171\n",
      " -20.11855976]\n",
      "Weight after 65000 iteration: [ 21.94160353  -8.37641991   0.25714193   2.72440883  -3.85876671\n",
      "  22.62301313   2.11906267   6.4905054   -6.5627742   -9.36788613\n",
      " -20.16341903]\n",
      "Weight after 70000 iteration: [ 22.04068635  -8.53729104   0.26564377   2.80304662  -3.9426755\n",
      "  22.49597416   2.14736483   6.61698761  -6.67571956  -9.42321826\n",
      " -20.20377899]\n",
      "Weight after 75000 iteration: [ 22.12704175  -8.67949719   0.27426081   2.86874298  -4.01172837\n",
      "  22.38314963   2.17197799   6.72641341  -6.77342795  -9.46972032\n",
      " -20.24014831]\n",
      "Weight after 80000 iteration: [ 22.2023944   -8.8051421    0.28256148   2.92375596  -4.06876637\n",
      "  22.28320151   2.1933542    6.82114265  -6.85790301  -9.50897925\n",
      " -20.27287965]\n",
      "Weight after 85000 iteration: [ 22.26820738  -8.91609882   0.29032127   2.96992074  -4.11605795\n",
      "  22.19482332   2.21190889   6.9031903   -6.93090069  -9.54225884\n",
      " -20.30226387]\n",
      "Weight after 90000 iteration: [ 22.32573031  -9.0140368    0.29743632   3.00873605  -4.15541622\n",
      "  22.11678601   2.22801362   6.97428449  -6.99395589  -9.57057381\n",
      " -20.32856829]\n",
      "Weight after 95000 iteration: [ 22.37603612  -9.10044388   0.30387363   3.04143088  -4.1882931\n",
      "  22.04795715   2.24199532   7.03591127  -7.04840708  -9.59474482\n",
      " -20.35204966]\n",
      "Weight after 100000 iteration: [ 22.4200499   -9.17664511   0.30964171   3.06901678  -4.21585436\n",
      "  21.98730633   2.254139     7.08935057  -7.09541887  -9.61544002\n",
      " -20.37295659]\n",
      "Weight after 105000 iteration: [ 22.45857194  -9.24381945   0.31477269   3.09232893  -4.23903889\n",
      "  21.93390358   2.26469167   7.135706    -7.13600275  -9.63320673\n",
      " -20.3915281 ]\n",
      "Weight after 110000 iteration: [ 22.49229639  -9.30301476   0.31931136   3.11205885  -4.25860546\n",
      "  21.88691424   2.27386684   7.17592982  -7.17103576  -9.64849588\n",
      " -20.40799133]\n",
      "Weight after 115000 iteration: [ 22.52182665  -9.35516143   0.32330837   3.12878062  -4.27516957\n",
      "  21.84559221   2.28184871   7.21084425  -7.20127734  -9.66168103\n",
      " -20.42255955]\n",
      "Weight after 120000 iteration: [ 22.54768812  -9.40108474   0.32681592   3.1429719   -4.28923246\n",
      "  21.8092726    2.28879619   7.24115951  -7.2273844   -9.67307326\n",
      " -20.43543084]\n",
      "Weight after 125000 iteration: [ 22.57033894  -9.44151607   0.32988515   3.155031    -4.30120393\n",
      "  21.77736432   2.29484637   7.26748941  -7.24992459  -9.68293285\n",
      " -20.4467875 ]\n",
      "Weight after 130000 iteration: [ 22.59017903  -9.47710303   0.33256461   3.16529073  -4.31142037\n",
      "  21.74934292   2.30011759   7.29036462  -7.26938807  -9.69147859\n",
      " -20.45679597]\n",
      "Weight after 135000 iteration: [ 22.60755784  -9.50841863   0.33489937   3.17402968  -4.3201591\n",
      "  21.72474386   2.30471209   7.31024413  -7.28619782  -9.69889517\n",
      " -20.46560723]\n",
      "Weight after 140000 iteration: [ 22.62278092  -9.53596952   0.33693065   3.18148152  -4.32764957\n",
      "  21.7031562    2.3087183    7.32752509  -7.30071872  -9.7053391\n",
      " -20.47335753]\n",
      "Weight after 145000 iteration: [ 22.6361156   -9.56020342   0.33869568   3.18784252  -4.33408244\n",
      "  21.68421688   2.31221274   7.34255127  -7.31326534  -9.7109435\n",
      " -20.48016924]\n",
      "Weight after 150000 iteration: [ 22.6477959   -9.5815157    0.34022783   3.19327785  -4.33961672\n",
      "  21.66760544   2.31526173   7.35562033  -7.32410888  -9.71582196\n",
      " -20.48615186]\n",
      "Weight after 155000 iteration: [ 22.6580267   -9.60025537   0.34155676   3.19792671  -4.34438549\n",
      "  21.65303931   2.31792277   7.36699011  -7.33348308  -9.72007171\n",
      " -20.49140308]\n",
      "Weight after 160000 iteration: [ 22.6669875   -9.61673036   0.34270871   3.20190656  -4.34850057\n",
      "  21.64026949   2.32024578   7.37688402  -7.34158936  -9.72377619\n",
      " -20.49600979]\n",
      "Weight after 165000 iteration: [ 22.67483553  -9.63121221   0.34370676   3.2053167   -4.35205618\n",
      "  21.62907673   2.32227413   7.38549574  -7.34860131  -9.72700717\n",
      " -20.50004913]\n",
      "Weight after 170000 iteration: [ 22.68170856  -9.64394032   0.34457117   3.20824116  -4.355132\n",
      "  21.6192681    2.32404552   7.3929932   -7.35466853  -9.72982654\n",
      " -20.50358944]\n",
      "Weight after 175000 iteration: [ 22.68772734  -9.65512564   0.34531966   3.21075115  -4.35779558\n",
      "  21.61067391   2.32559276   7.39952206  -7.35991995  -9.73228777\n",
      " -20.50669116]\n",
      "Weight after 180000 iteration: [ 22.69299767  -9.66495404   0.34596767   3.2129071   -4.36010437\n",
      "  21.603145     2.32694439   7.40520872  -7.36446672  -9.73443712\n",
      " -20.50940765]\n",
      "Weight after 185000 iteration: [ 22.6976123   -9.67358918   0.34652866   3.21476032  -4.36210733\n",
      "  21.5965503    2.32812529   7.41016286  -7.36840466  -9.73631468\n",
      " -20.511786  ]\n",
      "Weight after 190000 iteration: [ 22.70165251  -9.68117517   0.3470143    3.21635448  -4.36384631\n",
      "  21.59077468   2.32915713   7.41447976  -7.3718164   -9.73795525\n",
      " -20.51386769]\n",
      "Weight after 195000 iteration: [ 22.70518953  -9.68783885   0.34743475   3.21772674  -4.36535715\n",
      "  21.58571706   2.3300588    7.41824212  -7.37477322  -9.73938905\n",
      " -20.51568923]\n",
      "Weight after 200000 iteration: [ 22.7082858   -9.69369186   0.34779879   3.21890876  -4.36667058\n",
      "  21.58128871   2.33084678   7.42152181  -7.37733659  -9.74064238\n",
      " -20.51728276]\n",
      "Weight after 205000 iteration: [ 22.71099603  -9.6988324    0.34811405   3.21992759  -4.36781303\n",
      "  21.57741176   2.33153545   7.4243813   -7.37955959  -9.74173813\n",
      " -20.51867648]\n",
      "Weight after 210000 iteration: [ 22.71336817  -9.70334686   0.3483871    3.22080628  -4.36880725\n",
      "  21.57401793   2.33213736   7.42687486  -7.38148803  -9.74269622\n",
      " -20.51989521]\n",
      "Weight after 215000 iteration: [ 22.71544424  -9.70731122   0.34862366   3.22156457  -4.36967287\n",
      "  21.57104731   2.33266346   7.4290497   -7.38316146  -9.74353405\n",
      " -20.5209607 ]\n",
      "Weight after 220000 iteration: [ 22.71726104  -9.7107923    0.34882864   3.22221932  -4.37042681\n",
      "  21.56844736   2.33312332   7.43094688  -7.38461405  -9.74426678\n",
      " -20.52189205]\n",
      "Weight after 225000 iteration: [ 22.71885085  -9.71384881   0.34900632   3.22278499  -4.37108372\n",
      "  21.56617204   2.33352528   7.43260212  -7.38587533  -9.74490762\n",
      " -20.522706  ]\n",
      "Weight after 230000 iteration: [ 22.72024191  -9.71653241   0.34916037   3.22327395  -4.37165628\n",
      "  21.56418099   2.33387665   7.43404648  -7.38697082  -9.74546815\n",
      " -20.52341724]\n",
      "Weight after 235000 iteration: [ 22.72145898  -9.71888847   0.34929397   3.22369682  -4.37215546\n",
      "  21.56243882   2.33418379   7.43530703  -7.3879226   -9.74595844\n",
      " -20.52403864]\n",
      "Weight after 240000 iteration: [ 22.72252375  -9.72095688   0.34940988   3.22406273  -4.37259079\n",
      "  21.56091456   2.33445228   7.43640732  -7.38874975  -9.74638731\n",
      " -20.52458146]\n",
      "Weight after 245000 iteration: [ 22.7234552   -9.72277267   0.34951047   3.22437948  -4.37297051\n",
      "  21.55958104   2.33468698   7.43736785  -7.38946879  -9.74676246\n",
      " -20.52505557]\n",
      "Weight after 250000 iteration: [ 22.72426998  -9.72436663   0.34959779   3.22465381  -4.3733018\n",
      "  21.55841448   2.33489214   7.43820649  -7.39009402  -9.74709063\n",
      " -20.52546962]\n",
      "Weight after 255000 iteration: [ 22.72498264  -9.72576583   0.34967362   3.22489151  -4.37359089\n",
      "  21.55739404   2.33507149   7.4389388   -7.39063783  -9.74737771\n",
      " -20.52583116]\n",
      "Weight after 260000 iteration: [ 22.72560594  -9.72699401   0.34973949   3.22509756  -4.37384321\n",
      "  21.55650149   2.33522826   7.43957834  -7.39111094  -9.74762883\n",
      " -20.52614681]\n",
      "Weight after 265000 iteration: [ 22.72615106  -9.72807205   0.34979673   3.22527624  -4.37406346\n",
      "  21.55572084   2.33536531   7.44013692  -7.39152265  -9.74784851\n",
      " -20.52642237]\n",
      "Weight after 270000 iteration: [ 22.72662775  -9.72901828   0.34984648   3.22543126  -4.37425575\n",
      "  21.5550381    2.3354851    7.44062486  -7.39188101  -9.74804067\n",
      " -20.5266629 ]\n",
      "Weight after 275000 iteration: [ 22.7270446   -9.72984879   0.34988975   3.22556579  -4.37442365\n",
      "  21.55444104   2.33558982   7.44105113  -7.392193    -9.74820877\n",
      " -20.52687282]\n",
      "Weight after 280000 iteration: [ 22.72740908  -9.73057773   0.34992738   3.22568259  -4.37457027\n",
      "  21.55391893   2.33568136   7.44142357  -7.3924647   -9.74835582\n",
      " -20.52705602]\n",
      "Weight after 285000 iteration: [ 22.72772775  -9.7312175    0.34996013   3.22578402  -4.37469832\n",
      "  21.55346239   2.33576137   7.441749    -7.39270135  -9.74848444\n",
      " -20.52721587]\n",
      "Weight after 290000 iteration: [ 22.72800636  -9.731779     0.34998863   3.22587215  -4.37481016\n",
      "  21.5530632    2.33583131   7.44203339  -7.39290752  -9.74859695\n",
      " -20.52735533]\n",
      "Weight after 295000 iteration: [ 22.72824992  -9.7322718    0.35001345   3.22594875  -4.37490786\n",
      "  21.55271419   2.33589244   7.44228194  -7.39308717  -9.74869536\n",
      " -20.527477  ]\n",
      "Weight after 300000 iteration: [ 22.72846284  -9.7327043    0.35003506   3.22601533  -4.37499321\n",
      "  21.55240905   2.33594587   7.44249917  -7.39324375  -9.74878144\n",
      " -20.52758313]\n",
      "Weight after 305000 iteration: [ 22.72864895  -9.73308388   0.35005389   3.22607324  -4.37506777\n",
      "  21.55214229   2.33599258   7.44268907  -7.39338024  -9.74885673\n",
      " -20.52767569]\n",
      "Weight after 310000 iteration: [ 22.72881162  -9.73341701   0.3500703    3.22612361  -4.37513292\n",
      "  21.5519091    2.3360334    7.44285507  -7.39349925  -9.74892258\n",
      " -20.52775641]\n",
      "Weight after 315000 iteration: [ 22.7289538   -9.73370937   0.3500846    3.22616744  -4.37518984\n",
      "  21.55170526   2.33606907   7.44300019  -7.39360303  -9.74898017\n",
      " -20.5278268 ]\n",
      "Weight after 320000 iteration: [ 22.72907805  -9.73396595   0.35009707   3.22620559  -4.37523958\n",
      "  21.55152708   2.33610025   7.44312708  -7.39369354  -9.74903055\n",
      " -20.52788818]\n",
      "Weight after 325000 iteration: [ 22.72918664  -9.73419113   0.35010795   3.2262388   -4.37528304\n",
      "  21.55137134   2.33612751   7.44323803  -7.3937725   -9.7490746\n",
      " -20.52794168]\n",
      "Weight after 330000 iteration: [ 22.72928153  -9.73438875   0.35011744   3.22626773  -4.37532103\n",
      "  21.55123522   2.33615132   7.44333505  -7.39384139  -9.74911313\n",
      " -20.52798832]\n",
      "Weight after 335000 iteration: [ 22.72936444  -9.73456218   0.35012572   3.22629292  -4.37535423\n",
      "  21.55111626   2.33617214   7.44341989  -7.39390151  -9.74914682\n",
      " -20.52802898]\n",
      "Weight after 340000 iteration: [ 22.72943689  -9.73471439   0.35013295   3.22631487  -4.37538324\n",
      "  21.5510123    2.33619033   7.44349409  -7.39395397  -9.74917629\n",
      " -20.52806441]\n",
      "Weight after 345000 iteration: [ 22.72950018  -9.73484798   0.35013926   3.226334    -4.3754086\n",
      "  21.55092145   2.33620622   7.44355899  -7.39399977  -9.74920206\n",
      " -20.52809528]\n",
      "Weight after 350000 iteration: [ 22.72955548  -9.73496521   0.35014477   3.22635067  -4.37543076\n",
      "  21.55084206   2.33622011   7.44361576  -7.39403974  -9.74922459\n",
      " -20.52812218]\n",
      "Weight after 355000 iteration: [ 22.72960379  -9.7350681    0.35014959   3.2263652   -4.37545013\n",
      "  21.55077269   2.33623225   7.44366541  -7.39407465  -9.74924429\n",
      " -20.52814562]\n",
      "Weight after 360000 iteration: [ 22.72964599  -9.7351584    0.35015379   3.22637788  -4.37546706\n",
      "  21.55071208   2.33624286   7.44370884  -7.39410513  -9.74926152\n",
      " -20.52816604]\n",
      "Weight after 365000 iteration: [ 22.72968286  -9.73523766   0.35015747   3.22638893  -4.37548186\n",
      "  21.55065912   2.33625213   7.44374684  -7.39413175  -9.74927659\n",
      " -20.52818383]\n",
      "Weight after 370000 iteration: [ 22.72971506  -9.73530721   0.35016068   3.22639858  -4.3754948\n",
      "  21.55061285   2.33626023   7.44378008  -7.39415499  -9.74928976\n",
      " -20.52819931]\n",
      "Weight after 375000 iteration: [ 22.72974318  -9.73536826   0.35016349   3.22640699  -4.37550611\n",
      "  21.55057243   2.3362673    7.44380916  -7.3941753   -9.74930127\n",
      " -20.5282128 ]\n",
      "Weight after 380000 iteration: [ 22.72976774  -9.73542184   0.35016595   3.22641433  -4.375516\n",
      "  21.55053712   2.33627348   7.44383461  -7.39419304  -9.74931134\n",
      " -20.52822455]\n",
      "Weight after 385000 iteration: [ 22.72978919  -9.73546887   0.3501681    3.22642074  -4.37552464\n",
      "  21.55050627   2.33627889   7.44385688  -7.39420854  -9.74932015\n",
      " -20.52823477]\n",
      "Weight after 390000 iteration: [ 22.72980792  -9.73551014   0.35016998   3.22642633  -4.37553219\n",
      "  21.55047933   2.33628361   7.44387636  -7.39422209  -9.74932784\n",
      " -20.52824367]\n",
      "Weight after 395000 iteration: [ 22.72982428  -9.73554637   0.35017162   3.22643122  -4.3755388\n",
      "  21.55045579   2.33628773   7.44389341  -7.39423392  -9.74933457\n",
      " -20.52825142]\n",
      "Weight after 400000 iteration: [ 22.72983856  -9.73557817   0.35017306   3.22643548  -4.37554457\n",
      "  21.55043523   2.33629133   7.44390832  -7.39424427  -9.74934045\n",
      " -20.52825816]\n",
      "Weight after 405000 iteration: [ 22.72985103  -9.73560608   0.35017432   3.2264392   -4.37554962\n",
      "  21.55041728   2.33629448   7.44392138  -7.39425331  -9.74934559\n",
      " -20.52826403]\n",
      "Weight after 410000 iteration: [ 22.72986191  -9.73563058   0.35017542   3.22644246  -4.37555403\n",
      "  21.5504016    2.33629723   7.44393281  -7.39426121  -9.74935009\n",
      " -20.52826913]\n",
      "Weight after 415000 iteration: [ 22.72987142  -9.73565209   0.35017639   3.2264453   -4.37555789\n",
      "  21.5503879    2.33629963   7.44394281  -7.39426812  -9.74935402\n",
      " -20.52827357]\n",
      "Weight after 420000 iteration: [ 22.72987971  -9.73567097   0.35017723   3.22644778  -4.37556126\n",
      "  21.55037595   2.33630172   7.44395156  -7.39427416  -9.74935745\n",
      " -20.52827744]\n",
      "Weight after 425000 iteration: [ 22.72988696  -9.73568754   0.35017797   3.22644995  -4.37556421\n",
      "  21.5503655    2.33630356   7.44395922  -7.39427944  -9.74936046\n",
      " -20.52828079]\n",
      "Weight after 430000 iteration: [ 22.72989328  -9.73570208   0.35017862   3.22645184  -4.37556679\n",
      "  21.55035639   2.33630516   7.44396592  -7.39428406  -9.74936308\n",
      " -20.52828371]\n",
      "Weight after 435000 iteration: [ 22.7298988   -9.73571485   0.35017919   3.2264535   -4.37556904\n",
      "  21.55034842   2.33630655   7.44397179  -7.39428809  -9.74936537\n",
      " -20.52828625]\n",
      "Weight after 440000 iteration: [ 22.72990361  -9.73572607   0.35017969   3.22645495  -4.37557101\n",
      "  21.55034147   2.33630777   7.44397693  -7.39429162  -9.74936738\n",
      " -20.52828846]\n",
      "Weight after 445000 iteration: [ 22.72990781  -9.73573591   0.35018012   3.22645621  -4.37557274\n",
      "  21.5503354    2.33630884   7.44398143  -7.39429471  -9.74936913\n",
      " -20.52829038]\n",
      "Weight after 450000 iteration: [ 22.72991148  -9.73574455   0.3501805    3.22645732  -4.37557424\n",
      "  21.55033011   2.33630977   7.44398536  -7.39429741  -9.74937066\n",
      " -20.52829205]\n",
      "Weight after 455000 iteration: [ 22.72991468  -9.73575213   0.35018084   3.22645829  -4.37557556\n",
      "  21.55032548   2.33631058   7.44398881  -7.39429977  -9.749372\n",
      " -20.5282935 ]\n",
      "Weight after 460000 iteration: [ 22.72991747  -9.73575879   0.35018113   3.22645913  -4.37557671\n",
      "  21.55032145   2.33631129   7.44399183  -7.39430184  -9.74937317\n",
      " -20.52829475]\n",
      "Weight after 465000 iteration: [ 22.72991991  -9.73576464   0.35018139   3.22645987  -4.37557772\n",
      "  21.55031792   2.33631191   7.44399447  -7.39430365  -9.74937419\n",
      " -20.52829585]\n",
      "Weight after 470000 iteration: [ 22.72992203  -9.73576977   0.35018162   3.22646052  -4.3755786\n",
      "  21.55031485   2.33631246   7.44399678  -7.39430523  -9.74937508\n",
      " -20.5282968 ]\n",
      "Weight after 475000 iteration: [ 22.72992389  -9.73577428   0.35018181   3.22646109  -4.37557937\n",
      "  21.55031216   2.33631293   7.4439988   -7.39430661  -9.74937586\n",
      " -20.52829762]\n",
      "Weight after 480000 iteration: [ 22.72992551  -9.73577824   0.35018199   3.22646158  -4.37558004\n",
      "  21.55030982   2.33631334   7.44400058  -7.39430782  -9.74937654\n",
      " -20.52829834]\n",
      "Weight after 485000 iteration: [ 22.72992692  -9.73578171   0.35018214   3.22646201  -4.37558063\n",
      "  21.55030778   2.3363137    7.44400213  -7.39430888  -9.74937714\n",
      " -20.52829896]\n",
      "Weight after 490000 iteration: [ 22.72992815  -9.73578477   0.35018227   3.22646239  -4.37558114\n",
      "  21.55030599   2.33631402   7.44400349  -7.3943098   -9.74937766\n",
      " -20.5282995 ]\n",
      "Weight after 495000 iteration: [ 22.72992922  -9.73578745   0.35018239   3.22646272  -4.37558159\n",
      "  21.55030443   2.33631429   7.44400468  -7.39431061  -9.74937812\n",
      " -20.52829996]\n"
     ]
    }
   ],
   "source": [
    "opt_w = np_solve_via_gradient_descent(train_X_new, train_y, niter=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22.72993016,  -9.7357898 ,   0.35018249,   3.22646301,\n",
       "        -4.37558198,  21.55030308,   2.33631453,   7.44400572,\n",
       "        -7.39431132,  -9.74937851, -20.52830037])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost: 12.316321777609623\n"
     ]
    }
   ],
   "source": [
    "print(\"Training cost:\", np_cost_vectorized(opt_w, train_X_new, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost: 12.316321777609623\n"
     ]
    }
   ],
   "source": [
    "print(\"Training cost:\", np_cost_vectorized(opt_w, train_X_new, train_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
