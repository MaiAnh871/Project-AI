{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use simple data of mobile price range classifier. The dataset consists of 20 features and we need to predict the price range in which phone lies. These ranges are divided into 4 classes.\\\n",
    "\\\n",
    "'battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
    "'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height','px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g','touch_screen', 'wifi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before feeding data to our neural network we need it in a specific way so we need to process it accordingly. The preprocessing of data depends on the type of data. Here we will discuss how to handle tabular data and in later tutorials, we will handle image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1004</td>\n",
       "      <td>1654</td>\n",
       "      <td>1067</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>381</td>\n",
       "      <td>1018</td>\n",
       "      <td>3220</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>1149</td>\n",
       "      <td>700</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>836</td>\n",
       "      <td>1099</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1137</td>\n",
       "      <td>1224</td>\n",
       "      <td>513</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "5           1859     0          0.5         1   3       0          22    0.7   \n",
       "6           1821     0          1.7         0   4       1          10    0.8   \n",
       "7           1954     0          0.5         1   0       0          24    0.8   \n",
       "8           1445     1          0.5         0   0       0          53    0.7   \n",
       "9            509     1          0.6         1   2       1           9    0.1   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "5        164        1  ...       1004      1654  1067    17     1         10   \n",
       "6        139        8  ...        381      1018  3220    13     8         18   \n",
       "7        187        4  ...        512      1149   700    16     3          5   \n",
       "8        174        7  ...        386       836  1099    17     1         20   \n",
       "9         93        5  ...       1137      1224   513    19    10         12   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "5        1             0     0            1  \n",
       "6        1             0     1            3  \n",
       "7        1             1     1            0  \n",
       "8        1             0     0            0  \n",
       "9        1             0     0            0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#dataset import\n",
    "dataset = pd.read_csv('train.csv') #You need to change #directory accordingly\n",
    "dataset.head(10) #Return 10 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing pandas dataframe to numpy array\n",
    "X = dataset.iloc[:,:20].values\n",
    "y = dataset.iloc[:,20:21].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is used to normalize the data. Normalization is a technique used to change the values of an array to a common scale, without distorting differences in the ranges of values. It is an important step and you can check the difference in accuracies on our dataset by removing this step. It is mainly required in case the dataset features vary a lot as in our case the value of battery power is in the 1000â€™s and clock speed is less than 3. So if we feed unnormalized data to the neural network, the gradients will change differently for every column and thus the learning will oscillate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to one hot encode the classes. One hot encoding is a process to convert integer classes into binary values. Consider an example, letâ€™s say there are 3 classes in our dataset namely 1,2 and 3. Now we cannot directly feed this to neural network so we convert it in the form:\n",
    "\n",
    "1- 1 0 0\n",
    "\n",
    "2- 0 1 0\n",
    "\n",
    "3- 0 0 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is one unique binary value for the class. The new array formed will be of shape (n, number of classes), where n is the number of samples in our dataset. We can do this using simple function by sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(y).toarray()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, it is better to split data into training and testing data. Training data is the data on which we will train our neural network. Test data is used to check our trained neural network. This data is totally new for our neural network and if the neural network performs well on this dataset, it shows that there is no overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a simple tool for constructing a neural network. It is a high-level framework based on tensorflow, theano or cntk backends.\n",
    "\n",
    "In our dataset, the input is of 20 values and output is of 4 values. So the input and output layer is of 20 and 4 dimensions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=20, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our neural network, we are using two hidden layers of 16 and 12 dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to specify the loss function and the optimizer. It is done using compile function in keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here loss is cross entropy loss as discussed earlier. Categorical_crossentropy specifies that we have multiple classes. The optimizer is Adam. Metrics is used to specify the way we want to judge the performance of our neural network. Here we have specified it to accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training step is simple in keras. model.fit is used to train it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 2ms/step - loss: 1.5386 - accuracy: 0.2544\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.4205 - accuracy: 0.2906\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.3601 - accuracy: 0.3294\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.3182 - accuracy: 0.3806\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.2764 - accuracy: 0.4233\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.2275 - accuracy: 0.4661\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.1676 - accuracy: 0.5117\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.0972 - accuracy: 0.5417\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.0211 - accuracy: 0.5717\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.6056\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8623 - accuracy: 0.6461\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7896 - accuracy: 0.6772\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7249 - accuracy: 0.7150\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.7494\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.7889\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.8128\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.8411\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.8422\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8678\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8700\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8867\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8972\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8983\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.9089\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.9150\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.9167\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.9217\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.9250\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2576 - accuracy: 0.9317\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9322\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2364 - accuracy: 0.9367\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9422\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.9433\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9433\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2016 - accuracy: 0.9461\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9517\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9522\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9533\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9528\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9533\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9561\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.9567\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9567\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9589\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9567\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9606\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9639\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9639\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9661\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9683\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9678\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9678\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9678\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9678\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.9711\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9711\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.9711\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9700\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9717\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.9711\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9756\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9728\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9767\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.9761\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9789\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9733\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9789\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9761\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9800\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9811\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9789\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9811\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9806\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9822\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9833\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9817\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9833\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9833\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9822\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9850\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9839\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9844\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9878\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9883\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0601 - accuracy: 0.9883\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.9872\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9861\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0585 - accuracy: 0.9872\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9883\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9911\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9894\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9872\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9883\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9883\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9889\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9911\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9911\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, the dataset is very big and we cannot fit complete data at once so we use batch size. This divides our data into batches each of size equal to batch_size. Now only this number of samples will be loaded into memory and processed. Once we are done with one batch it is flushed from memory and the next batch will be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the modelâ€™s performance on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is inverse one hot encoding process. We will get integer labels using this step. We can predict on test data using a simple method of keras, model.predict(). It will take the test data as input and will return the prediction outputs as softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 94.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use test data as validation data and can check the accuracies after every epoch. This will give us an insight into overfitting at the time of training only and we can take steps before the completion of all epochs. We can do this by changing fit function as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9906 - val_loss: 0.1611 - val_accuracy: 0.9500\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9922 - val_loss: 0.1563 - val_accuracy: 0.9500\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9933 - val_loss: 0.1511 - val_accuracy: 0.9550\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9906 - val_loss: 0.1534 - val_accuracy: 0.9450\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9928 - val_loss: 0.1528 - val_accuracy: 0.9600\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9933 - val_loss: 0.1532 - val_accuracy: 0.9550\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9911 - val_loss: 0.1608 - val_accuracy: 0.9400\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9944 - val_loss: 0.1520 - val_accuracy: 0.9550\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9933 - val_loss: 0.1542 - val_accuracy: 0.9500\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9939 - val_loss: 0.1478 - val_accuracy: 0.9500\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9944 - val_loss: 0.1496 - val_accuracy: 0.9600\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9944 - val_loss: 0.1532 - val_accuracy: 0.9600\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9939 - val_loss: 0.1519 - val_accuracy: 0.9550\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9939 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9967 - val_loss: 0.1556 - val_accuracy: 0.9550\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9944 - val_loss: 0.1470 - val_accuracy: 0.9550\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9956 - val_loss: 0.1545 - val_accuracy: 0.9550\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9944 - val_loss: 0.1505 - val_accuracy: 0.9600\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9956 - val_loss: 0.1512 - val_accuracy: 0.9550\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9961 - val_loss: 0.1552 - val_accuracy: 0.9600\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9928 - val_loss: 0.1502 - val_accuracy: 0.9600\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9956 - val_loss: 0.1536 - val_accuracy: 0.9550\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9972 - val_loss: 0.1555 - val_accuracy: 0.9600\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9967 - val_loss: 0.1541 - val_accuracy: 0.9550\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9967 - val_loss: 0.1531 - val_accuracy: 0.9500\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9950 - val_loss: 0.1529 - val_accuracy: 0.9600\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9967 - val_loss: 0.1519 - val_accuracy: 0.9550\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9956 - val_loss: 0.1507 - val_accuracy: 0.9550\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9978 - val_loss: 0.1583 - val_accuracy: 0.9500\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 0.9950 - val_loss: 0.1574 - val_accuracy: 0.9500\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0325 - accuracy: 0.9944 - val_loss: 0.1589 - val_accuracy: 0.9550\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9967 - val_loss: 0.1537 - val_accuracy: 0.9550\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9978 - val_loss: 0.1593 - val_accuracy: 0.9550\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9978 - val_loss: 0.1546 - val_accuracy: 0.9550\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9972 - val_loss: 0.1494 - val_accuracy: 0.9500\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 0.9972 - val_loss: 0.1542 - val_accuracy: 0.9550\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9961 - val_loss: 0.1573 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9978 - val_loss: 0.1541 - val_accuracy: 0.9550\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9983 - val_loss: 0.1612 - val_accuracy: 0.9550\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9983 - val_loss: 0.1504 - val_accuracy: 0.9600\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9983 - val_loss: 0.1475 - val_accuracy: 0.9550\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9983 - val_loss: 0.1556 - val_accuracy: 0.9600\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9989 - val_loss: 0.1520 - val_accuracy: 0.9550\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9989 - val_loss: 0.1619 - val_accuracy: 0.9550\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9550\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9983 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9983 - val_loss: 0.1533 - val_accuracy: 0.9550\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9972 - val_loss: 0.1625 - val_accuracy: 0.9600\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9983 - val_loss: 0.1656 - val_accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9994 - val_loss: 0.1546 - val_accuracy: 0.9550\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9989 - val_loss: 0.1617 - val_accuracy: 0.9550\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 0.9983 - val_loss: 0.1553 - val_accuracy: 0.9600\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9972 - val_loss: 0.1582 - val_accuracy: 0.9550\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9989 - val_loss: 0.1553 - val_accuracy: 0.9600\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9600\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9989 - val_loss: 0.1570 - val_accuracy: 0.9600\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9994 - val_loss: 0.1604 - val_accuracy: 0.9600\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9994 - val_loss: 0.1598 - val_accuracy: 0.9600\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9994 - val_loss: 0.1570 - val_accuracy: 0.9600\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9994 - val_loss: 0.1594 - val_accuracy: 0.9600\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9983 - val_loss: 0.1571 - val_accuracy: 0.9600\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9983 - val_loss: 0.1695 - val_accuracy: 0.9500\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9994 - val_loss: 0.1605 - val_accuracy: 0.9550\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9600\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9994 - val_loss: 0.1641 - val_accuracy: 0.9600\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9550\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9989 - val_loss: 0.1604 - val_accuracy: 0.9600\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9989 - val_loss: 0.1731 - val_accuracy: 0.9500\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9500\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9600\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9994 - val_loss: 0.1638 - val_accuracy: 0.9500\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9994 - val_loss: 0.1624 - val_accuracy: 0.9550\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9600\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9994 - val_loss: 0.1658 - val_accuracy: 0.9500\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9550\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9550\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9600\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9989 - val_loss: 0.1658 - val_accuracy: 0.9550\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9600\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9994 - val_loss: 0.1683 - val_accuracy: 0.9500\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9500\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9450\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9994 - val_loss: 0.1716 - val_accuracy: 0.9600\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9500\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9450\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9550\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9500\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9450\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9500\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9450\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9983 - val_loss: 0.1800 - val_accuracy: 0.9450\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9500\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9500\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9450\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9450\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9550\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9550\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9450\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is working fine. Now we will visualize training and validation losses and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\STUDY\\20212\\AI\\Project-AI\\Part2\\Mobile-Price-Range-Classification.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/STUDY/20212/AI/Project-AI/Part2/Mobile-Price-Range-Classification.ipynb#ch0000027?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history1\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/STUDY/20212/AI/Project-AI/Part2/Mobile-Price-Range-Classification.ipynb#ch0000027?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history1\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/STUDY/20212/AI/Project-AI/Part2/Mobile-Price-Range-Classification.ipynb#ch0000027?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mModel accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
