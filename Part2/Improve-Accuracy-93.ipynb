{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Essential Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IBXRF3JsTKP1",
        "outputId": "560073c5-f44d-494e-9021-9921158a1b06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Nacionality</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>171</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>9254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>160.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>9070</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>9773</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-3.12</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>8014</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>9991</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>133.1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9500</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>142.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>14.345000</td>\n",
              "      <td>0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-4.06</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>9254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>119.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-4.06</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>137.0</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>14.142857</td>\n",
              "      <td>0</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>3.51</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Marital status  Application mode  Application order  Course  \\\n",
              "0               1                17                  5     171   \n",
              "1               1                15                  1    9254   \n",
              "2               1                 1                  5    9070   \n",
              "3               1                17                  2    9773   \n",
              "4               2                39                  1    8014   \n",
              "5               2                39                  1    9991   \n",
              "6               1                 1                  1    9500   \n",
              "7               1                18                  4    9254   \n",
              "8               1                 1                  3    9238   \n",
              "9               1                 1                  1    9238   \n",
              "\n",
              "   Daytime/evening attendance  Previous qualification  \\\n",
              "0                           1                       1   \n",
              "1                           1                       1   \n",
              "2                           1                       1   \n",
              "3                           1                       1   \n",
              "4                           0                       1   \n",
              "5                           0                      19   \n",
              "6                           1                       1   \n",
              "7                           1                       1   \n",
              "8                           1                       1   \n",
              "9                           1                       1   \n",
              "\n",
              "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
              "0                           122.0            1                      19   \n",
              "1                           160.0            1                       1   \n",
              "2                           122.0            1                      37   \n",
              "3                           122.0            1                      38   \n",
              "4                           100.0            1                      37   \n",
              "5                           133.1            1                      37   \n",
              "6                           142.0            1                      19   \n",
              "7                           119.0            1                      37   \n",
              "8                           137.0           62                       1   \n",
              "9                           138.0            1                       1   \n",
              "\n",
              "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
              "0                      12  ...                                    0   \n",
              "1                       3  ...                                    0   \n",
              "2                      37  ...                                    0   \n",
              "3                      37  ...                                    0   \n",
              "4                      38  ...                                    0   \n",
              "5                      37  ...                                    0   \n",
              "6                      38  ...                                    0   \n",
              "7                      37  ...                                    0   \n",
              "8                       1  ...                                    0   \n",
              "9                      19  ...                                    0   \n",
              "\n",
              "   Curricular units 2nd sem (enrolled)  \\\n",
              "0                                    0   \n",
              "1                                    6   \n",
              "2                                    6   \n",
              "3                                    6   \n",
              "4                                    6   \n",
              "5                                    5   \n",
              "6                                    8   \n",
              "7                                    5   \n",
              "8                                    6   \n",
              "9                                    6   \n",
              "\n",
              "   Curricular units 2nd sem (evaluations)  \\\n",
              "0                                       0   \n",
              "1                                       6   \n",
              "2                                       0   \n",
              "3                                      10   \n",
              "4                                       6   \n",
              "5                                      17   \n",
              "6                                       8   \n",
              "7                                       5   \n",
              "8                                       7   \n",
              "9                                      14   \n",
              "\n",
              "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "0                                    0                          0.000000   \n",
              "1                                    6                         13.666667   \n",
              "2                                    0                          0.000000   \n",
              "3                                    5                         12.400000   \n",
              "4                                    6                         13.000000   \n",
              "5                                    5                         11.500000   \n",
              "6                                    8                         14.345000   \n",
              "7                                    0                          0.000000   \n",
              "8                                    6                         14.142857   \n",
              "9                                    2                         13.500000   \n",
              "\n",
              "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "0                                               0               10.8   \n",
              "1                                               0               13.9   \n",
              "2                                               0               10.8   \n",
              "3                                               0                9.4   \n",
              "4                                               0               13.9   \n",
              "5                                               5               16.2   \n",
              "6                                               0               15.5   \n",
              "7                                               0               15.5   \n",
              "8                                               0               16.2   \n",
              "9                                               0                8.9   \n",
              "\n",
              "   Inflation rate   GDP    Target  \n",
              "0             1.4  1.74   Dropout  \n",
              "1            -0.3  0.79  Graduate  \n",
              "2             1.4  1.74   Dropout  \n",
              "3            -0.8 -3.12  Graduate  \n",
              "4            -0.3  0.79  Graduate  \n",
              "5             0.3 -0.92  Graduate  \n",
              "6             2.8 -4.06  Graduate  \n",
              "7             2.8 -4.06   Dropout  \n",
              "8             0.3 -0.92  Graduate  \n",
              "9             1.4  3.51   Dropout  \n",
              "\n",
              "[10 rows x 37 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#dataset import\n",
        "dataset = pd.read_csv('data.csv') #You need to change #directory accordingly\n",
        "dataset.head(10) #Return 10 rows of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-buQfLLrTUuc",
        "outputId": "a87b4f82-1e11-4e37-e6d5-754c611f9cc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Graduate    2209\n",
              "Dropout     1421\n",
              "Enrolled     794\n",
              "Name: Target, dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['Target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrolQem-TV34",
        "outputId": "bacd12e5-bbe9-4863-912f-d8c57c23e42b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4424, 36)\n",
            "(4424, 1)\n"
          ]
        }
      ],
      "source": [
        "#Changing pandas dataframe to numpy array\n",
        "X = dataset.iloc[:,:36].values\n",
        "y = dataset.iloc[:,36:37].values\n",
        "y[10:40]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KlGwVDaATWqX"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "import math\n",
        "\n",
        "bordersmote = SMOTEENN()\n",
        "X, y = SMOTEENN().fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LjzwqovUI80",
        "outputId": "841e1033-a2f5-4fdd-f979-852106897075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['Dropout', 'Enrolled', 'Graduate'], dtype=object),\n",
              " array([1042, 1437,  743], dtype=int64))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique = np.unique(y, return_counts = True)\n",
        "unique\n",
        "# (array(['Dropout', 'Enrolled', 'Graduate'], dtype=object),\n",
        "# array([1020, 1416,  739], dtype=int64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One - Hot Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYJucrgfTayV",
        "outputId": "354fa819-1881-4224-e872-27d7c4163733"
      },
      "outputs": [],
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "# dummy_y[10:40]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DXMxCBmrTb7t"
      },
      "outputs": [],
      "source": [
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "poly_features = PolynomialFeatures(degree = 2, include_bias = False)\n",
        "X = poly_features.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zNTX22OkTnnA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y4Uk8Yh7TpU3"
      },
      "outputs": [],
      "source": [
        "#Dependencies\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "# Neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units = 3, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cgYoymXmTuiE"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-c-Ns3ZTwAU",
        "outputId": "bc00ef59-d064-4d2c-e141-b8dfa3521921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "91/91 [==============================] - 4s 29ms/step - loss: 0.8040 - accuracy: 0.7016 - val_loss: 0.4477 - val_accuracy: 0.8142\n",
            "Epoch 2/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.4016 - accuracy: 0.8634 - val_loss: 0.3731 - val_accuracy: 0.8576\n",
            "Epoch 3/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.2950 - accuracy: 0.8979 - val_loss: 0.4080 - val_accuracy: 0.8576\n",
            "Epoch 4/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.2175 - accuracy: 0.9296 - val_loss: 0.3449 - val_accuracy: 0.8731\n",
            "Epoch 5/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.1937 - accuracy: 0.9331 - val_loss: 0.2755 - val_accuracy: 0.9133\n",
            "Epoch 6/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.1248 - accuracy: 0.9590 - val_loss: 0.3136 - val_accuracy: 0.9071\n",
            "Epoch 7/300\n",
            "91/91 [==============================] - 2s 21ms/step - loss: 0.0980 - accuracy: 0.9679 - val_loss: 0.2664 - val_accuracy: 0.9195\n",
            "Epoch 8/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.1036 - accuracy: 0.9686 - val_loss: 0.2737 - val_accuracy: 0.9288\n",
            "Epoch 9/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.1210 - accuracy: 0.9631 - val_loss: 0.3412 - val_accuracy: 0.9226\n",
            "Epoch 10/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0697 - accuracy: 0.9755 - val_loss: 0.5061 - val_accuracy: 0.9009\n",
            "Epoch 11/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0800 - accuracy: 0.9748 - val_loss: 0.3522 - val_accuracy: 0.9071\n",
            "Epoch 12/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0913 - accuracy: 0.9738 - val_loss: 0.4024 - val_accuracy: 0.9226\n",
            "Epoch 13/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0592 - accuracy: 0.9814 - val_loss: 0.4092 - val_accuracy: 0.9226\n",
            "Epoch 14/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0597 - accuracy: 0.9817 - val_loss: 0.5202 - val_accuracy: 0.9195\n",
            "Epoch 15/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0721 - accuracy: 0.9765 - val_loss: 0.4548 - val_accuracy: 0.9195\n",
            "Epoch 16/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0804 - accuracy: 0.9793 - val_loss: 0.4159 - val_accuracy: 0.9040\n",
            "Epoch 17/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0577 - accuracy: 0.9828 - val_loss: 0.5180 - val_accuracy: 0.9257\n",
            "Epoch 18/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0376 - accuracy: 0.9883 - val_loss: 0.2241 - val_accuracy: 0.9505\n",
            "Epoch 19/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0639 - accuracy: 0.9828 - val_loss: 0.4832 - val_accuracy: 0.9195\n",
            "Epoch 20/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0972 - accuracy: 0.9762 - val_loss: 0.5780 - val_accuracy: 0.9133\n",
            "Epoch 21/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0585 - accuracy: 0.9828 - val_loss: 0.4264 - val_accuracy: 0.9257\n",
            "Epoch 22/300\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.0583 - accuracy: 0.9838 - val_loss: 0.2918 - val_accuracy: 0.9133\n",
            "Epoch 23/300\n",
            "91/91 [==============================] - 2s 21ms/step - loss: 0.0699 - accuracy: 0.9810 - val_loss: 0.3658 - val_accuracy: 0.9257\n",
            "Epoch 24/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0478 - accuracy: 0.9886 - val_loss: 0.3485 - val_accuracy: 0.9257\n",
            "Epoch 25/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0679 - accuracy: 0.9803 - val_loss: 0.2495 - val_accuracy: 0.9319\n",
            "Epoch 26/300\n",
            "91/91 [==============================] - 2s 21ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.4740 - val_accuracy: 0.9257\n",
            "Epoch 27/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0320 - accuracy: 0.9931 - val_loss: 0.3576 - val_accuracy: 0.9288\n",
            "Epoch 28/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0342 - accuracy: 0.9914 - val_loss: 0.6006 - val_accuracy: 0.9009\n",
            "Epoch 29/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0737 - accuracy: 0.9803 - val_loss: 0.4301 - val_accuracy: 0.9102\n",
            "Epoch 30/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 0.4915 - val_accuracy: 0.9226\n",
            "Epoch 31/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0553 - accuracy: 0.9893 - val_loss: 0.3421 - val_accuracy: 0.9381\n",
            "Epoch 32/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0413 - accuracy: 0.9900 - val_loss: 0.4791 - val_accuracy: 0.9350\n",
            "Epoch 33/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.6308 - val_accuracy: 0.9381\n",
            "Epoch 34/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.3202 - val_accuracy: 0.9381\n",
            "Epoch 35/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0264 - accuracy: 0.9972 - val_loss: 0.6125 - val_accuracy: 0.9319\n",
            "Epoch 36/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0362 - accuracy: 0.9921 - val_loss: 0.8473 - val_accuracy: 0.9009\n",
            "Epoch 37/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0564 - accuracy: 0.9872 - val_loss: 0.6958 - val_accuracy: 0.9133\n",
            "Epoch 38/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 0.5402 - val_accuracy: 0.9288\n",
            "Epoch 39/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0486 - accuracy: 0.9883 - val_loss: 0.2362 - val_accuracy: 0.9381\n",
            "Epoch 40/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0648 - accuracy: 0.9817 - val_loss: 0.2860 - val_accuracy: 0.9350\n",
            "Epoch 41/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0438 - accuracy: 0.9924 - val_loss: 0.3666 - val_accuracy: 0.9257\n",
            "Epoch 42/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0448 - accuracy: 0.9903 - val_loss: 0.5318 - val_accuracy: 0.9288\n",
            "Epoch 43/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0275 - accuracy: 0.9928 - val_loss: 0.7457 - val_accuracy: 0.9350\n",
            "Epoch 44/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0826 - accuracy: 0.9900 - val_loss: 0.5525 - val_accuracy: 0.9288\n",
            "Epoch 45/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0576 - accuracy: 0.9910 - val_loss: 0.4450 - val_accuracy: 0.9257\n",
            "Epoch 46/300\n",
            "91/91 [==============================] - 2s 21ms/step - loss: 0.0849 - accuracy: 0.9862 - val_loss: 0.3309 - val_accuracy: 0.9226\n",
            "Epoch 47/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.6795 - val_accuracy: 0.9226\n",
            "Epoch 48/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.5518 - val_accuracy: 0.9164\n",
            "Epoch 49/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0266 - accuracy: 0.9938 - val_loss: 0.6130 - val_accuracy: 0.9195\n",
            "Epoch 50/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.8886 - val_accuracy: 0.9350\n",
            "Epoch 51/300\n",
            "91/91 [==============================] - 2s 21ms/step - loss: 0.0372 - accuracy: 0.9900 - val_loss: 0.5830 - val_accuracy: 0.9319\n",
            "Epoch 52/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.4881 - val_accuracy: 0.9412\n",
            "Epoch 53/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.8362 - val_accuracy: 0.9257\n",
            "Epoch 54/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.6912 - val_accuracy: 0.9381\n",
            "Epoch 55/300\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.1591 - accuracy: 0.9759 - val_loss: 0.3451 - val_accuracy: 0.9164\n",
            "Epoch 56/300\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.0954 - accuracy: 0.9817 - val_loss: 0.3971 - val_accuracy: 0.9443\n",
            "Epoch 57/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0575 - accuracy: 0.9900 - val_loss: 0.4331 - val_accuracy: 0.9443\n",
            "Epoch 58/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0604 - accuracy: 0.9886 - val_loss: 0.3568 - val_accuracy: 0.9319\n",
            "Epoch 59/300\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.0528 - accuracy: 0.9876 - val_loss: 0.2822 - val_accuracy: 0.9412\n",
            "Epoch 60/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0215 - accuracy: 0.9952 - val_loss: 0.6014 - val_accuracy: 0.9102\n",
            "Epoch 61/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.6001 - val_accuracy: 0.9319\n",
            "Epoch 62/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.5660 - val_accuracy: 0.9474\n",
            "Epoch 63/300\n",
            "91/91 [==============================] - 2s 20ms/step - loss: 0.0280 - accuracy: 0.9948 - val_loss: 0.4744 - val_accuracy: 0.9350\n",
            "Epoch 64/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.6446 - val_accuracy: 0.9350\n",
            "Epoch 65/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0301 - accuracy: 0.9931 - val_loss: 0.5842 - val_accuracy: 0.9412\n",
            "Epoch 66/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0254 - accuracy: 0.9966 - val_loss: 0.4189 - val_accuracy: 0.9257\n",
            "Epoch 67/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0431 - accuracy: 0.9952 - val_loss: 0.3762 - val_accuracy: 0.9536\n",
            "Epoch 68/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0675 - accuracy: 0.9897 - val_loss: 0.2400 - val_accuracy: 0.9412\n",
            "Epoch 69/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0313 - accuracy: 0.9941 - val_loss: 0.6089 - val_accuracy: 0.9226\n",
            "Epoch 70/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0581 - accuracy: 0.9976 - val_loss: 0.3921 - val_accuracy: 0.9257\n",
            "Epoch 71/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0727 - accuracy: 0.9952 - val_loss: 0.6362 - val_accuracy: 0.9195\n",
            "Epoch 72/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0202 - accuracy: 0.9952 - val_loss: 0.4410 - val_accuracy: 0.9350\n",
            "Epoch 73/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0195 - accuracy: 0.9962 - val_loss: 0.4581 - val_accuracy: 0.9319\n",
            "Epoch 74/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.4482 - val_accuracy: 0.9412\n",
            "Epoch 75/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0262 - accuracy: 0.9969 - val_loss: 0.4462 - val_accuracy: 0.9288\n",
            "Epoch 76/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0424 - accuracy: 0.9941 - val_loss: 0.3874 - val_accuracy: 0.9350\n",
            "Epoch 77/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0834 - accuracy: 0.9910 - val_loss: 0.4527 - val_accuracy: 0.9257\n",
            "Epoch 78/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0479 - accuracy: 0.9931 - val_loss: 0.7032 - val_accuracy: 0.9381\n",
            "Epoch 79/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0192 - accuracy: 0.9962 - val_loss: 0.6565 - val_accuracy: 0.9350\n",
            "Epoch 80/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0277 - accuracy: 0.9969 - val_loss: 0.4402 - val_accuracy: 0.9443\n",
            "Epoch 81/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0267 - accuracy: 0.9938 - val_loss: 0.5183 - val_accuracy: 0.9226\n",
            "Epoch 82/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.9741 - val_accuracy: 0.9257\n",
            "Epoch 83/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.8845 - val_accuracy: 0.9350\n",
            "Epoch 84/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0427 - accuracy: 0.9945 - val_loss: 0.6331 - val_accuracy: 0.9381\n",
            "Epoch 85/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0288 - accuracy: 0.9952 - val_loss: 0.7118 - val_accuracy: 0.9288\n",
            "Epoch 86/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.3183 - val_accuracy: 0.9319\n",
            "Epoch 87/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0385 - accuracy: 0.9945 - val_loss: 0.5891 - val_accuracy: 0.9443\n",
            "Epoch 88/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.9641 - val_accuracy: 0.9474\n",
            "Epoch 89/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0187 - accuracy: 0.9983 - val_loss: 1.0213 - val_accuracy: 0.9443\n",
            "Epoch 90/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4082 - val_accuracy: 0.9443\n",
            "Epoch 91/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0257 - accuracy: 0.9959 - val_loss: 0.9430 - val_accuracy: 0.9319\n",
            "Epoch 92/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0224 - accuracy: 0.9948 - val_loss: 0.8032 - val_accuracy: 0.9288\n",
            "Epoch 93/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.7250 - val_accuracy: 0.9474\n",
            "Epoch 94/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0300 - accuracy: 0.9948 - val_loss: 0.3942 - val_accuracy: 0.9412\n",
            "Epoch 95/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0188 - accuracy: 0.9979 - val_loss: 0.8340 - val_accuracy: 0.9536\n",
            "Epoch 96/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0340 - accuracy: 0.9934 - val_loss: 0.8956 - val_accuracy: 0.9226\n",
            "Epoch 97/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.6236 - val_accuracy: 0.9412\n",
            "Epoch 98/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0758 - accuracy: 0.9862 - val_loss: 0.6494 - val_accuracy: 0.9381\n",
            "Epoch 99/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 1.2378 - val_accuracy: 0.9288\n",
            "Epoch 100/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0656 - accuracy: 0.9941 - val_loss: 0.6219 - val_accuracy: 0.9412\n",
            "Epoch 101/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.7366 - val_accuracy: 0.9381\n",
            "Epoch 102/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.7672 - val_accuracy: 0.9474\n",
            "Epoch 103/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0735 - accuracy: 0.9903 - val_loss: 0.7789 - val_accuracy: 0.9288\n",
            "Epoch 104/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0474 - accuracy: 0.9948 - val_loss: 0.9764 - val_accuracy: 0.9226\n",
            "Epoch 105/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 1.2901 - val_accuracy: 0.9350\n",
            "Epoch 106/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0245 - accuracy: 0.9983 - val_loss: 1.2042 - val_accuracy: 0.9226\n",
            "Epoch 107/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 1.2068 - val_accuracy: 0.9350\n",
            "Epoch 108/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0109 - accuracy: 0.9993 - val_loss: 1.4714 - val_accuracy: 0.9319\n",
            "Epoch 109/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.3374 - accuracy: 0.9838 - val_loss: 0.9566 - val_accuracy: 0.9257\n",
            "Epoch 110/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0405 - accuracy: 0.9934 - val_loss: 0.6147 - val_accuracy: 0.9319\n",
            "Epoch 111/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0282 - accuracy: 0.9952 - val_loss: 0.7586 - val_accuracy: 0.9257\n",
            "Epoch 112/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0453 - accuracy: 0.9959 - val_loss: 1.2666 - val_accuracy: 0.9288\n",
            "Epoch 113/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0314 - accuracy: 0.9972 - val_loss: 1.0624 - val_accuracy: 0.9257\n",
            "Epoch 114/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0246 - accuracy: 0.9962 - val_loss: 0.9000 - val_accuracy: 0.9195\n",
            "Epoch 115/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0512 - accuracy: 0.9983 - val_loss: 1.1078 - val_accuracy: 0.9257\n",
            "Epoch 116/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0590 - accuracy: 0.9928 - val_loss: 0.5998 - val_accuracy: 0.9350\n",
            "Epoch 117/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0478 - accuracy: 0.9910 - val_loss: 0.6232 - val_accuracy: 0.9381\n",
            "Epoch 118/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.8483 - val_accuracy: 0.9474\n",
            "Epoch 119/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0445 - accuracy: 0.9945 - val_loss: 0.8839 - val_accuracy: 0.9536\n",
            "Epoch 120/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 1.2156 - val_accuracy: 0.9443\n",
            "Epoch 121/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0336 - accuracy: 0.9948 - val_loss: 1.3973 - val_accuracy: 0.9381\n",
            "Epoch 122/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0468 - accuracy: 0.9934 - val_loss: 1.1986 - val_accuracy: 0.9288\n",
            "Epoch 123/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 1.6293 - val_accuracy: 0.9350\n",
            "Epoch 124/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0321 - accuracy: 0.9959 - val_loss: 0.9944 - val_accuracy: 0.9257\n",
            "Epoch 125/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.9612 - val_accuracy: 0.9350\n",
            "Epoch 126/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0377 - accuracy: 0.9931 - val_loss: 1.1374 - val_accuracy: 0.9474\n",
            "Epoch 127/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 1.6662 - val_accuracy: 0.9443\n",
            "Epoch 128/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0236 - accuracy: 0.9966 - val_loss: 1.9147 - val_accuracy: 0.9288\n",
            "Epoch 129/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.2870 - accuracy: 0.9772 - val_loss: 0.7493 - val_accuracy: 0.9226\n",
            "Epoch 130/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0979 - accuracy: 0.9862 - val_loss: 1.0920 - val_accuracy: 0.9226\n",
            "Epoch 131/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0748 - accuracy: 0.9879 - val_loss: 0.7128 - val_accuracy: 0.9133\n",
            "Epoch 132/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0274 - accuracy: 0.9941 - val_loss: 0.9241 - val_accuracy: 0.9257\n",
            "Epoch 133/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 1.4341 - val_accuracy: 0.9350\n",
            "Epoch 134/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0879 - accuracy: 0.9903 - val_loss: 0.8385 - val_accuracy: 0.9350\n",
            "Epoch 135/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0282 - accuracy: 0.9941 - val_loss: 0.9036 - val_accuracy: 0.9381\n",
            "Epoch 136/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0243 - accuracy: 0.9972 - val_loss: 1.7471 - val_accuracy: 0.9412\n",
            "Epoch 137/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0446 - accuracy: 0.9931 - val_loss: 1.3694 - val_accuracy: 0.9443\n",
            "Epoch 138/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0168 - accuracy: 0.9962 - val_loss: 1.1026 - val_accuracy: 0.9412\n",
            "Epoch 139/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.3675 - val_accuracy: 0.9443\n",
            "Epoch 140/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.2935 - accuracy: 0.9859 - val_loss: 1.6253 - val_accuracy: 0.9257\n",
            "Epoch 141/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.1419 - accuracy: 0.9845 - val_loss: 0.9297 - val_accuracy: 0.9257\n",
            "Epoch 142/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0484 - accuracy: 0.9910 - val_loss: 1.4003 - val_accuracy: 0.9443\n",
            "Epoch 143/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0255 - accuracy: 0.9934 - val_loss: 1.8278 - val_accuracy: 0.9381\n",
            "Epoch 144/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0350 - accuracy: 0.9955 - val_loss: 1.7530 - val_accuracy: 0.9381\n",
            "Epoch 145/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0441 - accuracy: 0.9972 - val_loss: 2.4250 - val_accuracy: 0.9288\n",
            "Epoch 146/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0347 - accuracy: 0.9941 - val_loss: 1.7349 - val_accuracy: 0.9350\n",
            "Epoch 147/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 2.2420 - val_accuracy: 0.9350\n",
            "Epoch 148/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0160 - accuracy: 0.9983 - val_loss: 1.6715 - val_accuracy: 0.9350\n",
            "Epoch 149/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0402 - accuracy: 0.9990 - val_loss: 0.9378 - val_accuracy: 0.9381\n",
            "Epoch 150/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0742 - accuracy: 0.9917 - val_loss: 1.2042 - val_accuracy: 0.9319\n",
            "Epoch 151/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 1.5827 - val_accuracy: 0.9443\n",
            "Epoch 152/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 1.6700 - val_accuracy: 0.9381\n",
            "Epoch 153/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 1.9358 - val_accuracy: 0.9381\n",
            "Epoch 154/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 2.0219 - val_accuracy: 0.9412\n",
            "Epoch 155/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0030 - accuracy: 0.9986 - val_loss: 2.2761 - val_accuracy: 0.9381\n",
            "Epoch 156/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0388 - accuracy: 0.9962 - val_loss: 1.1716 - val_accuracy: 0.9350\n",
            "Epoch 157/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0195 - accuracy: 0.9979 - val_loss: 1.0173 - val_accuracy: 0.9381\n",
            "Epoch 158/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 1.6057 - val_accuracy: 0.9350\n",
            "Epoch 159/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0523 - accuracy: 0.9955 - val_loss: 1.1204 - val_accuracy: 0.9319\n",
            "Epoch 160/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 1.4231 - val_accuracy: 0.9319\n",
            "Epoch 161/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 1.7850 - val_accuracy: 0.9319\n",
            "Epoch 162/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 1.8015 - val_accuracy: 0.9350\n",
            "Epoch 163/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 2.0042 - val_accuracy: 0.9288\n",
            "Epoch 164/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2559 - val_accuracy: 0.9381\n",
            "Epoch 165/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 2.3220 - val_accuracy: 0.9319\n",
            "Epoch 166/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 1.6202 - val_accuracy: 0.9319\n",
            "Epoch 167/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 2.3935 - val_accuracy: 0.9350\n",
            "Epoch 168/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 2.6233 - val_accuracy: 0.9350\n",
            "Epoch 169/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 2.4607 - val_accuracy: 0.9350\n",
            "Epoch 170/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0314 - accuracy: 0.9966 - val_loss: 2.6513 - val_accuracy: 0.9226\n",
            "Epoch 171/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 2.2911 - val_accuracy: 0.9257\n",
            "Epoch 172/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 1.6317 - val_accuracy: 0.9350\n",
            "Epoch 173/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 2.5701 - val_accuracy: 0.9350\n",
            "Epoch 174/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0423 - accuracy: 0.9934 - val_loss: 1.3331 - val_accuracy: 0.9350\n",
            "Epoch 175/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0244 - accuracy: 0.9979 - val_loss: 1.7992 - val_accuracy: 0.9288\n",
            "Epoch 176/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 2.3108 - val_accuracy: 0.9443\n",
            "Epoch 177/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0662 - accuracy: 0.9986 - val_loss: 2.3067 - val_accuracy: 0.9505\n",
            "Epoch 178/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0584 - accuracy: 0.9952 - val_loss: 2.4608 - val_accuracy: 0.9319\n",
            "Epoch 179/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0217 - accuracy: 0.9972 - val_loss: 3.0063 - val_accuracy: 0.9350\n",
            "Epoch 180/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0496 - accuracy: 0.9938 - val_loss: 1.2537 - val_accuracy: 0.9257\n",
            "Epoch 181/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0788 - accuracy: 0.9938 - val_loss: 3.8095 - val_accuracy: 0.9226\n",
            "Epoch 182/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0490 - accuracy: 0.9921 - val_loss: 1.8928 - val_accuracy: 0.9350\n",
            "Epoch 183/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0291 - accuracy: 0.9952 - val_loss: 2.2154 - val_accuracy: 0.9257\n",
            "Epoch 184/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0573 - accuracy: 0.9941 - val_loss: 1.2253 - val_accuracy: 0.9288\n",
            "Epoch 185/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 1.9444 - val_accuracy: 0.9412\n",
            "Epoch 186/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 3.4639 - val_accuracy: 0.9350\n",
            "Epoch 187/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0346 - accuracy: 0.9966 - val_loss: 1.1035 - val_accuracy: 0.9412\n",
            "Epoch 188/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 1.3940 - val_accuracy: 0.9412\n",
            "Epoch 189/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.5924 - val_accuracy: 0.9474\n",
            "Epoch 190/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 1.4138 - val_accuracy: 0.9381\n",
            "Epoch 191/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0628 - accuracy: 0.9952 - val_loss: 2.3372 - val_accuracy: 0.9350\n",
            "Epoch 192/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0342 - accuracy: 0.9976 - val_loss: 0.9302 - val_accuracy: 0.9350\n",
            "Epoch 193/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0568 - accuracy: 0.9872 - val_loss: 0.6471 - val_accuracy: 0.9443\n",
            "Epoch 194/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0214 - accuracy: 0.9952 - val_loss: 0.6509 - val_accuracy: 0.9381\n",
            "Epoch 195/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.9138 - val_accuracy: 0.9443\n",
            "Epoch 196/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.8005 - val_accuracy: 0.9412\n",
            "Epoch 197/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 1.3270 - val_accuracy: 0.9381\n",
            "Epoch 198/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0434 - accuracy: 0.9952 - val_loss: 0.8280 - val_accuracy: 0.9443\n",
            "Epoch 199/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0152 - accuracy: 0.9979 - val_loss: 1.1712 - val_accuracy: 0.9412\n",
            "Epoch 200/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.9914 - val_accuracy: 0.9412\n",
            "Epoch 201/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 1.2313 - val_accuracy: 0.9474\n",
            "Epoch 202/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 1.2146 - val_accuracy: 0.9474\n",
            "Epoch 203/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.6693 - val_accuracy: 0.9536\n",
            "Epoch 204/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.5348 - val_accuracy: 0.9505\n",
            "Epoch 205/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 1.6204 - val_accuracy: 0.9443\n",
            "Epoch 206/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 4.2897e-04 - accuracy: 1.0000 - val_loss: 1.7528 - val_accuracy: 0.9443\n",
            "Epoch 207/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 1.5744 - val_accuracy: 0.9412\n",
            "Epoch 208/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0202 - accuracy: 0.9966 - val_loss: 1.9058 - val_accuracy: 0.9412\n",
            "Epoch 209/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 1.8502 - val_accuracy: 0.9567\n",
            "Epoch 210/300\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.2137 - val_accuracy: 0.9443\n",
            "Epoch 211/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0442 - accuracy: 0.9959 - val_loss: 1.0115 - val_accuracy: 0.9412\n",
            "Epoch 212/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 1.8035 - val_accuracy: 0.9350\n",
            "Epoch 213/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 2.0463 - val_accuracy: 0.9443\n",
            "Epoch 214/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0880 - accuracy: 0.9955 - val_loss: 1.2139 - val_accuracy: 0.9257\n",
            "Epoch 215/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0392 - accuracy: 0.9934 - val_loss: 0.9447 - val_accuracy: 0.9505\n",
            "Epoch 216/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 1.6172 - val_accuracy: 0.9536\n",
            "Epoch 217/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.1083 - accuracy: 0.9934 - val_loss: 2.0960 - val_accuracy: 0.9319\n",
            "Epoch 218/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.1205 - accuracy: 0.9893 - val_loss: 0.8337 - val_accuracy: 0.9505\n",
            "Epoch 219/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0353 - accuracy: 0.9924 - val_loss: 0.4363 - val_accuracy: 0.9319\n",
            "Epoch 220/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0337 - accuracy: 0.9945 - val_loss: 0.9900 - val_accuracy: 0.9319\n",
            "Epoch 221/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.1738 - accuracy: 0.9897 - val_loss: 0.7599 - val_accuracy: 0.9164\n",
            "Epoch 222/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 1.0357 - val_accuracy: 0.9319\n",
            "Epoch 223/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0369 - accuracy: 0.9972 - val_loss: 0.8945 - val_accuracy: 0.9412\n",
            "Epoch 224/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0275 - accuracy: 0.9969 - val_loss: 1.0548 - val_accuracy: 0.9288\n",
            "Epoch 225/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 1.0244 - val_accuracy: 0.9443\n",
            "Epoch 226/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 1.2986 - val_accuracy: 0.9474\n",
            "Epoch 227/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0404 - accuracy: 0.9945 - val_loss: 1.1360 - val_accuracy: 0.9257\n",
            "Epoch 228/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 1.7338 - val_accuracy: 0.9505\n",
            "Epoch 229/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 1.7466 - val_accuracy: 0.9443\n",
            "Epoch 230/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0441 - accuracy: 0.9962 - val_loss: 0.9413 - val_accuracy: 0.9443\n",
            "Epoch 231/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.4206 - val_accuracy: 0.9412\n",
            "Epoch 232/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 1.8502 - val_accuracy: 0.9381\n",
            "Epoch 233/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 3.4109e-04 - accuracy: 1.0000 - val_loss: 2.1534 - val_accuracy: 0.9381\n",
            "Epoch 234/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0734 - accuracy: 0.9979 - val_loss: 1.5357 - val_accuracy: 0.9443\n",
            "Epoch 235/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0230 - accuracy: 0.9976 - val_loss: 1.3351 - val_accuracy: 0.9412\n",
            "Epoch 236/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.1283 - accuracy: 0.9945 - val_loss: 1.0950 - val_accuracy: 0.9443\n",
            "Epoch 237/300\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.0280 - accuracy: 0.9976 - val_loss: 1.8584 - val_accuracy: 0.9412\n",
            "Epoch 238/300\n",
            "91/91 [==============================] - 2s 26ms/step - loss: 0.0821 - accuracy: 0.9962 - val_loss: 0.9650 - val_accuracy: 0.9536\n",
            "Epoch 239/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 1.5582 - val_accuracy: 0.9474\n",
            "Epoch 240/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0221 - accuracy: 0.9959 - val_loss: 1.1806 - val_accuracy: 0.9443\n",
            "Epoch 241/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 1.0498 - val_accuracy: 0.9443\n",
            "Epoch 242/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 2.1088 - val_accuracy: 0.9505\n",
            "Epoch 243/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 2.4094 - val_accuracy: 0.9536\n",
            "Epoch 244/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0278 - accuracy: 0.9986 - val_loss: 1.3536 - val_accuracy: 0.9536\n",
            "Epoch 245/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0311 - accuracy: 0.9969 - val_loss: 0.8499 - val_accuracy: 0.9505\n",
            "Epoch 246/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0213 - accuracy: 0.9962 - val_loss: 1.2674 - val_accuracy: 0.9443\n",
            "Epoch 247/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0152 - accuracy: 0.9979 - val_loss: 1.1733 - val_accuracy: 0.9474\n",
            "Epoch 248/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0175 - accuracy: 0.9966 - val_loss: 2.5081 - val_accuracy: 0.9350\n",
            "Epoch 249/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 3.0399 - val_accuracy: 0.9474\n",
            "Epoch 250/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 6.9767e-04 - accuracy: 1.0000 - val_loss: 4.1033 - val_accuracy: 0.9412\n",
            "Epoch 251/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 7.2914e-04 - accuracy: 0.9997 - val_loss: 4.0642 - val_accuracy: 0.9474\n",
            "Epoch 252/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 3.8199e-04 - accuracy: 1.0000 - val_loss: 4.3485 - val_accuracy: 0.9474\n",
            "Epoch 253/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 4.5700 - val_accuracy: 0.9350\n",
            "Epoch 254/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0231 - accuracy: 0.9969 - val_loss: 2.9376 - val_accuracy: 0.9381\n",
            "Epoch 255/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 3.4545 - val_accuracy: 0.9443\n",
            "Epoch 256/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 2.9247 - val_accuracy: 0.9412\n",
            "Epoch 257/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 3.0243 - val_accuracy: 0.9412\n",
            "Epoch 258/300\n",
            "91/91 [==============================] - 2s 25ms/step - loss: 0.2289 - accuracy: 0.9952 - val_loss: 2.2010 - val_accuracy: 0.9350\n",
            "Epoch 259/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0198 - accuracy: 0.9969 - val_loss: 1.8332 - val_accuracy: 0.9505\n",
            "Epoch 260/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0415 - accuracy: 0.9934 - val_loss: 2.6827 - val_accuracy: 0.9288\n",
            "Epoch 261/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0363 - accuracy: 0.9959 - val_loss: 3.3059 - val_accuracy: 0.9350\n",
            "Epoch 262/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0169 - accuracy: 0.9972 - val_loss: 2.5386 - val_accuracy: 0.9381\n",
            "Epoch 263/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.1656 - accuracy: 0.9817 - val_loss: 1.4479 - val_accuracy: 0.9257\n",
            "Epoch 264/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 2.9363 - val_accuracy: 0.9288\n",
            "Epoch 265/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.1111 - accuracy: 0.9914 - val_loss: 1.1794 - val_accuracy: 0.9102\n",
            "Epoch 266/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0265 - accuracy: 0.9941 - val_loss: 1.5206 - val_accuracy: 0.9288\n",
            "Epoch 267/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 2.4247 - val_accuracy: 0.9319\n",
            "Epoch 268/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0504 - accuracy: 0.9969 - val_loss: 1.5408 - val_accuracy: 0.9319\n",
            "Epoch 269/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 3.5898 - val_accuracy: 0.9195\n",
            "Epoch 270/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 3.7369 - val_accuracy: 0.9319\n",
            "Epoch 271/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 5.5859e-04 - accuracy: 1.0000 - val_loss: 3.7149 - val_accuracy: 0.9319\n",
            "Epoch 272/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 3.6914 - val_accuracy: 0.9257\n",
            "Epoch 273/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0194 - accuracy: 0.9966 - val_loss: 2.5180 - val_accuracy: 0.9350\n",
            "Epoch 274/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 3.2335 - val_accuracy: 0.9350\n",
            "Epoch 275/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 4.2939 - val_accuracy: 0.9288\n",
            "Epoch 276/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0982 - accuracy: 0.9948 - val_loss: 1.0143 - val_accuracy: 0.9319\n",
            "Epoch 277/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 2.5384 - val_accuracy: 0.9350\n",
            "Epoch 278/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0110 - accuracy: 0.9997 - val_loss: 2.4676 - val_accuracy: 0.9350\n",
            "Epoch 279/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 9.8003e-04 - accuracy: 0.9997 - val_loss: 2.5066 - val_accuracy: 0.9412\n",
            "Epoch 280/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 5.2097e-04 - accuracy: 1.0000 - val_loss: 3.2852 - val_accuracy: 0.9381\n",
            "Epoch 281/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 5.8514 - val_accuracy: 0.9381\n",
            "Epoch 282/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0240 - accuracy: 0.9993 - val_loss: 3.9749 - val_accuracy: 0.9288\n",
            "Epoch 283/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.2857 - accuracy: 0.9941 - val_loss: 5.3251 - val_accuracy: 0.9071\n",
            "Epoch 284/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0297 - accuracy: 0.9962 - val_loss: 2.3465 - val_accuracy: 0.9381\n",
            "Epoch 285/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0175 - accuracy: 0.9979 - val_loss: 2.9693 - val_accuracy: 0.9288\n",
            "Epoch 286/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 4.0713 - val_accuracy: 0.9381\n",
            "Epoch 287/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 3.5260 - val_accuracy: 0.9350\n",
            "Epoch 288/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 3.8331 - val_accuracy: 0.9288\n",
            "Epoch 289/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0101 - accuracy: 0.9986 - val_loss: 1.5897 - val_accuracy: 0.9226\n",
            "Epoch 290/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 1.6339 - val_accuracy: 0.9381\n",
            "Epoch 291/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0073 - accuracy: 0.9969 - val_loss: 2.2184 - val_accuracy: 0.9350\n",
            "Epoch 292/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0283 - accuracy: 0.9976 - val_loss: 1.8319 - val_accuracy: 0.9381\n",
            "Epoch 293/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0602 - accuracy: 0.9962 - val_loss: 1.0517 - val_accuracy: 0.9381\n",
            "Epoch 294/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 2.0770 - val_accuracy: 0.9257\n",
            "Epoch 295/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 2.1562 - val_accuracy: 0.9257\n",
            "Epoch 296/300\n",
            "91/91 [==============================] - 2s 22ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 2.2544 - val_accuracy: 0.9350\n",
            "Epoch 297/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 2.4303 - val_accuracy: 0.9195\n",
            "Epoch 298/300\n",
            "91/91 [==============================] - 2s 23ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 2.4424 - val_accuracy: 0.9257\n",
            "Epoch 299/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0027 - accuracy: 0.9986 - val_loss: 2.8465 - val_accuracy: 0.9381\n",
            "Epoch 300/300\n",
            "91/91 [==============================] - 2s 24ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 2.6900 - val_accuracy: 0.9412\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs = 300, validation_data = (X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW_brfNH8IXk",
        "outputId": "0f149cc2-105f-447b-a283-7cb67cef131b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9566563367843628"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M50U2tCv8P6e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('predict_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "later_model = load_model('predict_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABzMElEQVR4nO2dd5gb1dm376Ou7b25G/eCbWyKaQaD6QRIaAkEQgJ8pJEeSCeBvCmEkOQNCRDeUBIIEMBAgFAMBmMwNrZx793be1XXnO+P2ZkdaaUt9q5X9p77unxZK005MyP95jfPec5zhJQShUKhUKQutqFugEKhUCh6Rgm1QqFQpDhKqBUKhSLFUUKtUCgUKY4SaoVCoUhxHIOx0YKCAjl27NjB2LRCoVAck6xZs6ZeSlmY6LNBEeqxY8eyevXqwdi0QqFQHJMIIfYn+6xPoQ8hRI4Q4jkhxDYhxFYhxPyBa55CoVAoeqKvjvqPwOtSyiuFEC4gbRDbpFAoFAoLvQq1ECIbOBP4AoCUMgSEBrdZCoVCoTDoi6MeB9QBjwohZgFrgG9IKTusCwkhbgVuBRg9enS3jYTDYcrLywkEAofdaMXh4/F4GDlyJE6nc6ibolAoekH0VutDCDEP+Ag4TUq5UgjxR6BVSvmTZOvMmzdPxncm7t27l8zMTPLz8xFCDEDTFYeKlJKGhgba2toYN27cUDdHoVAAQog1Usp5iT7rS2diOVAupVzZ+fdzwAn9bUQgEFAinSIIIcjPz1dPNwrFUUKvQi2lrAYOCiEmd751DrDlUHamRDp1UNdCoTh66GvWx9eBJzszPvYANw1ekxQKheLI8EHFB4zJGsPIzJFD3ZQe6VMetZRynZRynpTyeCnl5VLKpsFu2GCQkZEx1E1QKBQpxB3v38GTW58c6mb0iqr1oVAohi2haIiwFh7qZvTKsBRqKSXf+973mDFjBjNnzuSZZ54BoKqqijPPPJPZs2czY8YM3n//faLRKF/4whfMZe+///4hbr1CoRgoNKkR0SJD3YxeGZRaH73x8/9sZktl64Buc1pZFj+7dHqfln3hhRdYt24d69evp76+nhNPPJEzzzyTp556ivPPP58f/ehHRKNRfD4f69ato6Kigk2bNgHQ3Nw8oO1WKBRDR1RGicroUDejV4alo16+fDmf/exnsdvtFBcXs2DBAj7++GNOPPFEHn30Ue666y42btxIZmYm48ePZ8+ePXz961/n9ddfJysra6ibr1AoBghNakS11BfqIXHUfXW+R5ozzzyTZcuW8eqrr/KFL3yBb3/729xwww2sX7+eN954gwcffJBnn32Wv//970PdVIVCcZhIKfXQh0z90MewdNRnnHEGzzzzDNFolLq6OpYtW8ZJJ53E/v37KS4u5pZbbuHmm29m7dq11NfXo2kan/nMZ7jnnntYu3btUDdfoVAMAJrUAJSjTlWuuOIKVqxYwaxZsxBC8Nvf/paSkhIef/xx7r33XpxOJxkZGTzxxBNUVFRw0003oWn6Rf3Vr341xK1XKBQDgSnUR0GMelgJdXt7O6CPyrv33nu59957Yz6/8cYbufHGG7utp1y0QnHsYQj00ZD1MSxDHwqFQmE4ahWjVigUihTFcNRHQ4xaCbVCoRiWHE0xaiXUCoViWKIctUKhUKQ4KkatUCgUKY7hpJWjVigUihRFxaiHMZFI6j9GKRQKlUedslx++eXMnTuX6dOn8/DDDwPw+uuvc8IJJzBr1izOOeccQB8Yc9NNNzFz5kyOP/54nn/+eSB24oHnnnuOL3zhCwB84Qtf4LbbbuPkk0/m+9//PqtWrWL+/PnMmTOHU089le3btwMQjUb57ne/y4wZMzj++OP53//9X9555x0uv/xyc7tvvfUWV1xxxRE4GwrF8MaMUWsRHt/8OCurVvayxtAxNCMT/3snVG8c2G2WzIQLf93jIn//+9/Jy8vD7/dz4oknctlll3HLLbewbNkyxo0bR2NjIwB333032dnZbNyot7GpqfcJbcrLy/nwww+x2+20trby/vvv43A4WLJkCT/84Q95/vnnefjhh9m3bx/r1q3D4XDQ2NhIbm4uX/nKV6irq6OwsJBHH32UL37xi4d/PhQKRY+YWR8yyu9W/w6AjTcOsC4NEMNqCPmf/vQnFi9eDMDBgwd5+OGHOfPMMxk3bhwAeXl5ACxZsoSnn37aXC83N7fXbV911VXY7XYAWlpauPHGG9m5cydCCMLhsLnd2267DYfDEbO/z3/+8/zzn//kpptuYsWKFTzxxBMDdMQKhSIZqihTb/TifAeDd999lyVLlrBixQrS0tI466yzmD17Ntu2bevzNqwzdwcCgZjP0tPTzdc/+clPOPvss1m8eDH79u3jrLPO6nG7N910E5deeikej4errrrKFHKFQjF4mDFqlZ6XOrS0tJCbm0taWhrbtm3jo48+IhAIsGzZMvbu3Qtghj4WLVrEAw88YK5rhD6Ki4vZunUrmqaZzjzZvkaMGAHAY489Zr6/aNEiHnroIbPD0dhfWVkZZWVl3HPPPdx0k5rgXaE4EhxNjnrYCPUFF1xAJBJh6tSp3HnnnZxyyikUFhby8MMP8+lPf5pZs2ZxzTXXAPDjH/+YpqYmZsyYwaxZs1i6dCkAv/71r7nkkks49dRTKS0tTbqv73//+/zgBz9gzpw5MVkgN998M6NHj+b4449n1qxZPPXUU+Zn1113HaNGjWLq1KmDdAYUCoWVo8lRCynlgG903rx5cvXq1THvbd26VYlQD3zta19jzpw5fOlLXzpi+1TXRDGc2Vi3kc+99jk8dg+BqB7KHMrORCHEGinlvESfqWBoCjB37lzS09O57777hropCsWwwXDUhkinMkqoU4A1a9YMdRMUimGHEaM+GuiTUAsh9gFtQBSIJLPnCoVCcbRwNAwdN+iPoz5bSlk/aC1RKBSKI8jR5KiHTdaHQqFQWDmaHHVfhVoCbwoh1gghbk20gBDiViHEaiHE6rq6uoFroUKhUAwCx6KjPl1KeQJwIfBVIcSZ8QtIKR+WUs6TUs4rLCwc0EYqFArFQHPMCbWUsqLz/1pgMXDSYDYqFbBWyotn3759zJgx4wi2RqFQDDRHw4hEg16FWgiRLoTINF4D5wGbBrthCoVCMZgcTY66L1kfxcDizoJEDuApKeXrh7PT36z6Ddsa+14MqS9MyZvCHSfdkfTzO++8k1GjRvHVr34VgLvuuguHw8HSpUtpamoiHA5zzz33cNlll/Vrv4FAgC9/+cusXr0ah8PB73//e84++2w2b97MTTfdRCgUQtM0nn/+ecrKyrj66qspLy8nGo3yk5/8xBy2rlAojixHU2dir0ItpdwDzDoCbRlUrrnmGr75zW+aQv3ss8/yxhtvcPvtt5OVlUV9fT2nnHIKn/rUp2Kq5PXGAw88gBCCjRs3sm3bNs477zx27NjBgw8+yDe+8Q2uu+46QqEQ0WiU1157jbKyMl599VVAL96kUCiGhmPNUQ84PTnfwWLOnDnU1tZSWVlJXV0dubm5lJSU8K1vfYtly5Zhs9moqKigpqaGkpKSPm93+fLlfP3rXwdgypQpjBkzhh07djB//nx++ctfUl5ezqc//WkmTpzIzJkz+c53vsMdd9zBJZdcwhlnnDFYh6tQKHoh3lHbROpmK6duywaBq666iueee45nnnmGa665hieffJK6ujrWrFnDunXrKC4u7lZn+lD53Oc+x8svv4zX6+Wiiy7inXfeYdKkSaxdu5aZM2fy4x//mF/84hcDsi+FQtF/4h11Kgv1sKr1cc0113DLLbdQX1/Pe++9x7PPPktRURFOp5OlS5eyf//+fm/zjDPO4Mknn2ThwoXs2LGDAwcOMHnyZPbs2cP48eO5/fbbOXDgABs2bGDKlCnk5eVx/fXXk5OTwyOPPDIIR6lQKPpCvKN2iNSVw9Rt2SAwffp02traGDFiBKWlpVx33XVceumlzJw5k3nz5jFlypR+b/MrX/kKX/7yl5k5cyYOh4PHHnsMt9vNs88+yz/+8Q+cTiclJSX88Ic/5OOPP+Z73/seNpsNp9PJX//610E4SoVC0ReOJket6lEPY9Q1UQxn/r3j3/xiRVf4McOZwYrPrRiy9vRUjzp1byEKhUIxiGharKO22+xD1JLeGVahj/6yceNGPv/5z8e853a7Wbly5RC1SKFQDBTxMWq7UEJ9VDJz5kzWrVs31M1QKIYFUS1KU7CJAm/BEdnf0RSjTt2WKRSKYcVvPv4NZz97Nh3hjiOyP5VHrVAoFP3kX9v+BUAwGjwi+4t31Kkc+lBCrVAoUoojVdXuaKr1oYRaoVCkFBEtckT2E++oU1m4lVAnoad61AqFYmCxuugjJdTxwjwYY0oGCiXUKU4kcmS+tArFUFLjqzFfR6Ry1PEMSXpe9f/8D8GtA1uP2j11CiU//GHSzweyHnV7ezuXXXZZwvWeeOIJfve73yGE4Pjjj+cf//gHNTU13HbbbezZsweAv/71r5SVlXHJJZewaZM+B8Pvfvc72tvbueuuuzjrrLOYPXs2y5cv57Of/SyTJk3innvuIRQKkZ+fz5NPPklxcTHt7e18/etfZ/Xq1Qgh+NnPfkZLSwsbNmzgD3/4AwB/+9vf2LJlC/fff//hnF6FYlA52HbQfH3EHLV29DjqYZNHPZD1qD0eD4sXL+623pYtW7jnnnv48MMPKSgooLGxEYDbb7+dBQsWsHjxYqLRKO3t7TQ1NfW4j1AohDEMv6mpiY8++gghBI888gi//e1vue+++7j77rvJzs5m48aN5nJOp5Nf/vKX3HvvvTidTh599FEeeuihwz19CsWgMhRCrRx1L/TkfAeLgaxHLaXkhz/8Ybf13nnnHa666ioKCvSE/by8PADeeecdnnjiCQDsdjvZ2dm9CrV15pfy8nKuueYaqqqqCIVCjBs3DoAlS5bw9NNPm8vl5uYCsHDhQl555RWmTp1KOBxm5syZ/TxbCsWRpbK90nw9VEKdyhMJDKsY9UDVox6IOtYOhyOm1kD8+unp6ebrr3/963zta19j48aNPPTQQ73u6+abb+axxx7j0Ucf5aabbupXuxSKoaDWV2u+HmhnG9EifPrlT/Pewfdi3o/fjxLqFOGaa67h6aef5rnnnuOqq66ipaXlkOpRJ1tv4cKF/Pvf/6ahoQHADH2cc845ZknTaDRKS0sLxcXF1NbW0tDQQDAY5JVXXulxfyNGjADg8ccfN99ftGgRDzzwgPm34dJPPvlkDh48yFNPPcVnP/vZvp4ehWLIsAp1WAsP6LYb/A3sbNrJz1f8POZ95ahTlET1qFevXs3MmTN54okn+lyPOtl606dP50c/+hELFixg1qxZfPvb3wbgj3/8I0uXLmXmzJnMnTuXLVu24HQ6+elPf8pJJ53EokWLetz3XXfdxVVXXcXcuXPNsArAj3/8Y5qampgxYwazZs1i6dKl5mdXX301p512mhkOUShSmVpfLXkePVQ40KEPwzk7bI5u7wu6+qNSWahVPepjlEsuuYRvfetbnHPOOUmXUddEkSqc+tSpjM4azeaGzfzlnL9wxsiBm0/0QOsBLl58MSMzRvLfz/zXfP+ej+7hxV0vmkPWHcLBJzd8MmD77S+qHvUworm5mUmTJuH1ensUaYUiVfCFfbSF2yjLKAMGJ0YNiR21y+aK+TtVGTbpeYfC0ViPOicnhx07dgx1MxSKPmPEp0dk6P0wAx36MGLe8UKtSQ2n3QmdIXGJRErZa3ruUHBEhTpVT0IyjuV61Kmc3K8YPtT763l2x7MApqMeLKF22pwx70e1KC67K+Y9TWopWUXviIU+PB4PDQ0NSiBSACklDQ0NeDyeoW6KYpjzfxv/j39s+QdgcdQDPIQ8FA0BiR21XdhjhFlDY1/LPup8dQPahsOlz45aCGEHVgMVUspL+rujkSNHUl5eTl1dap2A4YrH42HkyJFD3QzFMMcqnqXppcDAO+qQllioozKKTdiwC7sZn9akxnff+y6TcifxP2f8z4C243DoT+jjG8BWIOtQduR0Os0RdQqFQgFdHXiPX/A4ma5MYBCEuhdH7bA5TDGPalFaQ600BhoHtA2HS59CH0KIkcDFwCOD2xyFQjGcCEVD5LpzOaH4BFNIB02oRRJHbZl9XCIJRUO0h9sHtA2HS19j1H8Avg8kzQgXQtwqhFgthFitwhsKhaIvhKIhPfOCrs6+gU6T68lR24SNdGe6OfAlKqOEtNARm7exr/Qq1EKIS4BaKeWanpaTUj4spZwnpZxXWFg4YA1UKBTHLiEthNvuBrrmLBysGLXVOYMuynZh588L/8zNM28G9I72cDR8VDrq04BPCSH2AU8DC4UQ/xzUVikUimFBKBoyB50Yjnega30Yjjo+Pc9w1JPzJlPg1UszmI46dJQ5ainlD6SUI6WUY4FrgXeklNcPessUCsUxTzgaNnOZBz1GHZ/1oUVNF2/8H46G0aRGe7g9pVKJ1RByhUIxZASjQTNGbYjlgMeotR46E226BBr/B6J6CWGJZE/LHhr8DQPalkOlXyMTpZTvAu8OSksUimOYzfWbicgIswpnDXVTUgprjFoIgUM4BtxRm0WXkqTnAdg6PWsg0lXr/fKXLscu7Ky7Yd2AtudQUI5aoTgC/O8n/8t9q+8b6makHOFoOKYwksM28EIdjuox7/jyFUZ6HmD+bzhq6zKpgBJqheIIENJCZqxU0UVI60rPg4ER6vjYsnHeE00UYDrqTqEORoKHte/BQgm1QnEEiGrRlHFnqUQwGoxx1Hab/bCEut5fz4JnFvCLFb8wQx5GjDrRZLa9OepUQQm1QnEE0KR2xCZtPZoIRUMxFewcwnFYRZnW166nKdjEv3f8m+tfu57GQGNyR611d9T+iP+Q9z2YKKFWKI4AmtSUo05AOBo2OxPh8EMfmxo24RAOfnXGr9jWuI0l+5ckFWqrozYE23DhBl6H95DbMpAooVYojgBRGSWqKaGOJ6SFYgaiOGyOwzpPm+s3MzF3ImeM0KfyCkVDSUMfiWLU1qwPwJzHcahRQq1QHAGUo05MMBqMDX0chqOWUrK5YTPTC6ab27R24vYpRh0n1FmuQyoWOuAooVYojgBRGVUx6gRYRybC4cWoqzuqaQ21MjVvqunSQ9EuoZbEZoNoUjPrf6jORIVCoRx1AqJalIiMdHPUh1rrwxfxAZDlzsJhc2ATNsJaOKbWtBWj1gckd9TxLnyoUEKtUBwBVIy6O4aAxg94OdTzZM423jlU3GlzEo6Gu0If9D09z/g7VW6uSqgViiOAJrUBnwvwaMcQUKujPpw8asP9Gh2ELpsrJkYdPxDG2plo/G846h+d/CNGZoxUQq1QDCeiWndH/Z/d/+EPa/4wNA1KAYwQR4yjFg4aA428tOulfm/PEFUj7uy0xzrqeNG1OmpjeLmRnrdg5AJmFs5UoQ+FYjiRKEb9fvn7vL7v9SFq0dCTyFE7bU62N23nxx/8mOqO6n5tz3Dihjt22py6o9aSOGpNMws1GesYA15cdhd2cXijJAcSJdQKxREgUYw6IiMp82g9FBjuNT70YdAWauvX9uIdtcvu0jsT++CozVofljbZhV05aoViOGHEqK2uLqyF0bTUEIKhIJGjtpYi7e90WPExaqfNSSgaMkMsPcWo47M+XDYXdps9ZTqAlVArFEcAw81ZHVpEiwzrDsZkMWqD9lD/hNrM+ugUe5fdRTgaNl1yT1kf8Z2JDpsDu7CnzBOPEmqF4ghgCLT1hx/RIinzaD0U9NdRh6NhFu9cnPScGefWEF+nzRkb+kiQR20ItNGZGIgGcNlcCCGwCZsSaoViOGH84K2dU2EtnDJCMBT0FqOOF+oPKz/kpx/+lC0NWxJuzxBiax51MBrsCn3EjUxM5qiN9ihHrVAMM5Sj7k6i0Ie1QFN86KM11ApARzjxDOFGGMnamWiMVoTuowzDWtfw9RhHbQi1TXUmKhTDCsPtWR+/I1okZTqrhoLeQh/xWR9G6lz8MG+DRJ2JVlG3im5YCxPRInjsnph1ApGAebOwC9WZqFAMK8zQh6XzMKIN7/Q8Q6hjpuKydCbGO2dfWHfH/mji4v6GqJojE+0uWoOt5udWoTam3PI4dKG2Zn2o0IdCMUwxQx+aCn0YGDFq68QBPcWoOyK6cCdz1PGhD6fNaYZLIFaojZoehqM2ZiEPaSEzFKM6ExWKYYbxg4+JUXcOeInP7x0uJIpRG24YuseoDUedTKgTOWrr+bYKtRFGMR21rUsKDUftsDnQpJYS10cJtUIxyFgFIt5Rx38+nEgUo7ZOhRXvqI2Owd5i1Eac29ox6bF7YvKojW2YQm2RQiMUk0oV9HoVaiGERwixSgixXgixWQjx8yPRMIXiWCHeRRsYjnK4CrUhylZBtU4u2y300RmzThajNs6tNY/aIM2ZFuOMDaE25kS0OnnD4RuCnwrXpy+OOggslFLOAmYDFwghThnUVikUxxC9OepUcGxDgVmP2uKorSMD40Mf/nDPWR+JQh8G6c70mPPcLUadIPRhCH4qFGbqVailjnHGnJ3/hj5oo1AcBRxsPciB1gPm3/F51JAajm0oCEaCOIQjJiXPcMsF3gIOtB1gzhNzzA7B3kIfxrlNFPpId6YndNSJQh+GozYEPxWuj6P3RUAIYQfWABOAB6SUKwe1VQrFMcJFiy+K+Ts+PS/+veFEe7idDFdGzHuGay70FlLdUU1ERqjuqCbLlWWGPpLNaxhf5tTqqNMcaWZnpHUb8el50BWjNraTCk88fepMlFJGpZSzgZHASUKIGfHLCCFuFUKsFkKsrqurG+BmKhTHBgk7E4dpBb32cDsZzlihNgQ0z5NnvmfE8g1HbY1jWzGcb6IYdYYrIzb0YcSo7d6YdaB76OOoEWoDKWUzsBS4IMFnD0sp50kp5xUWFg5Q8xSKYwvrj94QoFQQgqGgPdTdUY/OHK1/ZulINETVmp5X2V7JwmcXcrD1oLlcfOgjJkbtiA19GGLvdug53FahTnOkxWwnFUIffcn6KBRC5HS+9gKLgG2D3C6F4pjE7EDUomaRoGEr1Akc9V2n3sVDix7ijhPvMB2xMYrQKtQH2w5S56/jYFuXUMeHPqyzt7gd7oSO2gh9WLM+DKE+qjoTgVJgqRBiA/Ax8JaU8pXBbZZCcfSTyIklGkqeCo5tKGgPdRfqdGc6p5adytT8qfzzon8CejhEStnVmRgNJIzvx5c5NRy1x+HBLuyxnYnR2NCHUZTJaAMcZZ2JUsoNwJwj0BaF4pgiUSzViFFbXdqwdtRxoQ8rhtsNRAKEtJB5ngIRi1Bbz6MWxSEcpugajtzr8CKE6DbgxS7s3eZMBD3nGrqGovelMNMD6x7gzX1v8tLl/Z+Uty/0KetDoVD0n0QzlCSqSz2cOxMN95oII8c5GA3GFGjyR/wJ4/vW+tLQlWbndXixYes2hNzj8JiiHhOjNoS6H1kfD65/UD+mBHH3gUANIVcoBolEdZMNgTaEBoZnep6Uko5QB5muzKTLGI7aH/Gb8Wm7sOOP+JM6amtRJyP04XV4sQlbt6JMxo0AEncmHkp63vam7X1etj8ooVYoBolEk7MmdNQpEAM90gSiASIy0m9HnevJJRANmDe6+BCStUyqNfTRTagjAfNGAImFuj/pebnuXAC2NQ5OnoUSaoVikEgo1CpGDXQ9bWQ6kztqo/xpIBow4/35nvyYGHV86MPqqI2BKx6HJ6FQG3U+IFaozc5EW987E41Y99aGrb0ueygooVYoBolEMWojzDHcHbUxe0tP8Vy7zY7T5iQQCZihjzxPXsw8iPGhj5gRhj056rjQR8LORNG3zkQpJc3BZgC2NiqhVihSii0NW6j31yf9PFGMOqGjTpHpno4kxrmJT8+Lx2P3EIwGzdS8XI8eYjCeVqznLj70ER+jtk5uG4gEzMEuEJue19/ORKNzM8uVRYG3YFDqVyuhVij6yaqqVdT6arn5jZt5ZOMjSZfrMUadIP93ONEXRw36yMFAJGDmPRtCbawfXzslJvTR6ajTHGkIIWJEPT5GbaW/nYmGm/7OvO/w0KKHYkR/oFDpeQpFP4hoEb685MucWnYqbeE2an21SZdNJNSJshWGY+jDODd9cdSBaMAcnZjtzgYsQh0X609UV9oY8BKTRx0NUGIvSbjP/uZRG0JttG0wUI5aoegHNb4aQlqI5RXLAWgMNALw8u6X+aT2k5hlO0IJQh+d7syanjccHbURv+/NUXscHoKRYJejdseFPnroTLSGPgSiW62P3hx1X7M+DKHOcef0uNzhoIRaoegH5W3lQNcjd1OgCYA/rf0Tz25/NmbZPmd9DMMYdb8ddedsMIYYGkLfLY9adA99GDHqqIzy7x3/5kDrgR5DH/GjFXsT6pZgS0zbBgMV+lAo+kFFe0XM34ajDkVDMS4ZknQmKkcNdAl1T3nUYIlRdxZRynJlxawf35mYzFEby/1ixS/M/VqzPhKhQh8KxVGK4agNWoItRLQIgWjAnKzVoC3c1m19FaPW8Uf8uGyumNldEmFkfQSiAVw2lym+RrpeTKesFpv1kefJ4/snfp/zx57frYOvI9zBqMxRPe67r0WZlFArFClGeVs5RWlFekEf4UCi59AmctRGh5eVRCMTh6OjDkfDMfWik+FxdHUmuh3uLqHuTNeLP4/WPGohBJ+f9nmK0opi3gc4qeQkrp58dY/77mvoo8HfQKYzM2aigoFGCbXimKOivYK7Pryrm3AO1LbHZ4/nN2f+httm3QZAvb+eqIzG7E9Kyd7mvd3WH44x6kAkYMZxDcJauFc3DfroxEBEj1F77J5ujjqqRQlGg/z0g59S66uNCX1YsQr1dVOv44FzHuh1/33pTHxi8xM8s/0ZSjNKez2Ww0EJteKY48PKD3l+5/NUtFX0vnA/KW8vZ0TGCM4fez4nFJ8AQFV7FaC7ROtybeE2JudOjll/OI5M/Oyrn+X0p0+PeS+iRfrkQK1ZH26720y5Mx21jLCraReLdy1me9P2mNCHFatQj88en7Qj0Yoh5D0J9Rv732BK3hQeXvRwr9s7HJRQK445jAlSk82td6hIKWkMNFLgLQC6UsWqfdVAbAehUfNhRkHs9KKmox5GA152Ne/q9l5YC/dNqC151B5Hd0dt9A8YJHPU1myQvjh5sDjqJE88Ukp2N+9mTtEc8r35fdrmoaKEWnHM0dskqIdCeVs5raFWALOYT55Xn4C1qqPTUVuFunErDuFgSt6UmO30Vj1vZdVKfr/m9wPW7lQlrIXNokk9YR2Z6LZ3xait05gZqXtAt1i0gaCrM7EnoY5ZTvQ8Z2J1RzUd4Q4m5Ezo9TgOFyXUimMOQ6AHSqgr2yu58IULuX/N/UBXneRsVzYCQXV7p6PuDH38ZtVveGTjI4zPGW+OcjNIlPVhdddLDy7lqa1PDUi7U5m+hj68di8hLYQ/4o8JfVi3Y4xaBPoU+ki2zHOXPseSq5Z0rWPrec7Enc07AZiYO7HX4zhclFArjjmMx2LDWSfDH/Fz94q7zUEryfjHln8AsLdF7xw0HLXdZifHnUONrwboctTvHHgHgBum3RDzyA2J86jjy2+mwmSqA4U1ZdE6MjAc7WNnYmfhpNZQa0zowyCqRQlqXULdl87EZPudnDeZorSirm31kp5nhHSOyzmut8M4bJRQK445DCdd76/nn1v+mfSH9sLOF3h2x7M8uunRpNsKR8O8sPMFoKs+snWgRJozrWvQi6aLki/i49rJ13LZhMu6iUJvWR+hqD434LHSwWitLmg95r7GqI1z3hJswW13dwuXRGSso46/MRr0Rajj6S09b3vjdoq8ReYgnMFECbXimMNw0q/vfZ3ffPybhJ1ZgOmEe5oOqrqj2txeU1B33taMgTRnmjngIRwNI6WkLdRmbjP+Mfu98vd4bc9rSUcmGvHWgXDVYS3MQ+sfMp8whgJr0SprLLnPoY/Op5eWYAseh0efvNYSR45okZjtDqRQW9PzntvxnHnDBv3muqJyBfNK5vVpW4eLEmrFMYfhqA0hTjSUG/SBCtBVOjMRRkchdA0XjxFqR5qZIxzWwvgjfqIyagp1/KN4ja+GO96/I2lnoiE6A5ED/sKOF/jzuj/z6ObkTwyDjdVRG08c0L+sD8DMoxZCxIQ/jDxqg8MJfcRjLKdJjRd2vsBzO54zP1tft56mYBNnjz67T9s6XJRQK445DAdpuLlEM61Al1BbC8rHU9lRCejFg4xYtnUKJ6/Da64f1sLmaETTUVtEwer2ko1MHEhHXR/QRXIwCtkDfFjxIetq1/W4jNVRW+PVfR3wYi10ZIRBrB2KEdl/R93XEYTGOhEtQke4I6YvY+nBpThsDk4vOz3Z6gOKEmrFMYfhqA1X2hFJ4qgDulDH1+iwYjjqcdnjzO3FxKgdXVkd4Wh3oY6pj2xxgkfCURs3qJ5CO4fDbz/+LQ9ueLDHZer8debreKHui2Ban3aMJxlrnDreUScT/76m51mxdia2h9vNEFdUi/La3teYXzq/1zKtA4USasUxR3xaXqK60NDlqK0jCuOpaq+i0FsY02EUH6M2iMgILSE9DGJM2moVhfjYaqLXA+moe6pQJ6XkkY2PUN1Rfcjbr/XXJj23BjGhD4tQR7RIn/KorUJtOmp7nKOO9J5HbQ2JJEvPS7ZOVEbxhX20h9sJR8N8VPURtb5aLptwWZ+2MxD0KtRCiFFCiKVCiC1CiM1CiG8ciYYpFIdKfFpeohi1lLLLUWvJHXVlRyWlGaXdwh0GVkcNXfWpE4U+rO2KyEjCARWGmPV08+grhrtPlEGyq3kXf1z7R+58/85D2nYgEqAt1NanFEiD+Bh1X5xtnifPfG3cIGNCH33sTDwcRx3RIuZxNgebeW3va2S5sjh71JGJT0PfHHUE+I6UchpwCvBVIcS0wW2WQnHoGEPIDRIJdUOgwRSwnkIf1R3VlKbHCrU19GF9H7o6HBOFPqxEtIjpDK0xaqPuclgOQOij01GHtTD1/nrm/mOuGVM2zsmh3hCMkEayjloD67mNCX1E+xb6sLrnRI66r6GPw0nP84V95nelKdhEvb+esdlj+1T9b6DoVaillFVSyrWdr9uArcCIwW6YQnEoSCm7hz4SiMm+ln3m62SOWpMaVe1VlKWXxQp1ktAHdMW9EzlqK6FoyBSewXLURow6HA3zfvn7hLSQOQuNcY76UpwoEXW+upjtJCOpUPcxRg1dAm38b12vr476UGp9CCEQCLN0AEBzoJlgNNhthORg068YtRBiLDAHWJngs1uFEKuFEKvr6uq6ratQHAnCWjhmSDYknhLrrf1vmT+2ZKJY768npIUoy4gVakMwoHvoo9HfN0ftj/jNUXfWAS/GKLv4YzgUTNeshc0biFE86LCFuq+OWguZIZ5DCX1A1zk2Qx9WRy37lp5nnTigP3Wj7TZ7jFA3BZtibrJHij4LtRAiA3ge+KaUsjX+cynlw1LKeVLKeYWFhQPZRoWizyRyePEDPiJahDf2vcGCUQvI8+QlDX3sb90PwJisMXidulB7Hd6YH32i0Ie1eFAyUegId5ifxaTnRQauM9EQmLAWNkMyxiwkhsD2Nh1VMgxHHYwGe2xrKBoyMyMOZcALdD21JO1MHCRHbawX76hD0VCfOkIHkj4JtRDCiS7ST0opX+hteYXiUNneuJ01NWsOef1Eo/DiHfXmhs00BBo4b+x5OG3OpKGPfa37ABibNdYU5Hhhiw99NAWbYtLhkjm89nA7TpsTu7CboQ8pZVd63mGGPqo7qs2BOKFoyMxwMfZliM/hOmrouaZKKBoyJ7C1HlNfq+cB3c59t87EPgwht95c+y3UwVhHHYwGU89RC/0I/w/YKqU89usvKoaUK/9zJV94/QuHvL7hqK1ON/7x3Jj3cGLORFx2V1JHva9lHx67h+L04i6xiBO2+NBHg78hVqiTCEdzsBmvw4td2GNKnxqDZw4n9LGxbiOLnlsUUwDKGHhidFYaGSGH6qitaXc9DVG3OupuoY8+pskZ59gIFcXnUfelHrWN/g94gQSOOthMWAunZIz6NODzwEIhxLrOfxcNcrsUikPCcHfWtK54oTZyh0vSS3DZXEkHl+xv3c/orNHYhC2pUBshEYPGQGOMUFvd270L7uXk0pMBvXaF1+HFbrObMWqr4ByOoz7YdjDm71A0ZA7cMRy7IdQ9jcrsCeuIQ0OoV1atZHnF8th9a12O2th3VNOLTvXZUXeeY03TnwasIhmV0ZgbbTLxj8mj7o+jtsSoBYKmgO6oj2TGB0CvLZZSLgdEb8spFIfL4Q51rvfX88jGRwC906yivQKB6Bb6qO6oJtOZSbozvUdHvb91v1lrOGnoI85RNwebme6cbv5tiIJAcMHYC3AKJyurVtIabMXr8GITNtP5xsdwDxWjeJRBIBowb07xQn2oIyAbAg04bU7CWti8Of5tw9/wRXycPqJrWLU19GGcZ+Npoa/O1hg85I/qT0vWsENYC8fc4A534oB4bMJmjkgsTi+mKaB3Jh5poVYjExUpQ7zA9JeHNzzM2wfeBrocdYG3oNujebWvmuL0YkB/jE4k1Hua91DeVs7YrLFAl1DHdx7G/w0kDH0Y/xs/8IiMmEJtxI2tQn04Q8gb/A3YhZ1l1yyjLL2MivYK82ZghIYOV6hbgi0Up+nn0Hhi8Uf83TpzraEP4ynB+L+vQv2Dk3/AFROuMG8A8XnU1utnjUVb6cvEAYmwLluSVkJHuCO1sz4UisHGmCT2ULEOlc736GloJekl3Rx1TUcNJeklgP4YHd+Z2B5q57rXrsPtcLNw9EKgS5Djf6DxnYlAwtCHIRTW9Y2ynQPtqBsCDeR58sj15OK0O80MDes+TKE+xBBLW6jNnHnbuBH6o/5uN72QFjKvS3wdk74626K0In5x2i8S51HLiBl3h+TnzSrUyeLYCdfrnOVFIMj15OrHqClHrRjGGJXqeuKdA+/w7Xe/nfAzq3MuTNNTRIvTiglr4RgBqe6o7hJqu6ubWFV3VNMebucnp/zEnJw2PpfXIJHTTuiobbGO2ljHGvqIHxDSX7Y1buOMp89gfe16M1/aaXPGdIYZGRLW1L2+sKpqFV9/++u8uudVwlG9nGtJmn4OjaJXxtyGVkJRXagFwrwhGvvsT6eelZ4cdV+Euj8Y1y/NmYbX4aUj1IEmtZTsTFQojgiV7b0L9TeWfoO39r+VUGBaQ63kunO5/6z7ObXsVLLd2UzI1SceNR7PA5EATcEmU2QSOWojBGOdWbq3rA8jjgqxQm2IkSEUVpFJc6TFpOf1xRn2xLLyZTQHm9ndstt8onDanKZ7hq44b39DHz/+4Me8W/4ubx942yw8ZdzsjBtkIBKIEU1NanqGhN0Vc0M0ju1whdph059GrDeHwRLqdEc6XofXvMGp0Idi2GIV6t6mojJyhK20hlopSS/h3DHnMqdoDsuvXc6IDL3agSHUxmQChsgkilEbg0OsmSPJYtQehweBIN3VFXaxirbhpI0fvPUH7nV4sdlsZtbHoThqKSU1HfoxWWtDm47a7jS3leXKMh11W7h/Qm114MZr4xwacelAJJAwzm5MStvNUR/ioBHDzXrtXkLREGEt3JWrneR4DlWojfXSnGl4HB4zjJaSA14UiiOBteRmskwMQ+gSTUjbGmwlyx07f50RHzWEek/zHgDKMsoAEmZ99CTU8VkfRuqeIRQQ66htwoZAdOtMBF3krY76UGLUr+x5hXOfO5f1detZV7fOfN8Qausjeq4nl2A0aE4XBn2LUUspY1yzMQDEEGqzMzHqJxAJmNk7xnl12py47K5ug3n6k31hxRBJt8Ntho2MvoKBdtRGG9Od6THXXjlqxbDh4Q0P8/jmx82/rbHUZM7ICDUYQr29cTu/+/h3SClpCbV0m2jUEFjD9b25/02yXFnMLpwNJAl9dG7bOruIkcubaCRfujM9Zr/xhfodNkfCzkRjwIuRrnYoWR87m3YC8MTmJ2gLtZnbt4Y+DLLd2QSiAXyRrmpwfbkh+CN+M986GA2a1ynbnY3X4cUX9uk1VjoH7BjbNITaCH2YBacON0bdefOxCqdxQ042UEgcZoZxhisj5tqrzkTFsOGNfW/wzoF3zL+t2RnJHLUhvEYc+fV9r/P4lsdpD7frjjpOqI0fs5E69s6Bd1g0ZpHpyozYaUuwhdP+dRpratbQGGgk250d4/hcNhenlp3KrMJZ3dr0s/k/40szv2T+nUiok4Y+OtPzNtdv5untT5uf9dVRG08Qb+5/E4CLxulj0Qq8BebxGeS4c8w60gY91eI2sA4YCkQCplBnubJIc6TREemIGcZtxIyNa2jUPhnoGLVVOI0nmmTnLdkI0d4wJka+fMLlMWGvlBvwolAMFq2h1phHUuvchskcpSnUna7XGHHnj/hpDXUPfRhOOBAJsL5uPb6Ij3NGn2N+btT6qOqoojXUyq6mXTQFmsh1x054K4TgoUUPJWzTglELYsSvm1ALh5nmZRUnw1FrUuPxzY+zsqqrKGV/Y8cAxxccz1mjzmLxrsUUegu77S/blU0wGoypzdGX0EeMUEe7Qh9ZrizSnen4wr6Y/OltjdtIc6SZ+dPdQh8DlPWR0FEPcOjjyklXUu+v5+JxF5slYoEjnvWhhFoxZLQEW2K+8O3hdtIcafgivqQCYrgow1EbuddNgSbCWrh76MPeFfowBGpk5kjzc+OR3BCjtnAbjYHGmPh0X7CKTrxQ22325DFqm52IFqG8ozxmnb46amvBoIvGX8SZI8/kntPuYW7x3G7tynZnE4gEzIkV0p3pfbohGOl3xvqmo3ZnkeZMwxf2xWSs/Pbj36JJjV+f8WvzmBN2Jh6iUBvrWR21cWNNFjs+VKH+2fyfma+NWiM97WewUEKtGBJC0VCMeEopaQ+1U5Jegq/dl/SR3BCw5kAz0JXFYfyfLEYdiAbMDjGrCLvseq0PQ6hbQ600BZoYlz2uX8fTo1ALuykUDpsDh3CYIxONokxGpT6D/jhqh83BKaWncPG4i3HYHDFz+Zkdb3Y3XofXjFGDfq76sh/reWsONNMa0oe/O21O8j351PprzbQ/6KoDYsaobbHpef0d8BKPcbOzCueF4y5kfM54Pjf1cwnXOVShtqJi1Iqjltf2vBYz8q2vGK7MEIFgNEhERkwRTSYgxuNzU6CJqBY1U9OMjBGj3rKBtTOxKdiEXdhjhNRw9Ea6X1uojaZgU8ykqn3BcM0Om6NbZog1Rg1dP/I0Rxo2YaO6ozomdOCxe/ruqEOtTM+fzl/P/Ss5npxunxs3ELfdjcfhQZNaTGdgnxx1500sz5Nnhj6MG+KYrDHsa9kX0/7mYDMtwRbzWhkx6visj8NNz7Oe53xvPrfNuq3bjdog2dDy/mA8nYESasVRRHOgmTvev4OXdr/U73UNYfRH/GhSMzsSDYG0dib6wj5TkI2OqqZgEw2BBrOXP5mjNlyQP+KnOdBMtjs7xl0ZPzgjJa8l2EJToKnfoQ/QRTHTmdlNFKxZH9D12Gw46t3Nu7u1uc+OOkEHqhVrx5shbEZ8v6+OOkaoO0MfRl/AmKwx+CI+s3Qs6DnwURk1S6E67c6Y0Ed/izL1dEwGvV2vQ+1MtBLjqNXIRMVgY0x5f7gYHXnWOGlfMYRaIglEAmZHYiKhfnD9g9z0xk1A1xDopkCTuX/AFPL4zkS33Y1AmI46vpPQEAujQlp5WzkS2W9HbWwrPuwB3YXacJJGjNo6w4uxnf446vhjjt8W6DcFM77fKdTZ7ux+dSbme/KRSBr8DebNYWz2WEDvQIzHuHl2S8/rZ1GmeGYUzODi8Rczs2Cm+V5vQj0Qjtoq1CqPWjHovLH/DW558xYq2isOaztGuMEY5dZXvvfe9/jxBz82//ZFfN0ctdXpVXdUdxW+tzhq6wCZap/+Ot5dCiHwODz60PFAU7fwgOHODPEyYsVGelt/cNoTC7Vd2GMcndVRGwLudXi586Q7Oa3sNLN8aF9oDfXsqM2ON7una7BQsH+O2ghrGINoav21XULdWV0wkVAb18wcmRiXR32oMepsdza/PuPXMWGuRMWxrNgGQOqsoRY1MlEx6BgxZWN6pkPFEEdrWl1vSClZXrE8pri9L9wl1MZADauAtIXbzLn5rDFqa7U901EnEC2vw6s76gQhDUOoDUdtiJKR3tYfkjlqu83eY+gDoCy9jOumXseDix7EYXP0SUA1qdEeau9T6MPtcJudb2bow60LdW91wK2hD4B6X725z5L0Etx2d2JH3XlNjM7Egcr6MOjvlFqHS7IJjo8ESqiHAYFIgM31m82/DVGy5v4eCofiqGt8Nd3Kjvoivh5DH8ZnzcFmNKmR58kjrIXZ2rjV/AHW+GoQiIRC6XV4zWJM1tGG0BVrjB+SblTf6w9JQx+ie2eiQOC2u833i9KKYrYTH/o42HaQhzc8HCOq7eF2JLJPjtpr95qdYU2BJmzC1jVIpJdpvzrCHXgdXlOoIjJihltswsborNHmd8qKEfpw2p3mUw0c/oAXA6NWdKKa4PEMROjDKs5KqBUDzsu7X+b6166PETyIHSzRHz6s/BB/xG8KdX8cdXzHGeiO2rhpGDHkGEfd+ZnR4Wc8bq+rXceozFGA7oQzXZkJ07C8Di8d4Q5agi3dhNp4hI0XmkNx1LefcDvXT72+2/sOW9eAF+jKwBBCmO9bhTqRo35j3xv87yf/a54D6Oob6ClGbe14Mxx1Y6CRNEeaeZPqKU79+ObHWVa+TK91YYnRWm8OozJGJVzXEGq33U2mK5P2UDtSysMuymRg3OTiM30SMdDpeYd7k+kvSqiHAY2BRiIyYjpZwz0eiqOu9dXy/976f3xr6bcSCvVzO55jV9OupOsnFOqIr9vjtdVRG47dFOrODqzKjkpGZI4wfzTJnKXH7qHOX0dURruHPmyxoQ/Q86APZXbuC8ddyAnFJ3R7v1t6ns1lukCjBkVvjto4x9anEetQ7mQY4QFr1ocxsa4hlMnCLJrU+OPaP7KvdV+3okTWfRoFruIxOxNtLjKcGURkhLW1a3liyxN62/ox00pPx5btOjJCPZRDyJVQDwPMGTg64699cdRhLcyf1v6pm1s2Oog+qPygW+hDSsnPV/ycK16+Iul2d7fs7pZn7Av7zG0YnX1W8TDa0OjXhXpM1hjzs5K0EvMHlMxZep1es4Rqb52JcGhuuicyXZkx1fVc9i6hNrJfenPUhkAbN9dgNMiLu14EehbqhJ2JgSbSnGnmZ8mE2hjtCXrOd4yjtpxro5RsPMbNxmV3mSGhL77xRfN7c7iO2ghnHClH7bQ5sQmbmS9/JFEjE4cB1jntoEuUekqr21y/mb9t/BvT8qdx7phzzfetg1uMGVkMIbXWkEjG7ubdzCiYweqa1eZ7voiPjlBsHNRw1FEtam7XcNRl6WU4bA4iWoTS9FKzoHtPjrohoHec5rkTdyZaZ+MeaKG2DkMG/anBuEkaHbrWmLhxbFbihfq1Pa/xr23/Avoe+jCENhANmCMLIXnow3DEBskcdTKhNrBmw9iwoaFX7jtcR218746UUAsh8Ng9hzxz++GgHPUwwDpVEvTNURvibi3IA1Af0AcxCAS57lxmF87GF/ER1aJ9CqVUd1SbP2zDZRpZH+nO9K64aaeTsz7qG0LtcXjMiVVL0i2OOolQWx9Z4/OjrQMXjPYcSkdiTxSlFcU45u+d+D3uP+t+APMGYhwPkDA9zxClen89H1d/zIG2AwDcMvMWjss+Lum+rY46pmyrw2u6wmSO2pr+WNFeETNkO1now9ifEWKyCRsO4TDPrdVFH24Hn/E00tMThcFACDXo370jHfYAJdTDAmvoI6pFzS94X4Q63iXX+3ShXvP5NSy7dhmLxiwCdEG1CnX8zN+gh0YaAg3ke/NZ+bmVvHHlG+Y+2sPtZDgzusVNEwm12+42i9aXppeaObTJnJX1kd1Yz8A6Ia7x2UA76niy3dnmzcBIN7TusydH/a9t/+KLb3yR1dWrGZkxkttPuL3HyVqtjjrHnWOGP9Icab3GqK2OujXUGjOE2urirUJtuO7JuZMBvcNPiK5sHOOpLn7g0aFwwbgLmFs8l1uPv7XXZQcijxr0G5zbdmQzPkAJ9bDAKtStoVbz0a0nB5zMUdf568h155rOyfgBtofbY0T1YNtB6v31MYLdGmolokXI9+ST5kwj05mJQzjwhX00B5rJcmeZ2zVCH9Y2Gu7T4/CYotofR+22u7tlfYzKHGWKS3G67moH2lH3Bev8jD05aqM+8vq69YzI7DnkYGwLMLNMjPMWE/pIJtQdNWZ4Ynr+9KSOOqZ2SueN4bQRp8Vs27rMp477FMuuXdZr23sj253NYxc8lrQz04o16+Zw8Ng9R3ywCyihHhZYY9TGqDTo2VEbTjreGdf56yhI6xq1Z9Qcbg/FOup9rfs4+9mz+crbXzHfM+Kxxqg/IQRepxdfxMeelj2MzRqrPyrbHLxz4B3+te1fMds0Qx92DyMyRuAQDorTi3vvTOz8vCS9pNvjtt1mZ1LuJACm5E5h4aiFnFp2atLzMtAY8ytaO6d6ctSGI5XIXmPDEBv6gK4QS5qz9/S8Gl8NRWlFvP6Z1/nbeX+LeTJJlmlhLHNa2Wkx71s7U+NvlkcCw1Ef7sAXt8N9xHOooQ+diUKIvwOXALVSyhmD3yTFQGOIrlGYCDo7tHroTEwW+mjwN1DgsQh15w+wLdQWkyGysW4jAGtq1nSt2+mIre4xzZFGZXsldf46JuZMBHRx2d60nUc2PMKPT+kaam5kfbgdbq6fej2nlJ5ilu+E3h21NU5sZUzWGDbUbyDXk8s3534z4TKDxYuXv9htsI3T7uwmnvGDhEDvVO2N+AJGMY66h9DHsvJlrK1ZS3F6sXlDMNpkXdfgvgX3IZH8Zd1fsAkbx+XExs2tjrovnX8DjRGjPtxYtcfu6XXi5cGgL61+DLhgkNuhGEQM0Q1EAmZH4qjMUT2OKDSFOoGjtoYGEoU+nDYnbx94u9s2DUdtDBMH3dltrNdFfULuBMBS0S7YmLgz0e4h15PLiSUnAvQq1IZIJXNyo7JGxbTvSFKUVsTkvMkx7xn1qg2MWt3x9OWRP77IvuGo3XZ3t9CHlJKffvBTlpUv46tvf5XKjsqYzlajuFSi0ZfnjT2P88eej9vuJt2RjhAipoPUOlx+KBy18SR1uEI9MnNkn26QA02vjlpKuUwIMfYItOXwkRJayiEagtxxIASE/SBsEOoAfyOk5UPFGvA3QWYJFE6Bqg36+tEgNO2D1kpwZ0L+BMgdC2EfuLMgsxTKPwabXd+e8aidlgdV6yHYBloYNA3yj9P/DrWDFoUpF0POGKjeCJEAODxQvx0CLfpyNjtEw+D0grDrx5BVBg633qaQT//M5tD3EY2A3akfg9Orb8ffDDIKdjf46vVlvXn4Oh2bf8drbOjsvJrQWsfGYCva+/djC7WDO0M/poxicLjpaNRn6+6o3gDL7oVgG7JgCvW+WvJrtsMbPwItQoaRNrb3PVo7c5XnuvL5qF0ve5lt98DmF6GtmvqGtQDkr38G0opACNIC7ewN6h2UE3Yuha1LcGldE69W738fALdwmO7e/fH/QXoJdNSBsOOV+jFlVW+Gxmr92oYD4EqD9hrcbfoEsNmt1bDk5/r5j4b1cyXsnBjVnyyK938EHb8FROcyQYh0/hM2/RoZIQop9WvjygBXOgSa9f+jEf211PTvkM2pXydvjn5dbfau/zvq9O+a1aE53DhbthIOtMCON6BuO/5gW7cKewAjNr0M298HI11MSv21sIEnGyJBPAE9nTJ962uwayWFIf0adexfjrNdvxmH9i6jYu8KPOmFLN61mHX7lpj7OLW9Vb/+moaIBvFgIyschLd+CsH2rn15siEawt1eS5oWhWX38p/8swlntsJ/70TYnWQIOy0yStbOd6Bqj/67CLbqvy9h6+GfiP3bmQbHLdR/i948/bcSaNG3FQnqf0fDoEX0diGxdRqO6Y4seO17+uegbxuh/7adXv03EGrT25aAu6QGeOD1H+jnW2r6OTfOvTsTzr0r4bqHw4DlUQshbgVuBRg9evRAbVYX3q2vQGuFLrI1m6D5IDhc0LhPf9+bo/9g2qr1HxfoIurwQEdt//fp8OgXfCDzJZf+j/6lsExZ1BNGSYeukKroc3s2uly8kZHBd5qaQWp0jB0FQlBRuYrX09K4MBRlXNs+tEwXvnd+ToYEkEgpEELfh68gHzLT8dVugo1LweagBY3ImJEUHlgJ/hUg7GQSgbJ82j9+mHaHHUd2FrOqtvNRrv54mxNog3/fCEBDTjaO7Eyy3/2t2dYRhflsztAzL4rf/R3YHDjLisCpfzUPbPk3ZGZQFPJz0NnpDpfd13mC9JOTlpsNOVlkv/NLCMU9xtvdtOVkQZaXnL3LoeUN/YduiK4WYV40wnN2yQTtI9j4Rtf5dnh0MXa49f1pka4fsKBTxDuvp7B1Ca4zTRfjUHvv18zu1ttizJIdCeDIyyKSngZPXQ1Ah90Go7umDyuNRGiw2xm77U2QEqkJhN34ogj9BhRoJap5mORxcbcrwml7nwK7i2yPHYoKaK3ZhHPHBzCilI4Pfs8FRQVMDIXA5WJvRH/Seqm6ifHRD7rOic2BZ2QxWf522P2gfnOXmi6SncfuLi4iw26Hd+7Bi+6kpc0JkTAZZbm0OB3kbHoBAkG9re4sXSDpFL2YfyR4T9ONyjt3Jz6fNifYXfrN0WbXb9rCjtvh5gkRYkLoILh36efdEFip6SbOwOHRt5GAbt2IhtAb/2cUpbZQSykfBh4GmDdv3uErXGsl7Fqi37lC7URCHmQ0hDM3E0qO138kZbPg+Kt0ZxL2E3UUUP3SDqKtfkZcOwGbCEPeBBCSSFuQaNhJtL4G54zTseWPwqFVQ902AuERtH+8BVt6GppIA7sbz/SppE/MR7SWE6hopn35Sux2H95TzyXa7idc34YjJw33qBIcriBi5GzIKEaLStrffgfZeIDA/hq8s08g2lCDx7+K5tVVhDsceKdNQgb8pJ9+BraiUTQ8+hS2NC+eWbMIH9yPs6iQllffINpYT95VF5N99ecRGbkEt20muGsnkfomZFTDM3Ec0teEkFGCB2qI+sLIcJjfj1hNU+U+Lsy/lQKbl6kH/sbYGsmsXV7m+6OMK5pCa4aN0wu3UTf1F9QvWYmw2/Bv3ETRl79EqPwA07aupD6znlPry6gedT3BnbtpnzuSnPb/ML7wdoInX05w1y5sNsmITd/HlnkxtkwXk2pXM+2Mn8HGn5MegPF1edQ6PoN/217O3riBk52S6rNvIf3E2Qi3m++4BC3LfsYlu7LYJ8/FO2s2eb7/UJnlAyE4OGI207ft5eSmfJqb60gPSBrzbqCxox1bRjZCRCkY3cRpm9fiaFxE7dhJ2PIK8EydTrhiP8KdSWb5m5yy9QMm5pxHeV0azpEjsaWlIZwOsNsRdgeFDjstDgc2twtbRgY2bxrC40HYbPg3bMSenY0tPR0ZDiFDYWQkgvf4mTgKC/CtWE60tQOiIeyFRfg+/oSODz7ANXYMmYvOxZGbhXfKWII7dxFta8c1ooSOj1YTbmzDlpVHuLqGSH0dMhjCO2c2k+s/xr12E+X2S7AXj6K1vIr/t+ljInYobIHRhRMZkT6C5oOVNLS3EamsQqSl4cjNxZ6Xhz0vF+nz4/v4Y9xTpnDyrFm0FhcT3L2b4hEe/vyX5ylodSEWXMzvX12Fe+5pnNCyle0jnUw9IDlht0Zzrhu35/Ps3bWb9BNPwL9hE9HWNr629iCuzGKqxl+HzZ1OpK4WGQzqNzHgtrc/xt3kY8+4M3EUFhJtaSW0dy+az8dvHYKm9AjZo09lf1oOrlGjCG7fjT07m3BFBbasLDLOPBMZCRNtaUHr6EB03pw7Vqwg/0tfQjicRMp3kV4cwDbhdFwjSwhV1BFpDyGlE+/s2QS2bkXz+3GWlhLcth0t4Mc5ahQTAz7C9Y3U1dcTqavDnpmJc9QoXKNH4506gfZ330NKG1GfHyIRXOPG4544Ad+aNYQrKrG5XUQ7OnCWlpE+/xRCe/eCsJF2whzaly3D9/HHyGZJSQ+ydqiI3kocAnSGPl7pa2fivHnz5OrVq3tfMBkVa5GPXUrDOojYiwjaJuH7ZCNISdpJJ5J14YU0/etpgnv2YHO7ER4PnsmTCFdUEiovByFwFhcjpUa0qRl7bg6RyqrYfTid5H/xi/g/+QTfqlUJm5H96U8T2rcP/9q1PbdXCOz5+Tjy84nU1hJtajLfx3p+bTbckycT3LpV/9jpREaj2LOykJEIWns7OBwQiSC8XjxTp3bt226HaDRmn8Rfu84vNeHEvfh7iqExU3BGwUl07N6BrU5vp+u44xA2/REzuGMHwuUiGglh0yDkFLidXhyFBYT3H+j5PFgIOMFjNMNuxzNlCqvymxGt7czeJ4g2N8csbyvIxzNxIr7Va8z2N2ZA1GmnsCkas93MstHYPF60gJ9oXT2aT3+steXno7W2Jj1+AEdxMdGmJmQo8ZyMA4LTScZpp+FbvVq/pkkwrr+jsBB7drZ+/rdvByBiA2/ZSMItTdRlShwtPtwRQXWOZISrkEx7Oq5x47Clp+MaPRqto4NIUyPRxiaijY1owSAZp5+Of+NGgrt2obW2YsvIQGtvp6U0k/wTTyPynzeozpYUt4CQELaDMwpRAXYJtrQ03JMn4//kE2yZmXhnz6bywGa8QfCGBVpHh34Dy+jM6BDgKCzEM2Uqob17iTY1YcvIwDV+PI68XF7Z9ByRyioWpM1C1DcSqarGM20a0fY2XGPGEj5wgOBOPUxly8jAlp6O5vejtbfjHDmS8IHu3z/n6NEJ3+8Ne04O0Y4O87viKCwkUtf/KeX0jem/TeH14ho3lvEvvHBImxFCrJFSzkv4WcoJdf0u+Pt5NO30Uv2+Bg4HzhFlZF9yKcLlouGhh9B8PlzjxpF5zkJkOIzm89O2dCkIGPn736P5/TQ++SQAjvwCIg31ZJx+BvacHOw52UTq6ml+/nn8a9bgGjuW7MsvJ+ca/THTlpYGmkb1PffQ8vwLuMaMIefaa8m+/DK01lb869bhKC7GWVZGpKaG4N69RGpqidTWEKlvQGRl8PTIci485QamTj+TjlWrcOTk0Lz4RTIWnEnmwoVE6uqQoRCVP/ghzpEjKf7hDxBOJ1pbG/bsbPzr12PLysI9cSLt775LaPduou3t2LNzyFiwAFtGOkSjhKuqQYuidXSQduKJIAShAwd4+tHvs0LuomFaGfedcS8/eOI66rIF1Xn6wIMPP/shLf4mPv/HM/jcuE9zzVV3IWw23t/xJi/977f48jef4OfrfoNv6xbCE0by0rWvI6XkySfuYNvK1/ju5/6Ctu8g7kkTEU4nv3rhG+SXjke0ttEcbuNr427g6bd+T40nyPYR8M9vf4QjPYMr/3MlhWmF/HXhXwhs3QqaRrS5BeGwk3bSSQi7nXBlJXf8ZhG57ZIRDeAOwYETR9EyZxyvNy4nN6OQpVcvNb8u4ZoaWpa+Q5sXxl5yNcJuJ9LURHD7Dlyj9HCBDIfRQiGE3Y5r/HiEEHq50EgEGY0iI1GI6E8jmt+P1tGB5g8ggwFkOIx78hQ0XwcyFEa4nAin/ljc8f4ytGAQ74wZuMaOBSkJlZfjLCvDWVxMtLWVSEMD4fJygjt24CgowF5QQLShAffkKbjHj0NGo9g8XWlvUtP419pH+f0n9/PW59/n1rduNWs9T8mbwrbGbTxwzgOcOfLMPv+kpJRoHT5sLidt775L+vz52DMzKd+9nouWXcdNRZ/iozUvcdoWycFCwbJZDm7IPo//d+4PceTm0rFyFc4RZbhGjux9Zz1w+zu3s/TgUlZ+bqXeARyJmI7ZbGdrK7b0dITDYb4ng0GE3Y5//XocBQWItDR8K1YQrq2l5bnnyb7iCrxz5iAjYXwrVuA5/nicRUWEDhzAPXEi9rw8Qnv3IdwunMXF+jZcLmQ0SqS6Gv/mzdT+5rd4Z88m7wtfwJ6ZgS0zk9CePQS278BZVkr6yScjIxFsaWn4N2wguHMXjqIioo0NBPfuJW3ePDLOOMNs96HQk1D3JT3vX8BZQIEQohz4mZTy/w65NT0gIxGqb/00/konwWaN9FNPZdTfHkbYu3Ifc666Eq21FeeYMTE5scWhEESj2Lx6BkDGmT1/kbMuuZjwgQO6m0wwlDX/rp+w47wpnHn657AZ+8/NxTWmqyCQa/RoXSAt7GvZx+MvXkqmaz/T09LIWLAAgNLZs81lHIV61sSYJx6PWdfm7hw1Nq/rWmWefTacfXbCY3CWlnZ7zzN5Mu+fXcCq6j1ANdXeIBvHdfV0G0N7s725MGU8yzMbubZzMMCP1t5D0zwbp8uDNNsD7B0lyBd6DFYIwdoxEbZnjiHn9DPhdMsxV42hyu4gpKXjtOWQf/71fOaKc3lp10ssXvdn/C7Jy1ufZEfTDi4ZfwnCZsM7fXriYyor460TYnvmLxo3m/K2cqJ2wRUTYgs+OYuLKbj2s1jnY3Hk5uI45eSE2zcQQoDTGSMU/cX12c92e8+4tgD2rCzsWVm4x40j44wzErcjbv/CZqOgYBRBl6DGVxOTs1uSXsK2xm39ns9RCIG9sx8g67zzzPfdpWVIm6AqI8KWMTa2jNFz3O8//ZdMzJmII00fPZh+8kn92l8yMl2ZOG1OvA6vef67tTM7u9t7ovNGZv1dZF+mz7RecMstMctnnNaVv+21/OacxcXEI+x2nCNG4BwxgsxFi7rPdZmf3+33DZA2dy5pc+f2dKgDTq+5KlLKz0opS6WUTinlyMESaYD6P99P85Yw9rLRFH3/+4z8ywMxIg3gyMvDNXZst5Nqc7lMke4LNpcL94QJSesNLDn4Nl/f91s2NW5O+HkyjGG3df46IlqE4584noc3PNyvbRwu1kEixkg2A2tq1MyCmWys34iUkq0NW83BMM2B5oR51Pta95klRq3ke/NpCDTQFmoz86pL0kvMvOX2UDuPbnqUk0tP5sbpN/b7eEZnjTbF6bqp1/V7/aMNY4Rkra82Jp2sNF2/MVvTGw8Haxqkue+0Yk4tO3VQRmeeUHQCp484fUCK+A80qdgmKykzMjHS1ETFI/8ga7SPMb//GflfvCnmkfBIYxS92dxwaEJd7683BzL8ed2fB7ZxvdAaamV89nigq/6zUdPCWpTo+ILjaQw0cqDtQMzUWDW+mm71QTSpcaD1gFm030qeJ4/GgJ7zbIxUhK5Ri3X+Omr9tZxUclK/8liNgRGjM0dz92l388KnXogZLHOsYuQf1/hqYgojXXbcZdw0/SZTyA8Xo0aKdR/W3OeB5jOTPsOfFv5p0LZ/LJMyZU4dubmsPX8ON7pfguLEj8VHkoo2feLXrQ1b+7WeMU9cna8uZjaOI0lrsJXTR57OnpY9pqPO9+TTEe6IKYZz5sgzESsFr+551XS/aY40qjqq8EV8eOweAtEAB9oOcPdHdxOMBpmYO7Hb/vI8eTQFmvA4PDGDIYzX2xv1DrKRGf2LcRanFdMSbGFM1hhyPDndakkfq+R78xEIqtqrqPXVcv7Y85mWP43pBdOZXjBwvw2nzUmmMzNmkuOBugkoBpaUcdQA43IbaE4rAu/hV9Y6XIwv79bG7kJd3VHNOc+eYwqQFWvowzrS7UiJdlSL0hZuY0zWGDx2T5dQdzpRq6MuzShlftl8Xtz1ojlicVLuJPa37keTmlmT43Ovfo7N9Zv51txvccn4S7rtM9+bj0Tij/hj4qdGHQvjHI7M7JtQG4WAjLaOzhzAvPyjAKfNSYG3gC0NW4jKKCeVnMQXZ3xxUPaV48kx64qMzRrLCUXdZ6hRDD0pJdQT5X722McNdTOALqHe1bTLLEVpsKl+E7X+2pji9waGo67315u1LYCYyWUHmu2N21m8czHQVRMiy5VFaUapGa824prxHVGXjL+Eqo4qPq7+GKfNydjssexp0UclmjHmcDu/OuNXfHHGFxPObGHd5rT8aeZrI/RhPJX0VajfvPJNXrniFfLceWS5soaNk7ZSlFbEhjp9xGx8adaBxOizcAgHL1/+MheMU9UiUpHUEepomGzZwnbGDnVLCGthanw1jM8eT0RGus0BaMSv97bsBfSSnHcsu4N9LftMRx3WwubngJliNRj8YsUv+OmHP2V5xfKuCU9dWWZNgpEZI81H2vg6C8a0Vruad5HlyqIkvcQsOmPtUDpjROKsBYjt3JqR35XBaXQsbmvcRrozvc81iAvTChmTNYYbp9/IT+f/tE/rHGsUpRWZtVgGU6iNfoB0V3rKd6gNZ1JHqO1O7pn6H/4avXxIm+GP+Klur0aTmjkF1ZbGLTHLHGjVhXpfyz5Ad7Sv7X2Nb7/3bWp8NWZxoG2N2/Q4oCvTnGuwJ97c9yYrq1Ym/KzeXx/T6WPF+IH9etWvYyY8NepDXD7hcrNwUfwMJ0ZIpNZXS7Y7O6YzyShm31sN3jxvl6O2ul8jRh2VUUZmjOy3EEwvmM75Y8/v1zrHCtbrYGR7DAbGzdNahlSReqSOUAM5GS7q/HqS+2AjpexWSvLtA2+z4JkFbO5MyTup5CQyXZndOhSNDIm9rbpjNpzPzqadNAYamVGgu8rtTdvJ8+SR78lPGKP2hX1Ud1Sbx/ud977DzW/ebE6ZBXCw9SD7W/dz94q7+dbSbyU8FiMWvr91P1Ud+gjMLHeW2fH3qeM+1SXUca7W6oYNR20wq3AWgFmlLhnJ0sWsUxb1Neyh0Dl79NnMKZrDDdNuSFitbqAwHbVlphtF6pEyWR8AuWkuQlGNjlCUDPfhNa3B30BLsIXxOeMTfv7irhf5w9o/8OaVb5qDClZUrsAf8bO6Wo89l2WUMS1vWjehNkIftb5aOsId3UR4ful8Pqz8kFpfLVPzpuJ1eBMK9XWvXceu5l0sGLkgZgLU53Y8x/XTrgfgFx/9wpyZpbK9Ek1qMSlumtSo9lUzJmsM+1v3m+mEWa4svnHCN7h60tWUZpSahePjHbXH4SHDmUF7uJ1sdzYnFJ3ALTNv4erJV5PvyefGaTfyxZk9d2RlubKYVzyPqyZdlXSZa6dc2+M2FLGcWnbqEZnAwPg+KEed2qSUo85L0x1YU8fh12G4+6O7+dKbX0rqzjc3bKYx0Mie5j3me0Zd5C0NeqijKK2IqflT2dG0w6zZG4gEqO6oZkreFEAPfzRaKm+NzRrL1ZOvNuv45nnzyPd2d9Sa1MyMjPfK3+Pb737b/Oyt/W+Zr2t9texp2UNVexXBaNB0zAZ1Pn1gzUkl+ugxo9Myy5WF2+42B6icNuI0Pj3x0wnjnUb4I8uVRZozjdtPuJ2S9BKcdiffPfG7vY6EE0Lw6AWPctH4i7p99sSFT/DqFa9ySukpPW5DMTQYfRbKUac2KSXUOWl6HLTZl7yoTjz7W/ebgzoa/A1UtFfgC/tYXrG8x7iukdWxs1kvAhOKhtjRtAPQY87GRKBT86YS0kKmoBvrLRy9ENAzQAwRznXncvsJt5PmTDPdUJ47jzxPXkwGCHTNBH7nSXdy9qizWVe3DoBzR5/LjqYd5g2mKdBEW6iNQFQPh1g7KAFTuE8q1YV6U8MmoPu0VMflHMfPT/15wqwNI3QxGDNvzCmaw+is4ZVedzRhXHPlqFOblBLq3PROR+1L7qh/s+o3PLj+QfPvO5fdya1v3kooGuKsZ8/igucv4IPKD8yUOsMdx1PZWeR+bc1alpUvY3vjdjOfNKSFzIwHYwJRI5vDEPYFIxdQml7KiqoVNAQaKPIW8d4175mzchtCXuurJd+TT0uwJWbKo3q/Xiy/wFvABWP1lKg8Tx7zy+bTHm6nsqOSqBY1Bd3A6MCMP44J2RPI9+TTFmoj3Zluhjr6gtVRK4YXRp+FMUpRkZqklFBneW0gwkmFWkrJS7tf4tU9rwJ6TYrNDZup9dfy7x3/NpdbXrGcTFcmdmHvNgT8w8oPufP9O00n+vzO5/nq219lyQF9VgvDcRZ59RxiI/OhzqeXQNzRuAO7sHNcznHML5vPqqpV1Pnq9NFklqwGo7rZiSUnmqEDY75CiBXqM0eeicvmYmLORHNaph2NO2gJtZgzhhusql7F9sbtpuM2jqM0o9QcoLJoTPcCMz1hOOpkk8Mqjl2Uoz46SJnOxI5wB19ddjWuvONp6piVcJkaXw1toTZzItWPqj9CIsl2Z3Pf6vvM5bY3bmdCzgTaw+3dUuuW7F9iCr2VxTsXk+/JJ8+bx86mneZgD0P86vydQt20g3HZ43Db3cwvm88LO19gTc0a5hbHVtPK9+bz/jXvk+nKZOlBvSxnY6CRnc07mZQ7yRTqQm8hGa4MfnzKjylJL2FizkQEgu1N27uFDErSS1h6cClLDy4lzZHG2aPPRkpJjjuHdGe6uc1PT/x03066pa2gHPVwxOhMTHepGHUqkzJCne5MZ0zWKKpyVvJh3WhObljE1PypMctYh2y/vPtlXt/3OpnOTB445wFuev2mmOUWjV2E2+7mvYPvIaU0Haa1+NAppafwUdVHADQFm1gwcgFhLczOpp1m6MNld5HjzjEd9fam7eYw21NKTkEgCEQDCTvcjJxi47MntjzBy7tf5uxRZzO7aDbQdSO4YmJX+c5RmaP4uPrjGPHPcmVx+5zb+aT2E2YUzGB5xXLzhnPtZD2j4p7T72HJ/iXMLpzd6/m2YrRhKGaHVgwteZ485hbPNVMxFalJygg1wNWTr2ZV9XdZ0fI3Gj9Yxr8v/XfMI/z2pi6h/tWqX+Gyubhx+o3MKpzF7xb8jncPvsviXYuJyAil6aWMyBjBi7teZG/LXvK9+WS7sylvKze38Z1532FU5ihu/O+NbG/azoyCGaaQWwccFHgLqPPX0RJsobqjmkm5kwBdiKflT2Nzw+YeMyOMz17e/TIeu4dl5ctw2V14Hd6EscGrJ1/N71b/zkwbzHXnUpZRxqXHXcqlx10KwKXHXcrWxVup7Kjkhuk3AHD6iNM5fcTp3bbXG8YIRiPMoxg+OGwOHrvgsaFuhqIXUkqoF45aSBql+EO6KK+oWhGTS7q9cTsjM0ZS3jnD9VMXP2XGdBeOXsjY7LEs3qXXvChJLzFd65eXfJlafy23zrw1Jr1tRMYI0p3pTC+Ybgq1MdjEKlpFaUXU+epYX7cewEzNAz3fdXPD5pjRefFYS3P+5dy/8MU3vshb+99iRMaIhMt/ftrn+e/e//J+hT4D931n3ddt6LfT5uRXZ/yK/a37GZU5Kum++8IpZafw2AWPdXuC6St1bUFy0pw47SnV5aFQHDOk1C/LaXfy3emP0Lrnq+S48nl88+NsrNtIVXsVoWiI1TWrmZY/je/N+x7fP/H7pkgbGB2AoA+7PS77ONKd6VR2VOK0OfnL+r8QlVG+NONL/PjkH5sjvk4pPYUMZwYzC2aaYQAjRg1djvqV3a+Q5cqKGak3v2y+uUwyMpwZjM0ayy0zb+HEkhM5ufTkmOp08diEjdNGdM1UMbtwdsLyorOLZnPZhMuS7rev2IStW4y9r4QiGgvve5enVvZ/3jqFQtE3UspRAyyYXATSwSTPhXxY+U9WVa1iZOZIrp96PY2BRq6cdKUpjvFkuDJIc6Thi/goTS/FbrMzs2AmH1V9xA9O+gE//VAv8HPaiNNixPaCsRewcPRC3HY3p5SewqllpzIuu6uKX6G3kBpfDUsOLOEzEz8TMzR6XvE87jntHs4dfW7SYxJC8PLlL5thnCsnXcnKqpU9irs1ZthTnY2hpr49SFsgwq7a5JO49petVa00dYQ4dULy82OwqaKF59aU89NLpmGzqaJCikNjxe4GRuR4GZ2fmmmKKeWoAYoyPcwdk8vuvTNJc6SR48lhX+s+frnyl0zKndTrCDfDCRsj8K6adBVXTbqKyydcbi4THyoQQpjx4Am5E3ho0UMxsWOjYzGshbtlVAghuGzCZb3moVpj7eeMOoey9DJzFpZEHF9wfI/bSxXq2vR89ZrWQC9L9p373tzBd/69vk/Lvraxisc+3Me+ho4B279i+PGVJ9fwx7d3DnUzkpJyjhrgmhNH8f3nmvjj+X/l9PFjeGXPK9T4arh28rW95gcXphXGVLA7b+x5nDdWn9Dz1LJT+bDyw353mhnZELMLZx9yHNeK0+7kxctfNIeZJ+JoqcFc394p1G3BXpbsOxXNfqpaArQFwmR6en6aqGnV97uxooXxhSoX+FijNRDmhTXl3DB/7KA9MbUHIzT5wpQ3+XpfeIhISaG+eGYpv/jPFh54s40TbvT2a0LUKXlTYtLxrPxp4Z9oCjRht9kTrJmc08tO5+pJV/O1OV/r13o9YVSz64lHznukX3MMDgWGo64dQEdd2ewHYE9dB7NG5fS4rOHkN1W0cNnsxJ2ziqOXVzdUcdd/tnDCmFyOH5kzKPuo6vy+Vbb4B2X7A0FKqkC628GD18+luiXAnS9s6Ne63533XR4575GEn7nt7kMqwp7jyeEn83/SrfJcf6hvDxKJav1a5+TSk3stMTrUmELdFkTTDr88rS8UocWvD7XvS9y7S6hbD3vfwxkpJfe9uZ3NlS1D3ZQYjJDW3vqu0JamSd7aUjMg3zeAyhb9O1TdEiA6QNscaFJSqAFOn1jAbWcdxwe7GthW3fcfoU3Y+u2YB5tgJMrC373Lr/87eLO8DBVG6COqSRoGoOphZXOXM99V17tQVxtCXdkyYD/c4Uh5k5//fWcXT6862PvCCQiEowTC0QFuFRxo0MMR++q7whLvbKvllidW897OugHZh/EEF45K8/ucaqSsUAN89sTReJw2fvbSZt7ZVsN1j3zEb1/vm9hJKQlF+udgB4utVW20BiL8c+V+GlL0i3Co1FmOZyA6FKssj5+9OWpfKEJbIMLEogzaAhE2VKSWG0xlpJQ89sFeLv7T+yzfWc+6g80AbKk6tCeTrzy5llue6D6H6OFyoLFTqC2dxevLmwFYva+RB5buoj0Y6dO2OoKRhDdzI/QBev9IKpLSQp2b7uJ/rpjJ6v1NfPGx1azc08hf39vN79/czmf++iHffnYdkahGVYuff3y0n1c2VJoC/YVHP2bhfe9S3x4kEI7SFggjpYy56wfCUXbUtPW5Pdba1v5QlD8u2cnqfY3c9fLmHi/w+s4fQSCs8fu3dvR5f1FNmuGS6pZAQiH8aE8Dj7y/Z0BnxdE0yco9DUSiWsx2t1e3EYzEuqb6thBpLv0JprZtAIS601HPGpXDR7sb+GCXXr/kvxur+NHijTHtMToSP3vSaBw2weubEpe0Bf1cbjqCQi6ljBGFNfsbWbG7oYc1Bp/2YIRbnljNxvIWNle2ctd/trC5spX/W77HFOptVa39ejKpavGzu66dZTvq+GBXPS9+UsF/N1b1vmIfkFKajtoa+thQrl/Hvy/fx71vbOfpVb3n8LcFwsz/1dv8/YO93T6rsDzFVaaoUPepM1EIcQHwR8AOPCKl/PWgtsrCp08YyfSybOragkwszuDiPy3nT+/sYlxBOmv2N7FyTyNVLX6M79ZL0yqREt7bUYfTLrj0f5fTHogQimqML8ygqsXPi185jdF5aXztqbUs2VrL986fzP6GDq49aTQnjO6KQ3+4q55nVx/ktrOO44W1Ffxr1QG+eNo4Zo7I5pODTTywdDf360X38IUi/PbKrtznUETD5dDvg+sPNlOY6eby2WX87f29rNjTwKjcNG5bcBzzj0s8jdX26jZu++caMj0OTh6Xx6Mf7KMw083b31lAmku/bAcafNzyxGraAhGCEY2vnj0hZhvBSJS99R1MLs5ECEEgHMXj7D0s9M+V+/npS5u5aGYJq/Y2ce9Vx5PlcfKZv37IiWNzeeSGE8nurB1e1x5kamkWa/Y3Ud0S5JMDTRRleSjL9vDPj/bzxuYairM8fPms8diEIMPjoDDDzYo9DRRmuJlYrA860jRJVEoqmv0IAfddNYuvPLmGmx9fzRvfPJP/+e9WDjb6OXdqMbNH5VDe5KcjpDupySWZzD8un9c3VfHd8ybR7A+zs6ad2aNy8LrsSCn50eKNPP3xQR68fi4XzIjtpzCyS8JRjUc/2MuFM0oZldf/fNqa1gAeh50sr4OrH1rB9uo2bj5jPOMK0vnWM+uQwG8+czzNvhB1bUG+f8EU7HGZDP9YsY8XPqngU7PK2FXbzk8vnYbboV+zUERjX0MHk4r7PjWXlJLNla1MLc3iP+sreWtLDQcbfZw9pQibgCvnjuT5tRXs7xTEjlCU/Y0+xuanmR3yLb4wXpcdl8PG/oYOMj1O8tJdaJrkur+tpKLZT6TzB/jNZ9aR7rJz+sSCXjN2eqPJF6YtGMFhE+yt72BXbRtFWR42dt5w/Z2m66V1ldwwfyzPrSnn4pml5nfTyjvbamkNRFj8SQU3nxGbFlvV4mdScQY7atp7FGpNk/zqv/psTz+6eNphHVt/Eb05MSGEHdgBLALKgY+Bz0opExd6BubNmydXrx74xyDQxSkQiTKpOJOnVx3gvR11jC9M54o5I3l3ey2/fX07YU3j55+aTlm2l3+tOkB+hovq1iAby5vRpH7ChYDWQIRMj4O2QNej008vmUZxloeH399jOmGDGSOyYjqtTpuQT1Gmh8aOECt2N/CNcyeypbKVLK+DxZ9UcPK4fM6bXsxflu5mamkWD15/Ar/67zYONvrYVNFCQ0eIb547iSmlmfx3YxXFWR7Km/zsa+hgU0ULmR4nzb4QmoTzphXz5pYaLphewsIpRdS0Bnh4mT6Zwcnj81iytZZF04ppC4QZmZvGzWeM455XtrJ8Vz3zxuQysTiDF9ZW8KtPz8RuE5RkefjXqgMUZLgZW5DOqxuqKMpys2J3A22dNzajY2V0XhqTSzL5YFc9kahk9qgc5ozOYeGUIr70+GqumDOCF9aWE5WSQFjDbhMcV5jOjpp2JhdnUtHsx2kX+EJR8tJdFGV5WH+wmWyvk3ljctE6BVpKKM3xsq2qlVU/OpeKZj+Lfv8euWkuKpr9uBw28tNdhCIaDR0hppdlsbmylSXfPpNNFa1885l1lGV7qGoNICVkuh3cc8UM3ttexwufVOCy2zh+ZDb/vm0+rYEIWR4Hb2yu5itPruXsyUWML0znb+/vpSzbww8umorLYaM4y8O00iw0KXlnWy3HFWYwuSSTxo4Q33j6E0qyPEwuySQv3cVdL+sldS+aWcrTHx9kSkkm26rbEAJOHJOHzQYf7ema6efcqUU47Tb2N/h4+Ia5uBw2zrr3XXyhrqeWi2aW8O1Fk4hokj8u2cl/N1Xz9YUTOHdqMRkeBy3+MMePyMZhGb5f0ezn7a01nDmxkPd31vGTlzZz3cmj2Vbdxo7qNto6QwXzxuRy9+UzuPCPeqmCk8blsWqv3r4ROV6unDuS+cfl8//+sYbSbA+3LTiOH7ywkYJMF89/+VS2VbVxw99XAfq59rjs1LcHkRI+NauMWaNyOHtyIaXZXp5bc5CnPz6IwyZYMKmQUXlpZHocnDO1OKb0wPqDzby1pYbrTxnD9po2bvz7qph2GYzJT2N/g48sj4PWQISFU4p4Z1st504t5m83zEUIQWsgzOsbq5lSmslD7+3h1U6n//StpzBrpH4Tb+oIcdGf3mfumFze21HHxKIM7r58BoWZbkIRDSmhoSOEy27j/5bv5fm1evmKB6+fy/nTiwd05nYhxBop5byEn/VBqOcDd0kpz+/8+wcAUspfJVtnMIW6N3bVttHiDzN3TPfaG5GoxoaKFv750X4y3A6mlGRx0rhcXvykkhvmj+GO5zewdLveQXFcYTpXzxvFyePzeeLDfVw/fwxzRuWwp76DffUdLP6kgjsumMKovDT21ndw/v3LCEU1SrM91LYFOXlcHhvLW8wfxV2XTuMLp3WNdmzsCHHTYx+bNwOnXRCOSlx2G7NGZTOhKJNvL5rEx/sa8YeifGbuSO56eTOPfbjP3Mb504v53vlTGJOfxg9f2MibW2qYUJTB5soWAmE9ZPL5U8bw0roKWgMRMtyOmHhelsdBIKIRiujtbuwIcdqEAuragtx54RSe/vggs0flcPcr+j351jPHM7U0k289EzsY5UcXTWXu2Fz+tfIAU0uzqG0LsnpfI+dMLea2BePZ1+Djqgc/pCDDTWWzH5tNcPvCifx56S58oQhOuw2n3YYvFCEQ1vjcyaP5nytmAvDy+krueWULGW4HP79sOn9YshOv047bYePtbfrM7hvuOo8sj5Pn1pTz4icVnDg2j6mlmdy/ZCdbO2Ou3zp3EuluO/e8utU8D5luB/5wlNH5aVS3BPCFoswdk0t5k88MqwCku+xIMAU0y+MgokndRUoIdYan8tJdTCvNYvmuesbkp/HGN8/kO8+uRyK576rZOO2CRz/YRyiq4XHa+c3r29A0icdpxx+O4rQLIlHJX647gcaOEI2+EPe+sR3rT3RqaZZ5TAYZbgeZHgdOuw1NSiqbu54wAfLTXWZH750XTiEY1rh/yQ7uvmw6n58/lmdXH6S80cdlc0Zwzn3vYRNwxsRC3ttRZx5XJKrRGohQmu2hyRciEpW6y7bbOG96CXnpTsbkp9MeiPCfDZV8cqDZ3L9NgCZh9qgchIB1B5vNY0pz2cn2OnE5bESikurW7pkXf7x2Nr98dasu3tVtvL65ml9/eibfe24Df/7cHP6wZCe7atuZWJTBztp2XA4bBeku6jtCMf1UZ0ws4P2d9eZ+izLdlDf50aTk/mtmU9cW5Pdv7Yi5UVoRAr561gT+u6mK3XUdOO0Ch82Gwyaw2wWaJsnyOll+x8KE6/fG4Qr1lcAFUsqbO//+PHCylPJrccvdCtwKMHr06Ln79+8/pMYOJeGoxoe79djsgkmFMS6lN1oDYaSEbK+TqCax2wThqEZDewibgMJMd8K7b0N7kO01bYwrSGd/g4+cNCdTSpLXhY5qkp21bQgEk0sSPwIfbPTxwa56JhZnMHdMHgcbfazY08CZEwv576Yqxuan89GeBv7fguOwCT217ZTxeUmPd93BZj7a08C1J44iJ83FpooWijLdvPBJBTleJ5fNHoHX1XNIpS0QxuO009Aewu2wkZuuu2SBno4ppWR/g4+GjiBnTy6KOVeapk+fYA0TaJrucOvbg1x7UuKpvtoCYd7dXsfMEdmMLUgnFNH450f72dfQQUm2h5qWAB6XnVvOGE84qvHUygNcd/IYCjJcbKpsxSagosnPij0N2ITgzEkF7KhpN9O4Lp9TxnGFGYSjkhV7GphUnMHk4kyW76qnJMtjhnWSUdXipz0QQQjB4k/K8Yc0zp9ezMnju8Jhu2rbWbO/Ea/Lgdth47xpxWyvaaO80U+LP4zbaWPV3kYC4ajuAIGx+emcO7WYlXsbaA1EuGH+GD7c3UB7IMLlc8pIczk40OBjVJ6323fyQIOP/AwX6W4He+raeXd7HfOPy6c028OG8hamlWVR2xrklQ2VVDT7OW9aCRcfXxqzjdrWAPXtIVwOwfqDLeyt7yAnzclNp43DbhN0BCPUtwfZVdvO+zvr6QjqT3BOu42iTDeLphXz4e4GMj0OctJcXHp8aUw7I1ENh91GZbOfshwv4ajGqr2NzBubyyvrq9hR00ZtW5CCDBfnTS9hT107Bxp9XHviaFbvb8Qf0thR00ZDR4jReV4+NWuE+Vtq8YdZvLaciCbJ9DgQCAoyXbQFIozJT2f2qBzq2oK8vqmKiuYAmpREopKopiGEIDfNxTfO7V6Xpy8cEaG2MpSOWqFQKI5GehLqvljGCsBaHGNk53sKhUKhOAL0Rag/BiYKIcYJIVzAtcDLg9sshUKhUBj0mp4npYwIIb4GvIGenvd3KeXmXlZTKBQKxQDRpzxqKeVrwGuD3BaFQqFQJCClRyYqFAqFQgm1QqFQpDxKqBUKhSLFUUKtUCgUKU6vA14OaaNC1AGHOjSxAKgfwOYMJepYUo9j5ThAHUuqcqjHMkZKmXCewEER6sNBCLE62eicow11LKnHsXIcoI4lVRmMY1GhD4VCoUhxlFArFApFipOKQv3wUDdgAFHHknocK8cB6lhSlQE/lpSLUSsUCoUillR01AqFQqGwoIRaoVAoUpyUEWohxAVCiO1CiF1CiDuHuj39RQixTwixUQixTgixuvO9PCHEW0KInZ3/5/a2naFACPF3IUStEGKT5b2EbRc6f+q8ThuEECcMXcu7k+RY7hJCVHRem3VCiIssn/2g81i2CyHOH5pWJ0YIMUoIsVQIsUUIsVkI8Y3O94+6a9PDsRx110YI4RFCrBJCrO88lp93vj9OCLGys83PdJaFRgjh7vx7V+fnY/u9UynlkP9DL5+6GxgPuID1wLShblc/j2EfUBD33m+BOztf3wn8ZqjbmaTtZwInAJt6aztwEfBfQACnACuHuv19OJa7gO8mWHZa53fNDYzr/A7ah/oYLO0rBU7ofJ2JPsn0tKPx2vRwLEfdtek8vxmdr53Ays7z/Sxwbef7DwJf7nz9FeDBztfXAs/0d5+p4qhPAnZJKfdIKUPA08BlQ9ymgeAy4PHO148Dlw9dU5IjpVwGNMa9naztlwFPSJ2PgBwhRCkpQpJjScZlwNNSyqCUci+wC/27mBJIKauklGs7X7cBW4ERHIXXpodjSUbKXpvO89ve+aez858EFgLPdb4ff12M6/UccI7o5/TlqSLUI4CDlr/L6fkipiISeFMIsaZzol+AYillVefraqB4aJp2SCRr+9F6rb7WGQ74uyUEddQcS+fj8hx093ZUX5u4Y4Gj8NoIIexCiHVALfAWuuNvllJGOhexttc8ls7PW4B8+kGqCPWxwOlSyhOAC4GvCiHOtH4o9eeeozIX8mhueyd/BY4DZgNVwH1D2pp+IoTIAJ4HvimlbLV+drRdmwTHclReGyllVEo5G30O2ZOAKYO5v1QR6qN+Al0pZUXn/7XAYvSLV2M8enb+Xzt0Lew3ydp+1F0rKWVN5w9LA/5G1yN0yh+LEMKJLmxPSilf6Hz7qLw2iY7laL42AFLKZmApMB891GTMmmVtr3ksnZ9nAw392U+qCPVRPYGuECJdCJFpvAbOAzahH8ONnYvdCLw0NC08JJK1/WXghs4Mg1OAFstjeEoSF6e9Av3agH4s13b2yo8DJgKrjnT7ktEZx/w/YKuU8veWj466a5PsWI7GayOEKBRC5HS+9gKL0GPuS4ErOxeLvy7G9boSeKfzSajvDHUPqqUn9SL0nuDdwI+Guj39bPt49B7q9cBmo/3ocai3gZ3AEiBvqNuapP3/Qn/sDKPH1r6UrO3oPd4PdF6njcC8oW5/H47lH51t3dD5oym1LP+jzmPZDlw41O2PO5bT0cMaG4B1nf8uOhqvTQ/HctRdG+B44JPONm8Cftr5/nj0m8ku4N+Au/N9T+ffuzo/H9/ffaoh5AqFQpHipEroQ6FQKBRJUEKtUCgUKY4SaoVCoUhxlFArFApFiqOEWqFQKFIcJdQKhUKR4iihVigUihTn/wM348/YsW+RmAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses.plot()\n",
        "plt.savefig('losses.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Marital status                                       1.000000\n",
              "Application mode                                    17.000000\n",
              "Application order                                    1.000000\n",
              "Course                                            9853.000000\n",
              "Daytime/evening attendance                           1.000000\n",
              "Previous qualification                               1.000000\n",
              "Previous qualification (grade)                     125.000000\n",
              "Nacionality                                          1.000000\n",
              "Mother's qualification                              19.000000\n",
              "Father's qualification                              19.000000\n",
              "Mother's occupation                                  4.000000\n",
              "Father's occupation                                  7.000000\n",
              "Admission grade                                    128.500000\n",
              "Displaced                                            1.000000\n",
              "Educational special needs                            0.000000\n",
              "Debtor                                               0.000000\n",
              "Tuition fees up to date                              1.000000\n",
              "Gender                                               0.000000\n",
              "Scholarship holder                                   0.000000\n",
              "Age at enrollment                                   18.000000\n",
              "International                                        0.000000\n",
              "Curricular units 1st sem (credited)                  0.000000\n",
              "Curricular units 1st sem (enrolled)                  7.000000\n",
              "Curricular units 1st sem (evaluations)               9.000000\n",
              "Curricular units 1st sem (approved)                  6.000000\n",
              "Curricular units 1st sem (grade)                    11.500000\n",
              "Curricular units 1st sem (without evaluations)       0.000000\n",
              "Curricular units 2nd sem (credited)                  0.000000\n",
              "Curricular units 2nd sem (enrolled)                  7.000000\n",
              "Curricular units 2nd sem (evaluations)               8.000000\n",
              "Curricular units 2nd sem (approved)                  7.000000\n",
              "Curricular units 2nd sem (grade)                    12.714286\n",
              "Curricular units 2nd sem (without evaluations)       0.000000\n",
              "Unemployment rate                                   13.900000\n",
              "Inflation rate                                      -0.300000\n",
              "GDP                                                  0.790000\n",
              "Name: 1195, dtype: float64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "random.seed(87)\n",
        "random_ind = random.randint(0, len(dataset))\n",
        "\n",
        "new_student = dataset.drop('Target', axis = 1).iloc[random_ind]\n",
        "new_student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.9380804953560371\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.89      0.93       104\n",
            "           1       0.90      0.99      0.94       145\n",
            "           2       0.99      0.89      0.94        74\n",
            "\n",
            "   micro avg       0.94      0.94      0.94       323\n",
            "   macro avg       0.95      0.93      0.94       323\n",
            "weighted avg       0.94      0.94      0.94       323\n",
            " samples avg       0.94      0.94      0.94       323\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy Score:', accuracy_score(y_test, predictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test, predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Untitled2.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
