{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IBXRF3JsTKP1",
        "outputId": "560073c5-f44d-494e-9021-9921158a1b06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Nacionality</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>171</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>9254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>160.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>9070</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>9773</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-3.12</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>8014</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>9991</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>133.1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9500</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>142.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>14.345000</td>\n",
              "      <td>0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-4.06</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>9254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>119.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-4.06</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>137.0</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>14.142857</td>\n",
              "      <td>0</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>3.51</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Marital status  Application mode  Application order  Course  \\\n",
              "0               1                17                  5     171   \n",
              "1               1                15                  1    9254   \n",
              "2               1                 1                  5    9070   \n",
              "3               1                17                  2    9773   \n",
              "4               2                39                  1    8014   \n",
              "5               2                39                  1    9991   \n",
              "6               1                 1                  1    9500   \n",
              "7               1                18                  4    9254   \n",
              "8               1                 1                  3    9238   \n",
              "9               1                 1                  1    9238   \n",
              "\n",
              "   Daytime/evening attendance  Previous qualification  \\\n",
              "0                           1                       1   \n",
              "1                           1                       1   \n",
              "2                           1                       1   \n",
              "3                           1                       1   \n",
              "4                           0                       1   \n",
              "5                           0                      19   \n",
              "6                           1                       1   \n",
              "7                           1                       1   \n",
              "8                           1                       1   \n",
              "9                           1                       1   \n",
              "\n",
              "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
              "0                           122.0            1                      19   \n",
              "1                           160.0            1                       1   \n",
              "2                           122.0            1                      37   \n",
              "3                           122.0            1                      38   \n",
              "4                           100.0            1                      37   \n",
              "5                           133.1            1                      37   \n",
              "6                           142.0            1                      19   \n",
              "7                           119.0            1                      37   \n",
              "8                           137.0           62                       1   \n",
              "9                           138.0            1                       1   \n",
              "\n",
              "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
              "0                      12  ...                                    0   \n",
              "1                       3  ...                                    0   \n",
              "2                      37  ...                                    0   \n",
              "3                      37  ...                                    0   \n",
              "4                      38  ...                                    0   \n",
              "5                      37  ...                                    0   \n",
              "6                      38  ...                                    0   \n",
              "7                      37  ...                                    0   \n",
              "8                       1  ...                                    0   \n",
              "9                      19  ...                                    0   \n",
              "\n",
              "   Curricular units 2nd sem (enrolled)  \\\n",
              "0                                    0   \n",
              "1                                    6   \n",
              "2                                    6   \n",
              "3                                    6   \n",
              "4                                    6   \n",
              "5                                    5   \n",
              "6                                    8   \n",
              "7                                    5   \n",
              "8                                    6   \n",
              "9                                    6   \n",
              "\n",
              "   Curricular units 2nd sem (evaluations)  \\\n",
              "0                                       0   \n",
              "1                                       6   \n",
              "2                                       0   \n",
              "3                                      10   \n",
              "4                                       6   \n",
              "5                                      17   \n",
              "6                                       8   \n",
              "7                                       5   \n",
              "8                                       7   \n",
              "9                                      14   \n",
              "\n",
              "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "0                                    0                          0.000000   \n",
              "1                                    6                         13.666667   \n",
              "2                                    0                          0.000000   \n",
              "3                                    5                         12.400000   \n",
              "4                                    6                         13.000000   \n",
              "5                                    5                         11.500000   \n",
              "6                                    8                         14.345000   \n",
              "7                                    0                          0.000000   \n",
              "8                                    6                         14.142857   \n",
              "9                                    2                         13.500000   \n",
              "\n",
              "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "0                                               0               10.8   \n",
              "1                                               0               13.9   \n",
              "2                                               0               10.8   \n",
              "3                                               0                9.4   \n",
              "4                                               0               13.9   \n",
              "5                                               5               16.2   \n",
              "6                                               0               15.5   \n",
              "7                                               0               15.5   \n",
              "8                                               0               16.2   \n",
              "9                                               0                8.9   \n",
              "\n",
              "   Inflation rate   GDP    Target  \n",
              "0             1.4  1.74   Dropout  \n",
              "1            -0.3  0.79  Graduate  \n",
              "2             1.4  1.74   Dropout  \n",
              "3            -0.8 -3.12  Graduate  \n",
              "4            -0.3  0.79  Graduate  \n",
              "5             0.3 -0.92  Graduate  \n",
              "6             2.8 -4.06  Graduate  \n",
              "7             2.8 -4.06   Dropout  \n",
              "8             0.3 -0.92  Graduate  \n",
              "9             1.4  3.51   Dropout  \n",
              "\n",
              "[10 rows x 37 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#dataset import\n",
        "dataset = pd.read_csv('data.csv') #You need to change #directory accordingly\n",
        "dataset.head(10) #Return 10 rows of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-buQfLLrTUuc",
        "outputId": "a87b4f82-1e11-4e37-e6d5-754c611f9cc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Graduate    2209\n",
              "Dropout     1421\n",
              "Enrolled     794\n",
              "Name: Target, dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['Target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrolQem-TV34",
        "outputId": "bacd12e5-bbe9-4863-912f-d8c57c23e42b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4424, 36)\n",
            "(4424, 1)\n"
          ]
        }
      ],
      "source": [
        "#Changing pandas dataframe to numpy array\n",
        "X = dataset.iloc[:,:36].values\n",
        "y = dataset.iloc[:,36:37].values\n",
        "y[10:40]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCXSuAmm73VM",
        "outputId": "b8874d01-5060-4643-e278-e2184925de17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imblearn) (0.9.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KlGwVDaATWqX"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "import math\n",
        "\n",
        "bordersmote = SMOTEENN()\n",
        "X, y = SMOTEENN().fit_resample(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LjzwqovUI80",
        "outputId": "841e1033-a2f5-4fdd-f979-852106897075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3086, 36)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYJucrgfTayV",
        "outputId": "354fa819-1881-4224-e872-27d7c4163733"
      },
      "outputs": [],
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "# dummy_y[10:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DXMxCBmrTb7t"
      },
      "outputs": [],
      "source": [
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X = poly_features.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zNTX22OkTnnA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,dummy_y,test_size = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y4Uk8Yh7TpU3"
      },
      "outputs": [],
      "source": [
        "#Dependencies\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "# Neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cgYoymXmTuiE"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-c-Ns3ZTwAU",
        "outputId": "bc00ef59-d064-4d2c-e141-b8dfa3521921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "87/87 [==============================] - 7s 29ms/step - loss: 0.8440 - accuracy: 0.7062 - val_loss: 0.4053 - val_accuracy: 0.8317\n",
            "Epoch 2/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.4076 - accuracy: 0.8650 - val_loss: 0.3438 - val_accuracy: 0.8544\n",
            "Epoch 3/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.2561 - accuracy: 0.9193 - val_loss: 0.2773 - val_accuracy: 0.9288\n",
            "Epoch 4/300\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.1845 - accuracy: 0.9420 - val_loss: 0.2826 - val_accuracy: 0.9061\n",
            "Epoch 5/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.1457 - accuracy: 0.9514 - val_loss: 0.2808 - val_accuracy: 0.9288\n",
            "Epoch 6/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.1167 - accuracy: 0.9622 - val_loss: 0.2985 - val_accuracy: 0.9223\n",
            "Epoch 7/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0857 - accuracy: 0.9741 - val_loss: 0.4922 - val_accuracy: 0.9353\n",
            "Epoch 8/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0911 - accuracy: 0.9730 - val_loss: 0.4480 - val_accuracy: 0.9191\n",
            "Epoch 9/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0805 - accuracy: 0.9766 - val_loss: 0.3538 - val_accuracy: 0.9159\n",
            "Epoch 10/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0590 - accuracy: 0.9795 - val_loss: 0.3922 - val_accuracy: 0.9256\n",
            "Epoch 11/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0618 - accuracy: 0.9784 - val_loss: 0.4693 - val_accuracy: 0.9191\n",
            "Epoch 12/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0867 - accuracy: 0.9777 - val_loss: 0.4719 - val_accuracy: 0.9094\n",
            "Epoch 13/300\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.0580 - accuracy: 0.9834 - val_loss: 0.5475 - val_accuracy: 0.9094\n",
            "Epoch 14/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0814 - accuracy: 0.9752 - val_loss: 0.4272 - val_accuracy: 0.9191\n",
            "Epoch 15/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0478 - accuracy: 0.9863 - val_loss: 0.4455 - val_accuracy: 0.9256\n",
            "Epoch 16/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 0.5096 - val_accuracy: 0.9320\n",
            "Epoch 17/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0564 - accuracy: 0.9860 - val_loss: 0.4050 - val_accuracy: 0.9191\n",
            "Epoch 18/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0448 - accuracy: 0.9867 - val_loss: 0.4973 - val_accuracy: 0.9320\n",
            "Epoch 19/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.0713 - accuracy: 0.9831 - val_loss: 0.5441 - val_accuracy: 0.9385\n",
            "Epoch 20/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0608 - accuracy: 0.9820 - val_loss: 0.4126 - val_accuracy: 0.9353\n",
            "Epoch 21/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.5348 - val_accuracy: 0.9256\n",
            "Epoch 22/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 0.6027 - val_accuracy: 0.9353\n",
            "Epoch 23/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.5964 - val_accuracy: 0.9288\n",
            "Epoch 24/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.7164 - val_accuracy: 0.9320\n",
            "Epoch 25/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0359 - accuracy: 0.9885 - val_loss: 0.4317 - val_accuracy: 0.9159\n",
            "Epoch 26/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0501 - accuracy: 0.9860 - val_loss: 0.4000 - val_accuracy: 0.9288\n",
            "Epoch 27/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 0.6346 - val_accuracy: 0.9126\n",
            "Epoch 28/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0400 - accuracy: 0.9899 - val_loss: 0.5614 - val_accuracy: 0.9320\n",
            "Epoch 29/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.4629 - val_accuracy: 0.9353\n",
            "Epoch 30/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0345 - accuracy: 0.9924 - val_loss: 0.5811 - val_accuracy: 0.9256\n",
            "Epoch 31/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0330 - accuracy: 0.9942 - val_loss: 0.6366 - val_accuracy: 0.9223\n",
            "Epoch 32/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0898 - accuracy: 0.9802 - val_loss: 0.4127 - val_accuracy: 0.9288\n",
            "Epoch 33/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0776 - accuracy: 0.9824 - val_loss: 0.5693 - val_accuracy: 0.9385\n",
            "Epoch 34/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0545 - accuracy: 0.9892 - val_loss: 0.5428 - val_accuracy: 0.9288\n",
            "Epoch 35/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0419 - accuracy: 0.9906 - val_loss: 0.6466 - val_accuracy: 0.9288\n",
            "Epoch 36/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0319 - accuracy: 0.9921 - val_loss: 0.6078 - val_accuracy: 0.9385\n",
            "Epoch 37/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0414 - accuracy: 0.9903 - val_loss: 0.6789 - val_accuracy: 0.9256\n",
            "Epoch 38/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0235 - accuracy: 0.9939 - val_loss: 0.8114 - val_accuracy: 0.9385\n",
            "Epoch 39/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 1.0573 - val_accuracy: 0.9353\n",
            "Epoch 40/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0358 - accuracy: 0.9953 - val_loss: 0.8916 - val_accuracy: 0.9320\n",
            "Epoch 41/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0730 - accuracy: 0.9899 - val_loss: 0.5868 - val_accuracy: 0.9256\n",
            "Epoch 42/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.6664 - val_accuracy: 0.9288\n",
            "Epoch 43/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0464 - accuracy: 0.9903 - val_loss: 0.6499 - val_accuracy: 0.9288\n",
            "Epoch 44/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0334 - accuracy: 0.9950 - val_loss: 0.7159 - val_accuracy: 0.9417\n",
            "Epoch 45/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.7313 - val_accuracy: 0.9353\n",
            "Epoch 46/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0262 - accuracy: 0.9953 - val_loss: 0.6093 - val_accuracy: 0.9320\n",
            "Epoch 47/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0335 - accuracy: 0.9899 - val_loss: 1.2325 - val_accuracy: 0.9417\n",
            "Epoch 48/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0560 - accuracy: 0.9881 - val_loss: 0.6691 - val_accuracy: 0.9191\n",
            "Epoch 49/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0432 - accuracy: 0.9906 - val_loss: 0.5024 - val_accuracy: 0.9482\n",
            "Epoch 50/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0355 - accuracy: 0.9935 - val_loss: 0.5825 - val_accuracy: 0.9353\n",
            "Epoch 51/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.7579 - val_accuracy: 0.9417\n",
            "Epoch 52/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.7924 - val_accuracy: 0.9256\n",
            "Epoch 53/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0981 - accuracy: 0.9942 - val_loss: 0.4112 - val_accuracy: 0.9353\n",
            "Epoch 54/300\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.0373 - accuracy: 0.9924 - val_loss: 0.7876 - val_accuracy: 0.9223\n",
            "Epoch 55/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0334 - accuracy: 0.9917 - val_loss: 0.7354 - val_accuracy: 0.9288\n",
            "Epoch 56/300\n",
            "87/87 [==============================] - 2s 20ms/step - loss: 0.0511 - accuracy: 0.9903 - val_loss: 0.5942 - val_accuracy: 0.9353\n",
            "Epoch 57/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 0.5964 - val_accuracy: 0.9450\n",
            "Epoch 58/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0321 - accuracy: 0.9950 - val_loss: 0.4725 - val_accuracy: 0.9126\n",
            "Epoch 59/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.7183 - val_accuracy: 0.9159\n",
            "Epoch 60/300\n",
            "87/87 [==============================] - 3s 32ms/step - loss: 0.0897 - accuracy: 0.9885 - val_loss: 0.7053 - val_accuracy: 0.9288\n",
            "Epoch 61/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.1141 - accuracy: 0.9896 - val_loss: 0.7366 - val_accuracy: 0.9256\n",
            "Epoch 62/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0492 - accuracy: 0.9896 - val_loss: 0.4286 - val_accuracy: 0.9353\n",
            "Epoch 63/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0419 - accuracy: 0.9906 - val_loss: 0.7813 - val_accuracy: 0.9256\n",
            "Epoch 64/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0323 - accuracy: 0.9946 - val_loss: 0.6220 - val_accuracy: 0.9159\n",
            "Epoch 65/300\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.0477 - accuracy: 0.9917 - val_loss: 0.8405 - val_accuracy: 0.9320\n",
            "Epoch 66/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0863 - accuracy: 0.9881 - val_loss: 0.6986 - val_accuracy: 0.9320\n",
            "Epoch 67/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.9120 - val_accuracy: 0.9353\n",
            "Epoch 68/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 1.0480 - val_accuracy: 0.9288\n",
            "Epoch 69/300\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 1.0216 - val_accuracy: 0.9288\n",
            "Epoch 70/300\n",
            "87/87 [==============================] - 3s 31ms/step - loss: 0.0460 - accuracy: 0.9888 - val_loss: 0.6351 - val_accuracy: 0.9353\n",
            "Epoch 71/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.6811 - val_accuracy: 0.9353\n",
            "Epoch 72/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.0150 - accuracy: 0.9978 - val_loss: 0.7518 - val_accuracy: 0.9353\n",
            "Epoch 73/300\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.9594 - val_accuracy: 0.9288\n",
            "Epoch 74/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0202 - accuracy: 0.9971 - val_loss: 1.0518 - val_accuracy: 0.9320\n",
            "Epoch 75/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.0368 - accuracy: 0.9942 - val_loss: 0.7095 - val_accuracy: 0.9320\n",
            "Epoch 76/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0388 - accuracy: 0.9946 - val_loss: 0.7759 - val_accuracy: 0.9256\n",
            "Epoch 77/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.8224 - val_accuracy: 0.9288\n",
            "Epoch 78/300\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.0250 - accuracy: 0.9939 - val_loss: 1.0444 - val_accuracy: 0.9256\n",
            "Epoch 79/300\n",
            "87/87 [==============================] - 2s 21ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 1.3045 - val_accuracy: 0.9256\n",
            "Epoch 80/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 1.0502 - val_accuracy: 0.9191\n",
            "Epoch 81/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0407 - accuracy: 0.9928 - val_loss: 0.9712 - val_accuracy: 0.9094\n",
            "Epoch 82/300\n",
            "87/87 [==============================] - 3s 31ms/step - loss: 0.0294 - accuracy: 0.9921 - val_loss: 1.0856 - val_accuracy: 0.9256\n",
            "Epoch 83/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0222 - accuracy: 0.9950 - val_loss: 1.3875 - val_accuracy: 0.9256\n",
            "Epoch 84/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.1053 - accuracy: 0.9921 - val_loss: 1.3468 - val_accuracy: 0.9223\n",
            "Epoch 85/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0634 - accuracy: 0.9906 - val_loss: 0.7969 - val_accuracy: 0.9320\n",
            "Epoch 86/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0829 - accuracy: 0.9917 - val_loss: 0.8171 - val_accuracy: 0.9256\n",
            "Epoch 87/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0331 - accuracy: 0.9935 - val_loss: 0.8208 - val_accuracy: 0.9159\n",
            "Epoch 88/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.4926 - val_accuracy: 0.9320\n",
            "Epoch 89/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0449 - accuracy: 0.9906 - val_loss: 1.1280 - val_accuracy: 0.9256\n",
            "Epoch 90/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 1.0535 - val_accuracy: 0.9256\n",
            "Epoch 91/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 1.0702 - val_accuracy: 0.9256\n",
            "Epoch 92/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 1.7378 - val_accuracy: 0.9320\n",
            "Epoch 93/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0546 - accuracy: 0.9953 - val_loss: 2.0249 - val_accuracy: 0.9191\n",
            "Epoch 94/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0595 - accuracy: 0.9924 - val_loss: 0.9302 - val_accuracy: 0.9191\n",
            "Epoch 95/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0364 - accuracy: 0.9953 - val_loss: 1.4402 - val_accuracy: 0.9126\n",
            "Epoch 96/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0280 - accuracy: 0.9968 - val_loss: 1.5597 - val_accuracy: 0.9256\n",
            "Epoch 97/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0127 - accuracy: 0.9993 - val_loss: 2.2880 - val_accuracy: 0.9223\n",
            "Epoch 98/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.1646 - accuracy: 0.9852 - val_loss: 1.2351 - val_accuracy: 0.9061\n",
            "Epoch 99/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.1015 - accuracy: 0.9863 - val_loss: 0.9002 - val_accuracy: 0.9256\n",
            "Epoch 100/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0363 - accuracy: 0.9928 - val_loss: 0.8382 - val_accuracy: 0.9256\n",
            "Epoch 101/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0240 - accuracy: 0.9964 - val_loss: 0.8986 - val_accuracy: 0.9256\n",
            "Epoch 102/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 1.1608 - val_accuracy: 0.9353\n",
            "Epoch 103/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0209 - accuracy: 0.9989 - val_loss: 1.8464 - val_accuracy: 0.9288\n",
            "Epoch 104/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 1.5508 - val_accuracy: 0.9223\n",
            "Epoch 105/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 1.4097 - val_accuracy: 0.9191\n",
            "Epoch 106/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 1.5632 - val_accuracy: 0.9353\n",
            "Epoch 107/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0341 - accuracy: 0.9971 - val_loss: 0.9571 - val_accuracy: 0.9353\n",
            "Epoch 108/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.1171 - accuracy: 0.9971 - val_loss: 1.3987 - val_accuracy: 0.9256\n",
            "Epoch 109/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0103 - accuracy: 0.9960 - val_loss: 1.4234 - val_accuracy: 0.9417\n",
            "Epoch 110/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0258 - accuracy: 0.9964 - val_loss: 1.6123 - val_accuracy: 0.9353\n",
            "Epoch 111/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 1.8193 - val_accuracy: 0.9353\n",
            "Epoch 112/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 2.3320 - val_accuracy: 0.9385\n",
            "Epoch 113/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0347 - accuracy: 0.9960 - val_loss: 1.2713 - val_accuracy: 0.9385\n",
            "Epoch 114/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0170 - accuracy: 0.9964 - val_loss: 1.6094 - val_accuracy: 0.9353\n",
            "Epoch 115/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0475 - accuracy: 0.9957 - val_loss: 1.1850 - val_accuracy: 0.9256\n",
            "Epoch 116/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 1.8588 - val_accuracy: 0.9385\n",
            "Epoch 117/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0069 - accuracy: 0.9971 - val_loss: 1.9788 - val_accuracy: 0.9288\n",
            "Epoch 118/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 2.3044 - val_accuracy: 0.9353\n",
            "Epoch 119/300\n",
            "87/87 [==============================] - 3s 32ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 2.3652 - val_accuracy: 0.9353\n",
            "Epoch 120/300\n",
            "87/87 [==============================] - 3s 31ms/step - loss: 9.1495e-04 - accuracy: 0.9996 - val_loss: 2.6827 - val_accuracy: 0.9353\n",
            "Epoch 121/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0213 - accuracy: 0.9982 - val_loss: 2.6208 - val_accuracy: 0.9320\n",
            "Epoch 122/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 2.9508 - val_accuracy: 0.9288\n",
            "Epoch 123/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 2.8820 - val_accuracy: 0.9223\n",
            "Epoch 124/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 2.2519 - val_accuracy: 0.9288\n",
            "Epoch 125/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 2.1511 - val_accuracy: 0.9256\n",
            "Epoch 126/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0101 - accuracy: 0.9989 - val_loss: 2.5538 - val_accuracy: 0.9256\n",
            "Epoch 127/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 1.7773 - val_accuracy: 0.9320\n",
            "Epoch 128/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0126 - accuracy: 0.9986 - val_loss: 1.8089 - val_accuracy: 0.9159\n",
            "Epoch 129/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0687 - accuracy: 0.9924 - val_loss: 1.7767 - val_accuracy: 0.9029\n",
            "Epoch 130/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0208 - accuracy: 0.9960 - val_loss: 1.5747 - val_accuracy: 0.9094\n",
            "Epoch 131/300\n",
            "87/87 [==============================] - 3s 32ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 2.6689 - val_accuracy: 0.9353\n",
            "Epoch 132/300\n",
            "87/87 [==============================] - 3s 37ms/step - loss: 0.0331 - accuracy: 0.9964 - val_loss: 2.1266 - val_accuracy: 0.9417\n",
            "Epoch 133/300\n",
            "87/87 [==============================] - 3s 32ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 2.7752 - val_accuracy: 0.9191\n",
            "Epoch 134/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0752 - accuracy: 0.9917 - val_loss: 1.8560 - val_accuracy: 0.9223\n",
            "Epoch 135/300\n",
            "87/87 [==============================] - 3s 31ms/step - loss: 0.0677 - accuracy: 0.9903 - val_loss: 1.2080 - val_accuracy: 0.9320\n",
            "Epoch 136/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.8685 - val_accuracy: 0.9353\n",
            "Epoch 137/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 1.7435 - val_accuracy: 0.9256\n",
            "Epoch 138/300\n",
            "87/87 [==============================] - 3s 34ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 1.7460 - val_accuracy: 0.9288\n",
            "Epoch 139/300\n",
            "87/87 [==============================] - 3s 33ms/step - loss: 0.0532 - accuracy: 0.9921 - val_loss: 0.7551 - val_accuracy: 0.9256\n",
            "Epoch 140/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0225 - accuracy: 0.9957 - val_loss: 1.5142 - val_accuracy: 0.9256\n",
            "Epoch 141/300\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.0352 - accuracy: 0.9968 - val_loss: 1.0741 - val_accuracy: 0.9288\n",
            "Epoch 142/300\n",
            "87/87 [==============================] - 3s 31ms/step - loss: 0.0618 - accuracy: 0.9910 - val_loss: 1.1992 - val_accuracy: 0.9320\n",
            "Epoch 143/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0294 - accuracy: 0.9957 - val_loss: 1.3220 - val_accuracy: 0.9482\n",
            "Epoch 144/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0168 - accuracy: 0.9968 - val_loss: 1.6486 - val_accuracy: 0.9353\n",
            "Epoch 145/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 1.6134 - val_accuracy: 0.9320\n",
            "Epoch 146/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0183 - accuracy: 0.9971 - val_loss: 1.4022 - val_accuracy: 0.9353\n",
            "Epoch 147/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 1.8832 - val_accuracy: 0.9353\n",
            "Epoch 148/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0393 - accuracy: 0.9960 - val_loss: 0.9380 - val_accuracy: 0.9417\n",
            "Epoch 149/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0063 - accuracy: 0.9971 - val_loss: 2.1534 - val_accuracy: 0.9256\n",
            "Epoch 150/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 2.3868 - val_accuracy: 0.9385\n",
            "Epoch 151/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0239 - accuracy: 0.9964 - val_loss: 1.0233 - val_accuracy: 0.9223\n",
            "Epoch 152/300\n",
            "87/87 [==============================] - 3s 32ms/step - loss: 0.0609 - accuracy: 0.9978 - val_loss: 1.8663 - val_accuracy: 0.9385\n",
            "Epoch 153/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0184 - accuracy: 0.9978 - val_loss: 1.5881 - val_accuracy: 0.9353\n",
            "Epoch 154/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0195 - accuracy: 0.9978 - val_loss: 1.9130 - val_accuracy: 0.9288\n",
            "Epoch 155/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0289 - accuracy: 0.9942 - val_loss: 1.2631 - val_accuracy: 0.9353\n",
            "Epoch 156/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0285 - accuracy: 0.9946 - val_loss: 1.1197 - val_accuracy: 0.9547\n",
            "Epoch 157/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0698 - accuracy: 0.9950 - val_loss: 1.6506 - val_accuracy: 0.9417\n",
            "Epoch 158/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0195 - accuracy: 0.9971 - val_loss: 1.5163 - val_accuracy: 0.9450\n",
            "Epoch 159/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0237 - accuracy: 0.9964 - val_loss: 1.3791 - val_accuracy: 0.9320\n",
            "Epoch 160/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 1.4090 - val_accuracy: 0.9353\n",
            "Epoch 161/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 2.5909 - val_accuracy: 0.9320\n",
            "Epoch 162/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0330 - accuracy: 0.9942 - val_loss: 1.9494 - val_accuracy: 0.9223\n",
            "Epoch 163/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0307 - accuracy: 0.9935 - val_loss: 1.3069 - val_accuracy: 0.9126\n",
            "Epoch 164/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 1.6357 - val_accuracy: 0.9159\n",
            "Epoch 165/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.1363 - accuracy: 0.9946 - val_loss: 1.6800 - val_accuracy: 0.9256\n",
            "Epoch 166/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 2.0976 - val_accuracy: 0.9029\n",
            "Epoch 167/300\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.0257 - accuracy: 0.9960 - val_loss: 1.0672 - val_accuracy: 0.9385\n",
            "Epoch 168/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0289 - accuracy: 0.9953 - val_loss: 1.6889 - val_accuracy: 0.9385\n",
            "Epoch 169/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0142 - accuracy: 0.9982 - val_loss: 1.5393 - val_accuracy: 0.9256\n",
            "Epoch 170/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 1.7642 - val_accuracy: 0.9320\n",
            "Epoch 171/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 1.7692 - val_accuracy: 0.9450\n",
            "Epoch 172/300\n",
            "87/87 [==============================] - 2s 22ms/step - loss: 0.0787 - accuracy: 0.9975 - val_loss: 1.6278 - val_accuracy: 0.9288\n",
            "Epoch 173/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.1235 - accuracy: 0.9928 - val_loss: 1.2560 - val_accuracy: 0.9353\n",
            "Epoch 174/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 2.3354 - val_accuracy: 0.9126\n",
            "Epoch 175/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0555 - accuracy: 0.9968 - val_loss: 2.4992 - val_accuracy: 0.9256\n",
            "Epoch 176/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.1727 - accuracy: 0.9928 - val_loss: 1.2903 - val_accuracy: 0.9191\n",
            "Epoch 177/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0260 - accuracy: 0.9939 - val_loss: 1.7847 - val_accuracy: 0.9191\n",
            "Epoch 178/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0136 - accuracy: 0.9982 - val_loss: 1.4747 - val_accuracy: 0.9320\n",
            "Epoch 179/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 1.7048 - val_accuracy: 0.9385\n",
            "Epoch 180/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 2.0385 - val_accuracy: 0.9353\n",
            "Epoch 181/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 8.5415e-04 - accuracy: 0.9996 - val_loss: 2.5540 - val_accuracy: 0.9353\n",
            "Epoch 182/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 3.7699 - val_accuracy: 0.9191\n",
            "Epoch 183/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 2.6241 - val_accuracy: 0.9450\n",
            "Epoch 184/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0296 - accuracy: 0.9986 - val_loss: 1.8297 - val_accuracy: 0.9450\n",
            "Epoch 185/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0188 - accuracy: 0.9975 - val_loss: 1.5563 - val_accuracy: 0.9482\n",
            "Epoch 186/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 2.1889 - val_accuracy: 0.9482\n",
            "Epoch 187/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 4.0204e-05 - accuracy: 1.0000 - val_loss: 2.3068 - val_accuracy: 0.9385\n",
            "Epoch 188/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 6.4913e-05 - accuracy: 1.0000 - val_loss: 2.4712 - val_accuracy: 0.9320\n",
            "Epoch 189/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0139 - accuracy: 0.9986 - val_loss: 1.7256 - val_accuracy: 0.9320\n",
            "Epoch 190/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 1.8795 - val_accuracy: 0.9417\n",
            "Epoch 191/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 2.4845 - val_accuracy: 0.9320\n",
            "Epoch 192/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0365 - accuracy: 0.9978 - val_loss: 1.3215 - val_accuracy: 0.9515\n",
            "Epoch 193/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0206 - accuracy: 0.9971 - val_loss: 1.1311 - val_accuracy: 0.9450\n",
            "Epoch 194/300\n",
            "87/87 [==============================] - 3s 37ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 1.3737 - val_accuracy: 0.9515\n",
            "Epoch 195/300\n",
            "87/87 [==============================] - 3s 40ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 2.8530 - val_accuracy: 0.9385\n",
            "Epoch 196/300\n",
            "87/87 [==============================] - 3s 34ms/step - loss: 0.4101 - accuracy: 0.9863 - val_loss: 1.1298 - val_accuracy: 0.9385\n",
            "Epoch 197/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0246 - accuracy: 0.9953 - val_loss: 1.7941 - val_accuracy: 0.9450\n",
            "Epoch 198/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0692 - accuracy: 0.9950 - val_loss: 1.0142 - val_accuracy: 0.9450\n",
            "Epoch 199/300\n",
            "87/87 [==============================] - 3s 32ms/step - loss: 0.0286 - accuracy: 0.9935 - val_loss: 1.3480 - val_accuracy: 0.9385\n",
            "Epoch 200/300\n",
            "87/87 [==============================] - 3s 39ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 1.5019 - val_accuracy: 0.9450\n",
            "Epoch 201/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0670 - accuracy: 0.9960 - val_loss: 1.6852 - val_accuracy: 0.9256\n",
            "Epoch 202/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0643 - accuracy: 0.9953 - val_loss: 1.1412 - val_accuracy: 0.9288\n",
            "Epoch 203/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0151 - accuracy: 0.9978 - val_loss: 1.7696 - val_accuracy: 0.9450\n",
            "Epoch 204/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 9.9798e-04 - accuracy: 1.0000 - val_loss: 3.2573 - val_accuracy: 0.9450\n",
            "Epoch 205/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.1694 - accuracy: 0.9993 - val_loss: 5.1962 - val_accuracy: 0.9353\n",
            "Epoch 206/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0763 - accuracy: 0.9935 - val_loss: 1.4084 - val_accuracy: 0.9417\n",
            "Epoch 207/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 2.2525 - val_accuracy: 0.9353\n",
            "Epoch 208/300\n",
            "87/87 [==============================] - 3s 37ms/step - loss: 0.0208 - accuracy: 0.9975 - val_loss: 1.5493 - val_accuracy: 0.9482\n",
            "Epoch 209/300\n",
            "87/87 [==============================] - 3s 35ms/step - loss: 0.0338 - accuracy: 0.9939 - val_loss: 1.1496 - val_accuracy: 0.9417\n",
            "Epoch 210/300\n",
            "87/87 [==============================] - 3s 34ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 1.6483 - val_accuracy: 0.9450\n",
            "Epoch 211/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0354 - accuracy: 0.9950 - val_loss: 1.6071 - val_accuracy: 0.9353\n",
            "Epoch 212/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.1134 - accuracy: 0.9968 - val_loss: 1.3498 - val_accuracy: 0.9288\n",
            "Epoch 213/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0317 - accuracy: 0.9950 - val_loss: 1.3006 - val_accuracy: 0.9353\n",
            "Epoch 214/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 1.1981 - val_accuracy: 0.9450\n",
            "Epoch 215/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0292 - val_accuracy: 0.9450\n",
            "Epoch 216/300\n",
            "87/87 [==============================] - 3s 33ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 2.2610 - val_accuracy: 0.9482\n",
            "Epoch 217/300\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 2.0567 - val_accuracy: 0.9450\n",
            "Epoch 218/300\n",
            "87/87 [==============================] - 3s 31ms/step - loss: 0.0154 - accuracy: 0.9989 - val_loss: 2.6659 - val_accuracy: 0.9417\n",
            "Epoch 219/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 2.8371 - val_accuracy: 0.9450\n",
            "Epoch 220/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 5.3453e-04 - accuracy: 1.0000 - val_loss: 3.2078 - val_accuracy: 0.9450\n",
            "Epoch 221/300\n",
            "87/87 [==============================] - 3s 33ms/step - loss: 0.0380 - accuracy: 0.9971 - val_loss: 3.0937 - val_accuracy: 0.9320\n",
            "Epoch 222/300\n",
            "87/87 [==============================] - 3s 31ms/step - loss: 0.1336 - accuracy: 0.9971 - val_loss: 1.2717 - val_accuracy: 0.9353\n",
            "Epoch 223/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0149 - accuracy: 0.9982 - val_loss: 1.7019 - val_accuracy: 0.9482\n",
            "Epoch 224/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0089 - accuracy: 0.9989 - val_loss: 2.4694 - val_accuracy: 0.9450\n",
            "Epoch 225/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 1.9769 - val_accuracy: 0.9353\n",
            "Epoch 226/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0300 - accuracy: 0.9957 - val_loss: 2.0218 - val_accuracy: 0.9450\n",
            "Epoch 227/300\n",
            "87/87 [==============================] - 3s 33ms/step - loss: 0.0407 - accuracy: 0.9971 - val_loss: 1.8796 - val_accuracy: 0.9515\n",
            "Epoch 228/300\n",
            "87/87 [==============================] - 3s 33ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 3.0203 - val_accuracy: 0.9482\n",
            "Epoch 229/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 2.2491e-04 - accuracy: 1.0000 - val_loss: 3.3910 - val_accuracy: 0.9482\n",
            "Epoch 230/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 2.5367 - val_accuracy: 0.9482\n",
            "Epoch 231/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0150 - accuracy: 0.9978 - val_loss: 2.6697 - val_accuracy: 0.9482\n",
            "Epoch 232/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0369 - accuracy: 0.9957 - val_loss: 1.4993 - val_accuracy: 0.9482\n",
            "Epoch 233/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 2.6956 - val_accuracy: 0.9547\n",
            "Epoch 234/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 3.1915 - val_accuracy: 0.9547\n",
            "Epoch 235/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0441 - accuracy: 0.9968 - val_loss: 2.4143 - val_accuracy: 0.9450\n",
            "Epoch 236/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 3.0871 - val_accuracy: 0.9515\n",
            "Epoch 237/300\n",
            "87/87 [==============================] - 2s 29ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 3.7791 - val_accuracy: 0.9482\n",
            "Epoch 238/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 4.6867 - val_accuracy: 0.9515\n",
            "Epoch 239/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 9.5960e-04 - accuracy: 0.9993 - val_loss: 5.5805 - val_accuracy: 0.9515\n",
            "Epoch 240/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0437 - accuracy: 0.9989 - val_loss: 6.5599 - val_accuracy: 0.9482\n",
            "Epoch 241/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0164 - accuracy: 0.9982 - val_loss: 4.2431 - val_accuracy: 0.9547\n",
            "Epoch 242/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0372 - accuracy: 0.9950 - val_loss: 3.9664 - val_accuracy: 0.9482\n",
            "Epoch 243/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.1278 - accuracy: 0.9924 - val_loss: 3.9058 - val_accuracy: 0.9385\n",
            "Epoch 244/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 5.2274 - val_accuracy: 0.9450\n",
            "Epoch 245/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0078 - accuracy: 0.9960 - val_loss: 6.4741 - val_accuracy: 0.9353\n",
            "Epoch 246/300\n",
            "87/87 [==============================] - 3s 30ms/step - loss: 0.0786 - accuracy: 0.9928 - val_loss: 1.9625 - val_accuracy: 0.9288\n",
            "Epoch 247/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0793 - accuracy: 0.9899 - val_loss: 1.6655 - val_accuracy: 0.9029\n",
            "Epoch 248/300\n",
            "87/87 [==============================] - 3s 34ms/step - loss: 0.0246 - accuracy: 0.9935 - val_loss: 2.0675 - val_accuracy: 0.9353\n",
            "Epoch 249/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0347 - accuracy: 0.9910 - val_loss: 2.9731 - val_accuracy: 0.9385\n",
            "Epoch 250/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0504 - accuracy: 0.9942 - val_loss: 2.1450 - val_accuracy: 0.9482\n",
            "Epoch 251/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 2.9258 - val_accuracy: 0.9482\n",
            "Epoch 252/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0255 - accuracy: 0.9950 - val_loss: 3.1567 - val_accuracy: 0.9450\n",
            "Epoch 253/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0572 - accuracy: 0.9946 - val_loss: 2.9462 - val_accuracy: 0.9450\n",
            "Epoch 254/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.1168 - accuracy: 0.9950 - val_loss: 1.7299 - val_accuracy: 0.9417\n",
            "Epoch 255/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0206 - accuracy: 0.9953 - val_loss: 1.6422 - val_accuracy: 0.9450\n",
            "Epoch 256/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 1.7099 - val_accuracy: 0.9385\n",
            "Epoch 257/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 2.2052 - val_accuracy: 0.9385\n",
            "Epoch 258/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 2.6362 - val_accuracy: 0.9450\n",
            "Epoch 259/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 2.5375 - val_accuracy: 0.9417\n",
            "Epoch 260/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 2.8042 - val_accuracy: 0.9385\n",
            "Epoch 261/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0491 - accuracy: 0.9939 - val_loss: 1.2922 - val_accuracy: 0.9385\n",
            "Epoch 262/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 2.2945 - val_accuracy: 0.9450\n",
            "Epoch 263/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 2.6138 - val_accuracy: 0.9385\n",
            "Epoch 264/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 2.6764 - val_accuracy: 0.9417\n",
            "Epoch 265/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 7.5128e-04 - accuracy: 0.9996 - val_loss: 3.4158 - val_accuracy: 0.9450\n",
            "Epoch 266/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0534 - accuracy: 0.9971 - val_loss: 2.2129 - val_accuracy: 0.9223\n",
            "Epoch 267/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0309 - accuracy: 0.9950 - val_loss: 2.3466 - val_accuracy: 0.9288\n",
            "Epoch 268/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0198 - accuracy: 0.9975 - val_loss: 2.1860 - val_accuracy: 0.9417\n",
            "Epoch 269/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 3.1305 - val_accuracy: 0.9385\n",
            "Epoch 270/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 3.9732 - val_accuracy: 0.9385\n",
            "Epoch 271/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0679 - accuracy: 0.9971 - val_loss: 2.6605 - val_accuracy: 0.9450\n",
            "Epoch 272/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0253 - accuracy: 0.9964 - val_loss: 2.5799 - val_accuracy: 0.9385\n",
            "Epoch 273/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 2.1765 - val_accuracy: 0.9417\n",
            "Epoch 274/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0128 - accuracy: 0.9986 - val_loss: 3.0022 - val_accuracy: 0.9450\n",
            "Epoch 275/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0380 - accuracy: 0.9957 - val_loss: 2.4333 - val_accuracy: 0.9320\n",
            "Epoch 276/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0759 - accuracy: 0.9946 - val_loss: 2.3736 - val_accuracy: 0.9353\n",
            "Epoch 277/300\n",
            "87/87 [==============================] - 2s 26ms/step - loss: 0.0892 - accuracy: 0.9946 - val_loss: 2.9646 - val_accuracy: 0.9450\n",
            "Epoch 278/300\n",
            "87/87 [==============================] - 3s 40ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 3.2934 - val_accuracy: 0.9385\n",
            "Epoch 279/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 3.9910 - val_accuracy: 0.9417\n",
            "Epoch 280/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0110 - accuracy: 0.9989 - val_loss: 6.0411 - val_accuracy: 0.9417\n",
            "Epoch 281/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0455 - accuracy: 0.9996 - val_loss: 3.5450 - val_accuracy: 0.9385\n",
            "Epoch 282/300\n",
            "87/87 [==============================] - 2s 27ms/step - loss: 0.0817 - accuracy: 0.9964 - val_loss: 4.4478 - val_accuracy: 0.9353\n",
            "Epoch 283/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 5.5140 - val_accuracy: 0.9353\n",
            "Epoch 284/300\n",
            "87/87 [==============================] - 2s 28ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 5.6570 - val_accuracy: 0.9353\n",
            "Epoch 285/300\n",
            "87/87 [==============================] - 3s 29ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 6.2546 - val_accuracy: 0.9417\n",
            "Epoch 286/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0354 - accuracy: 0.9971 - val_loss: 3.0520 - val_accuracy: 0.9353\n",
            "Epoch 287/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 3.7211 - val_accuracy: 0.9320\n",
            "Epoch 288/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.1599 - accuracy: 0.9971 - val_loss: 3.7806 - val_accuracy: 0.9353\n",
            "Epoch 289/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0282 - accuracy: 0.9964 - val_loss: 4.3597 - val_accuracy: 0.9385\n",
            "Epoch 290/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 5.6207 - val_accuracy: 0.9417\n",
            "Epoch 291/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.1246 - accuracy: 0.9924 - val_loss: 2.9855 - val_accuracy: 0.9320\n",
            "Epoch 292/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 2.9214 - val_accuracy: 0.9256\n",
            "Epoch 293/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 3.5321 - val_accuracy: 0.9288\n",
            "Epoch 294/300\n",
            "87/87 [==============================] - 2s 25ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 4.1342 - val_accuracy: 0.9353\n",
            "Epoch 295/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 4.0502 - val_accuracy: 0.9385\n",
            "Epoch 296/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 3.9292 - val_accuracy: 0.9353\n",
            "Epoch 297/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 4.2718 - val_accuracy: 0.9353\n",
            "Epoch 298/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 4.9176 - val_accuracy: 0.9353\n",
            "Epoch 299/300\n",
            "87/87 [==============================] - 2s 24ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 6.6052 - val_accuracy: 0.9288\n",
            "Epoch 300/300\n",
            "87/87 [==============================] - 2s 23ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 6.4006 - val_accuracy: 0.9320\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train,y_train,epochs=300,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW_brfNH8IXk",
        "outputId": "0f149cc2-105f-447b-a283-7cb67cef131b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.954692542552948"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M50U2tCv8P6e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('predict_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "later_model = load_model('predict_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses.plot()\n",
        "plt.savefig('losses.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Marital status                                       1.000000\n",
              "Application mode                                    17.000000\n",
              "Application order                                    1.000000\n",
              "Course                                            9853.000000\n",
              "Daytime/evening attendance                           1.000000\n",
              "Previous qualification                               1.000000\n",
              "Previous qualification (grade)                     125.000000\n",
              "Nacionality                                          1.000000\n",
              "Mother's qualification                              19.000000\n",
              "Father's qualification                              19.000000\n",
              "Mother's occupation                                  4.000000\n",
              "Father's occupation                                  7.000000\n",
              "Admission grade                                    128.500000\n",
              "Displaced                                            1.000000\n",
              "Educational special needs                            0.000000\n",
              "Debtor                                               0.000000\n",
              "Tuition fees up to date                              1.000000\n",
              "Gender                                               0.000000\n",
              "Scholarship holder                                   0.000000\n",
              "Age at enrollment                                   18.000000\n",
              "International                                        0.000000\n",
              "Curricular units 1st sem (credited)                  0.000000\n",
              "Curricular units 1st sem (enrolled)                  7.000000\n",
              "Curricular units 1st sem (evaluations)               9.000000\n",
              "Curricular units 1st sem (approved)                  6.000000\n",
              "Curricular units 1st sem (grade)                    11.500000\n",
              "Curricular units 1st sem (without evaluations)       0.000000\n",
              "Curricular units 2nd sem (credited)                  0.000000\n",
              "Curricular units 2nd sem (enrolled)                  7.000000\n",
              "Curricular units 2nd sem (evaluations)               8.000000\n",
              "Curricular units 2nd sem (approved)                  7.000000\n",
              "Curricular units 2nd sem (grade)                    12.714286\n",
              "Curricular units 2nd sem (without evaluations)       0.000000\n",
              "Unemployment rate                                   13.900000\n",
              "Inflation rate                                      -0.300000\n",
              "GDP                                                  0.790000\n",
              "Name: 1195, dtype: float64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "random.seed(87)\n",
        "random_ind = random.randint(0,len(dataset))\n",
        "\n",
        "new_student = dataset.drop('Target',axis=1).iloc[random_ind]\n",
        "new_student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.9320388349514563\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96       114\n",
            "           1       0.92      0.94      0.93       135\n",
            "           2       0.87      0.90      0.89        60\n",
            "\n",
            "   micro avg       0.93      0.93      0.93       309\n",
            "   macro avg       0.92      0.93      0.93       309\n",
            "weighted avg       0.93      0.93      0.93       309\n",
            " samples avg       0.93      0.93      0.93       309\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy Score:',accuracy_score(y_test,predictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Untitled2.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
